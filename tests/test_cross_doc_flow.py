"""æµ‹è¯•è·¨æ–‡æ¡£æ£€ç´¢æ•°æ®æµçš„å®Œæ•´æ€§"""

# æ¨¡æ‹Ÿå®Œæ•´çš„æ•°æ®æµ
def test_cross_doc_data_flow():
    print("=" * 80)
    print("æµ‹è¯•è·¨æ–‡æ¡£æ£€ç´¢æ•°æ®æµ")
    print("=" * 80)

    # Step 1: æ¨¡æ‹Ÿ RetrievalAgent çš„è¿”å›ç»“æœ
    retrieval_state_a = {
        "query": "Transformeråœ¨NLPä¸­çš„ä¼˜ç‚¹",
        "doc_name": "NLPè®ºæ–‡.pdf",
        "final_summary": "Transformeråœ¨NLPä»»åŠ¡ä¸­å…·æœ‰ä»¥ä¸‹ä¼˜ç‚¹ï¼š\n1. å¹¶è¡Œè®¡ç®—èƒ½åŠ›å¼ºï¼ˆè§ç¬¬3ç« ï¼Œç¬¬12é¡µï¼‰\n2. é•¿è·ç¦»ä¾èµ–å»ºæ¨¡å¥½ï¼ˆè§ç¬¬3ç« ï¼Œç¬¬15é¡µï¼‰",
        "formatted_data": [...],  # ç®€åŒ–
        "is_complete": True
    }

    retrieval_state_b = {
        "query": "Transformeræ¨¡å‹æ¶æ„ä¼˜åŠ¿",
        "doc_name": "æ¶æ„æŒ‡å—.pdf",
        "final_summary": "Transformeræ¶æ„çš„æ ¸å¿ƒä¼˜åŠ¿åŒ…æ‹¬ï¼š\n- Self-attentionæœºåˆ¶ï¼ˆè§ç¬¬2ç« ï¼Œç¬¬8é¡µï¼‰\n- å¤šå¤´æ³¨æ„åŠ›è®¾è®¡ï¼ˆè§ç¬¬2ç« ï¼Œç¬¬10é¡µï¼‰",
        "formatted_data": [...],  # ç®€åŒ–
        "is_complete": True
    }

    # Step 2: æ¨¡æ‹Ÿ ParallelCoordinator æ·»åŠ å…ƒæ•°æ®
    multi_doc_results = {
        "NLPè®ºæ–‡.pdf": {
            **retrieval_state_a,
            "source_metadata": {
                "doc_name": "NLPè®ºæ–‡.pdf",
                "similarity_score": 0.85
            },
            "used_query": "Transformeråœ¨NLPä¸­çš„ä¼˜ç‚¹"
        },
        "æ¶æ„æŒ‡å—.pdf": {
            **retrieval_state_b,
            "source_metadata": {
                "doc_name": "æ¶æ„æŒ‡å—.pdf",
                "similarity_score": 0.78
            },
            "used_query": "Transformeræ¨¡å‹æ¶æ„ä¼˜åŠ¿"
        }
    }

    print("\nğŸ“Š Step 1: ParallelCoordinator è¿”å›çš„ç»“æœ")
    print(f"   - æ–‡æ¡£æ•°é‡: {len(multi_doc_results)}")
    for doc_name, result in multi_doc_results.items():
        print(f"   - {doc_name}:")
        print(f"      - æœ‰ final_summary: {'final_summary' in result}")
        print(f"      - æœ‰ source_metadata: {'source_metadata' in result}")
        print(f"      - æœ‰ used_query: {'used_query' in result}")

    # Step 3: æ¨¡æ‹Ÿ CrossDocumentSynthesizer._format_multi_doc_results
    formatted_sections = []
    for doc_name, result in multi_doc_results.items():
        if result.get("error"):
            print(f"   âš ï¸  æ–‡æ¡£ '{doc_name}' æ£€ç´¢å¤±è´¥ï¼Œè·³è¿‡")
            continue

        source_metadata = result.get("source_metadata", {})
        relevance_score = source_metadata.get("similarity_score", "N/A")
        final_summary = result.get("final_summary", "")

        if not final_summary or not final_summary.strip():
            print(f"   âš ï¸  æ–‡æ¡£ '{doc_name}' ç»“æœä¸ºç©ºï¼Œè·³è¿‡")
            continue

        section = f"""
========================================
æ–‡æ¡£: {doc_name} (ç›¸å…³æ€§è¯„åˆ†: {relevance_score if isinstance(relevance_score, str) else f'{relevance_score:.3f}'})
========================================
{final_summary}
"""
        formatted_sections.append(section)

    formatted_results = "\n\n".join(formatted_sections)

    print("\nğŸ“‹ Step 2: CrossDocumentSynthesizer æ ¼å¼åŒ–ç»“æœ")
    print(formatted_results)

    # Step 4: æ¨¡æ‹Ÿ LLM è¾“å…¥
    user_query = "Transformerçš„ä¼˜ç‚¹"
    llm_prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{user_query}

ä»¥ä¸‹æ˜¯ä»å¤šä¸ªç›¸å…³æ–‡æ¡£ä¸­æ£€ç´¢åˆ°çš„å†…å®¹ï¼š

{formatted_results}

è¯·æ ¹æ®ä»¥ä¸Šå¤šä¸ªæ–‡æ¡£çš„å†…å®¹ï¼Œç»¼åˆå›ç­”ç”¨æˆ·é—®é¢˜ã€‚è¦æ±‚ï¼š
1. ç»¼åˆæ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæä¾›å…¨é¢çš„ç­”æ¡ˆ
2. æ˜ç¡®æ ‡æ³¨ä¿¡æ¯æ¥æºï¼ˆä¾‹å¦‚ï¼š"æ ¹æ®æ–‡æ¡£A..."ï¼Œ"æ–‡æ¡£BæŒ‡å‡º..."ï¼‰
3. å¦‚æœä¸åŒæ–‡æ¡£æœ‰å†²çªä¿¡æ¯ï¼Œè¯·å®¢è§‚å‘ˆç°å¹¶è¯´æ˜
4. å¦‚æœæ‰€æœ‰æ–‡æ¡£éƒ½æ— æ³•å›ç­”é—®é¢˜ï¼Œè¯·æ˜ç¡®è¯´æ˜
5. ä¿æŒç­”æ¡ˆçš„è¿è´¯æ€§å’Œå¯è¯»æ€§"""

    print("\nğŸ¤– Step 3: å‘é€ç»™ LLM çš„ Prompt")
    print("=" * 80)
    print(llm_prompt[:500] + "...")
    print("=" * 80)

    # éªŒè¯å…³é”®å­—æ®µ
    print("\nâœ… æ•°æ®æµéªŒè¯:")
    print(f"   - æ‰€æœ‰æ–‡æ¡£éƒ½æœ‰ final_summary: {all('final_summary' in r for r in multi_doc_results.values())}")
    print(f"   - æ‰€æœ‰æ–‡æ¡£éƒ½æœ‰ source_metadata: {all('source_metadata' in r for r in multi_doc_results.values())}")
    print(f"   - æ ¼å¼åŒ–ç»“æœä¸ä¸ºç©º: {len(formatted_results) > 0}")
    print(f"   - æ ¼å¼åŒ–åŒ…å«æ–‡æ¡£å: {all(doc_name in formatted_results for doc_name in multi_doc_results.keys())}")

if __name__ == "__main__":
    test_cross_doc_data_flow()
