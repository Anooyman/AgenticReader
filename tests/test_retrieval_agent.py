"""
RetrievalAgent æµ‹è¯•æ–‡ä»¶

åŠŸèƒ½ï¼š
1. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²ç»è¢«ç´¢å¼•ï¼ˆé€šè¿‡DocumentRegistryï¼‰
2. å¦‚æœå·²ç´¢å¼•ï¼Œä½¿ç”¨RetrievalAgentè¿›è¡Œæ£€ç´¢æµ‹è¯•
3. æ”¯æŒå•ä¸ªæˆ–æ‰¹é‡æŸ¥è¯¢æµ‹è¯•
4. æ˜¾ç¤ºæ£€ç´¢ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯

è¿è¡Œæ–¹å¼ï¼š
    python tests/test_retrieval_agent.py
"""
import sys
import os
import logging
import asyncio
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.agents.retrieval import RetrievalAgent
from src.agents.indexing import DocumentRegistry
from src.config.settings import VECTOR_DB_PATH

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s - %(message)s'
)
logger = logging.getLogger(__name__)


def print_section(title):
    """æ‰“å°åˆ†éš”çº¿å’Œæ ‡é¢˜"""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80 + "\n")


def print_subsection(title):
    """æ‰“å°å­æ ‡é¢˜"""
    print("\n" + "-"*80)
    print(f"  {title}")
    print("-"*80 + "\n")


def check_document_indexed(doc_registry: DocumentRegistry, doc_name: str) -> bool:
    """
    æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²è¢«ç´¢å¼•

    Args:
        doc_registry: DocumentRegistryå®ä¾‹
        doc_name: æ–‡æ¡£åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰

    Returns:
        bool: æ˜¯å¦å·²ç´¢å¼•
    """
    doc_info = doc_registry.get_by_name(doc_name)

    if doc_info:
        logger.info(f"âœ… æ–‡æ¡£å·²ç´¢å¼•: {doc_name}")
        logger.info(f"   - æ–‡æ¡£ID: {doc_info['doc_id']}")
        logger.info(f"   - ç´¢å¼•è·¯å¾„: {doc_info.get('index_path', 'N/A')}")
        logger.info(f"   - åˆ›å»ºæ—¶é—´: {doc_info.get('created_at', 'N/A')}")
        logger.info(f"   - ç®€è¦æ‘˜è¦: {doc_info.get('brief_summary', 'N/A')[:100]}...")

        # æ£€æŸ¥å‘é‡æ•°æ®åº“æ˜¯å¦å­˜åœ¨
        index_path = doc_info.get('index_path')
        if index_path and os.path.exists(index_path):
            logger.info(f"   - âœ… å‘é‡æ•°æ®åº“å­˜åœ¨")
            return True
        else:
            logger.warning(f"   - âš ï¸ å‘é‡æ•°æ®åº“ä¸å­˜åœ¨: {index_path}")
            return False
    else:
        logger.warning(f"âŒ æ–‡æ¡£æœªç´¢å¼•: {doc_name}")
        logger.warning(f"   æç¤º: è¯·å…ˆä½¿ç”¨ test_indexing_agent.py å¯¹è¯¥æ–‡æ¡£è¿›è¡Œç´¢å¼•")
        return False


async def test_single_query(
    retrieval_agent: RetrievalAgent,
    doc_name: str,
    query: str,
    max_iterations: int = 3
) -> Dict[str, Any]:
    """
    æµ‹è¯•å•ä¸ªæŸ¥è¯¢

    Args:
        retrieval_agent: RetrievalAgentå®ä¾‹
        doc_name: æ–‡æ¡£åç§°
        query: æŸ¥è¯¢é—®é¢˜
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°

    Returns:
        dict: æ£€ç´¢ç»“æœ
    """
    print_subsection(f"æ£€ç´¢æµ‹è¯•: {query}")

    try:
        logger.info(f"ğŸ“ æŸ¥è¯¢å†…å®¹: {query}")
        logger.info(f"ğŸ“„ ç›®æ ‡æ–‡æ¡£: {doc_name}")
        logger.info(f"ğŸ”„ æœ€å¤§è¿­ä»£: {max_iterations}")

        # è°ƒç”¨RetrievalAgentçš„graph
        result = await retrieval_agent.graph.ainvoke({
            "query": query,
            "doc_name": doc_name,
            "max_iterations": max_iterations,
            "current_iteration": 0,
            "is_complete": False,
            "thoughts": [],
            "actions": [],
            "observations": [],
            "retrieved_content": []
        })

        # æ£€æŸ¥ç»“æœ
        is_complete = result.get("is_complete", False)
        final_summary = result.get("final_summary", "")
        selected_pages = result.get("selected_pages", [])
        retrieved_content = result.get("retrieved_content", [])

        if is_complete:
            logger.info(f"\nâœ… æ£€ç´¢æˆåŠŸ")
            logger.info(f"\nğŸ“„ æœ€ç»ˆæ‘˜è¦:")
            logger.info(f"{final_summary}")
            logger.info(f"\nğŸ“‘ ç›¸å…³é¡µç : {selected_pages}")
            logger.info(f"\nğŸ“Š æ£€ç´¢ç»Ÿè®¡:")
            logger.info(f"   - æ£€ç´¢åˆ°çš„å†…å®¹å—: {len(retrieved_content)}")
            logger.info(f"   - è¿­ä»£æ¬¡æ•°: {result.get('current_iteration', 0)}")

            # æ˜¾ç¤ºéƒ¨åˆ†æ£€ç´¢å†…å®¹
            if retrieved_content:
                logger.info(f"\nğŸ“š æ£€ç´¢å†…å®¹é¢„è§ˆ:")
                for idx, content in enumerate(retrieved_content[:3], 1):
                    title = content.get("title", "Unknown")
                    pages = content.get("pages", [])
                    text = content.get("content", "")[:150]
                    logger.info(f"\n   [{idx}] {title} (Pages: {pages})")
                    logger.info(f"       {text}...")

            return {
                "query": query,
                "status": "success",
                "final_summary": final_summary,
                "selected_pages": selected_pages,
                "retrieved_count": len(retrieved_content),
                "iterations": result.get('current_iteration', 0)
            }
        else:
            logger.warning(f"âš ï¸ æ£€ç´¢æœªå®Œæˆ")
            logger.warning(f"   - åŸå› : {result.get('reason', 'æœªçŸ¥')}")

            return {
                "query": query,
                "status": "incomplete",
                "reason": result.get('reason', 'æœªçŸ¥'),
                "iterations": result.get('current_iteration', 0)
            }

    except Exception as e:
        logger.error(f"âŒ æ£€ç´¢å¤±è´¥: {query}")
        logger.error(f"   - é”™è¯¯: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

        return {
            "query": query,
            "status": "error",
            "error": str(e)
        }


async def batch_test_queries(
    doc_name: str,
    query_list: List[str],
    provider: str = "openai",
    max_iterations: int = 3
):
    """
    æ‰¹é‡æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨

    Args:
        doc_name: æ–‡æ¡£åç§°
        query_list: æŸ¥è¯¢åˆ—è¡¨
        provider: LLMæä¾›å•†
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
    """
    print_section(f"æ‰¹é‡æ£€ç´¢æµ‹è¯• - æ–‡æ¡£: {doc_name}")

    # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²ç´¢å¼•
    logger.info(f"ğŸ“‹ åˆå§‹åŒ–DocumentRegistry...")
    doc_registry = DocumentRegistry()

    if not check_document_indexed(doc_registry, doc_name):
        logger.error(f"âŒ æ–‡æ¡£æœªç´¢å¼•ï¼Œæ— æ³•è¿›è¡Œæ£€ç´¢æµ‹è¯•")
        logger.info(f"\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        logger.info(f"   1. è¿è¡Œ: python tests/test_indexing_agent.py")
        logger.info(f"   2. è¾“å…¥æ–‡æ¡£å: {doc_name}")
        logger.info(f"   3. ç­‰å¾…ç´¢å¼•å®Œæˆåå†è¿è¡Œæœ¬æµ‹è¯•")
        return

    # åˆå§‹åŒ–RetrievalAgent
    logger.info(f"\nğŸ”§ åˆå§‹åŒ–RetrievalAgent (provider={provider})...")
    retrieval_agent = RetrievalAgent(doc_name=doc_name)

    # å¤„ç†ç»“æœç»Ÿè®¡
    results = {
        "success": [],
        "incomplete": [],
        "error": []
    }

    # é€ä¸ªå¤„ç†æŸ¥è¯¢
    logger.info(f"\nğŸš€ å¼€å§‹æ‰¹é‡æ£€ç´¢æµ‹è¯• - å…± {len(query_list)} ä¸ªæŸ¥è¯¢\n")

    for idx, query in enumerate(query_list, 1):
        logger.info(f"\n{'='*80}")
        logger.info(f"è¿›åº¦: {idx}/{len(query_list)}")
        logger.info(f"{'='*80}")

        result = await test_single_query(
            retrieval_agent,
            doc_name,
            query,
            max_iterations
        )

        # ç»Ÿè®¡ç»“æœ
        status = result["status"]
        if status == "success":
            results["success"].append(result)
        elif status == "incomplete":
            results["incomplete"].append(result)
        else:
            results["error"].append(result)

    # æ‰“å°æœ€ç»ˆç»Ÿè®¡
    print_section("æµ‹è¯•å®Œæˆ - ç»Ÿè®¡æŠ¥å‘Š")

    logger.info(f"âœ… æ£€ç´¢æˆåŠŸ: {len(results['success'])} ä¸ª")
    for r in results['success']:
        logger.info(f"\n   æŸ¥è¯¢: {r['query']}")
        logger.info(f"   æ‘˜è¦: {r['final_summary'][:100]}...")
        logger.info(f"   é¡µç : {r['selected_pages']}")
        logger.info(f"   è¿­ä»£: {r['iterations']} æ¬¡")

    logger.info(f"\nâš ï¸ æœªå®Œæˆ: {len(results['incomplete'])} ä¸ª")
    for r in results['incomplete']:
        logger.info(f"   - {r['query']}: {r['reason']}")

    logger.info(f"\nâŒ å¤±è´¥: {len(results['error'])} ä¸ª")
    for r in results['error']:
        logger.info(f"   - {r['query']}: {r['error']}")

    logger.info(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    logger.info(f"   - æ€»æŸ¥è¯¢æ•°: {len(query_list)}")
    logger.info(f"   - æˆåŠŸç‡: {len(results['success'])/len(query_list)*100:.1f}%")

    return results


def get_query_list_from_user() -> List[str]:
    """
    ä»ç”¨æˆ·è¾“å…¥è·å–æŸ¥è¯¢åˆ—è¡¨

    Returns:
        List[str]: æŸ¥è¯¢åˆ—è¡¨
    """
    print("\n" + "="*80)
    print("  è¯·è¾“å…¥æŸ¥è¯¢é—®é¢˜")
    print("="*80)
    print("\nä½¿ç”¨è¯´æ˜:")
    print("  - è¾“å…¥æŸ¥è¯¢é—®é¢˜")
    print("  - å¤šä¸ªé—®é¢˜ç”¨åˆ†å·(;)åˆ†éš”")
    print("  - ä¾‹å¦‚: æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆ?; ä½œè€…æ˜¯è°?")
    print("  - è¾“å…¥ 'q' æˆ– 'quit' é€€å‡º\n")

    try:
        user_input = input("è¯·è¾“å…¥æŸ¥è¯¢: ").strip()

        # æ£€æŸ¥é€€å‡ºå‘½ä»¤
        if user_input.lower() in ['q', 'quit', 'exit', 'é€€å‡º']:
            logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return []

        # æ£€æŸ¥ç©ºè¾“å…¥
        if not user_input:
            logger.warning("è¾“å…¥ä¸ºç©ºï¼Œè¯·é‡æ–°è¿è¡Œå¹¶è¾“å…¥æŸ¥è¯¢")
            return []

        # è§£æåˆ†å·åˆ†éš”çš„æŸ¥è¯¢
        queries = [q.strip() for q in user_input.split(';')]
        # è¿‡æ»¤æ‰ç©ºå­—ç¬¦ä¸²
        queries = [q for q in queries if q]

        if not queries:
            logger.warning("æœªè¯†åˆ«åˆ°æœ‰æ•ˆçš„æŸ¥è¯¢")
            return []

        logger.info(f"âœ… å·²è¯†åˆ« {len(queries)} ä¸ªæŸ¥è¯¢:")
        for query in queries:
            logger.info(f"   - {query}")

        return queries

    except EOFError:
        logger.warning("\næ£€æµ‹åˆ°EOFï¼Œä½¿ç”¨ç©ºåˆ—è¡¨")
        return []
    except KeyboardInterrupt:
        logger.warning("\nç”¨æˆ·ä¸­æ–­è¾“å…¥")
        return []


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print_section("RetrievalAgent æµ‹è¯•")

    # ==================== é…ç½®æµ‹è¯•å‚æ•° ====================

    # ğŸ“ æ–‡æ¡£åç§°ï¼ˆå¿…é¡»æ˜¯å·²ç»ç´¢å¼•è¿‡çš„æ–‡æ¡£ï¼‰
    doc_name = "1706.03762v7"  # æ”¹ä¸ºä½ å·²ç»ç´¢å¼•çš„æ–‡æ¡£å

    # ğŸ“ æŸ¥è¯¢åˆ—è¡¨ï¼ˆæ”¯æŒå¤šä¸ªæŸ¥è¯¢ï¼‰
    query_list = [
        "è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ç¬¬ä¸‰ç« çš„è¯¦ç»†å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ",
        "æœ¬æ–‡çš„ç»“æ„æ˜¯æ€æ ·çš„ï¼Ÿ",
        # "Transformeræ¨¡å‹çš„æ¶æ„æ˜¯æ€æ ·çš„ï¼Ÿ",
        # "ä½œè€…æå‡ºäº†å“ªäº›åˆ›æ–°ç‚¹ï¼Ÿ",
    ]

    # å¦‚æœæŸ¥è¯¢åˆ—è¡¨ä¸ºç©ºï¼Œæç¤ºç”¨æˆ·è¾“å…¥
    if not query_list:
        logger.info("ğŸ’¬ æŸ¥è¯¢åˆ—è¡¨æœªé¢„è®¾ï¼Œå¯åŠ¨äº¤äº’å¼è¾“å…¥...")
        query_list = get_query_list_from_user()

        if not query_list:
            logger.warning("âš ï¸ æœªè·å–åˆ°æŸ¥è¯¢åˆ—è¡¨ï¼Œé€€å‡ºæµ‹è¯•")
            logger.info("\næç¤ºï¼šä½ ä¹Ÿå¯ä»¥ç›´æ¥åœ¨ä»£ç ä¸­é…ç½®query_list:")
            logger.info('    query_list = ["é—®é¢˜1", "é—®é¢˜2"]')
            return

    # LLMæä¾›å•†é…ç½®
    provider = "openai"  # å¯é€‰: "openai", "azure", "ollama"

    # æœ€å¤§è¿­ä»£æ¬¡æ•°
    max_iterations = 3

    # ==================== æ‰§è¡Œæµ‹è¯• ====================

    logger.info("ğŸ“‹ æµ‹è¯•é…ç½®:")
    logger.info(f"   - æ–‡æ¡£åç§°: {doc_name}")
    logger.info(f"   - æŸ¥è¯¢æ•°é‡: {len(query_list)}")
    logger.info(f"   - LLM Provider: {provider}")
    logger.info(f"   - æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
    logger.info(f"   - å‘é‡æ•°æ®åº“è·¯å¾„: {VECTOR_DB_PATH}")

    # è¿è¡Œå¼‚æ­¥æ‰¹å¤„ç†
    try:
        results = asyncio.run(batch_test_queries(
            doc_name=doc_name,
            query_list=query_list,
            provider=provider,
            max_iterations=max_iterations
        ))

        if results:
            print_section("æµ‹è¯•å®Œæˆ")
            logger.info("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
            logger.info(f"ğŸ“Š å¤„ç†ç»“æœ: æˆåŠŸ {len(results['success'])} | æœªå®Œæˆ {len(results['incomplete'])} | å¤±è´¥ {len(results['error'])}")

    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        logger.error(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())


if __name__ == "__main__":
    main()
