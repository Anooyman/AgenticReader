"""
LLM Provider åˆ‡æ¢æµ‹è¯•

è¿™ä¸ªæµ‹è¯•å±•ç¤ºï¼š
1. ä¸åŒ Provider çš„åˆå§‹åŒ–ï¼ˆAzure, OpenAI, Ollamaï¼‰
2. Provider ä¿¡æ¯æŸ¥çœ‹
3. åŠ¨æ€åˆ‡æ¢ Provider
4. æµ‹è¯•æ¯ä¸ª Provider çš„åŸºæœ¬åŠŸèƒ½

è¿è¡Œæ–¹å¼ï¼š
    python tests/test_llm_providers.py

æ³¨æ„ï¼š
    - éœ€è¦é…ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡æ‰èƒ½æµ‹è¯•å¯¹åº”çš„ Provider
    - å¦‚æœæŸä¸ª Provider æœªé…ç½®ï¼Œä¼šè·³è¿‡è¯¥æµ‹è¯•
"""
import sys
import os
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.core.llm.client import LLMBase
from src.core.llm.providers import AzureLLMProvider, OpenAILLMProvider, OllamaLLMProvider
from src.agents.common.prompts import CommonRole

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)


def print_section(title):
    """æ‰“å°åˆ†éš”çº¿å’Œæ ‡é¢˜"""
    print("\n" + "="*70)
    print(f"  {title}")
    print("="*70 + "\n")


def test_provider_initialization():
    """æµ‹è¯•1ï¼šProvider åˆå§‹åŒ–"""
    print_section("æµ‹è¯•1ï¼šProvider åˆå§‹åŒ–")

    providers = {
        "openai": "OpenAI",
        "azure": "Azure OpenAI",
        "ollama": "Ollama (æœ¬åœ°æ¨¡å‹)"
    }

    successful_providers = []

    for provider_key, provider_name in providers.items():
        try:
            print(f"ğŸ“Œ å°è¯•åˆå§‹åŒ– {provider_name}...")
            llm_client = LLMBase(provider=provider_key)

            # è·å–providerä¿¡æ¯
            provider_info = llm_client.get_provider_info()

            print(f"âœ… {provider_name} åˆå§‹åŒ–æˆåŠŸï¼")
            print(f"   - Provider: {provider_info['provider']}")
            print(f"   - Chat Model: {provider_info['chat_model_type']}")
            print(f"   - Embedding Model: {provider_info['embedding_model_type']}")
            print()

            successful_providers.append(provider_key)

        except Exception as e:
            print(f"âš ï¸  {provider_name} åˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"   æç¤º: è¯·æ£€æŸ¥ {provider_key.upper()} ç›¸å…³çš„ç¯å¢ƒå˜é‡é…ç½®\n")

    if successful_providers:
        print(f"âœ… æˆåŠŸåˆå§‹åŒ–çš„ Provider: {', '.join(successful_providers)}")
        return True
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸåˆå§‹åŒ–çš„ Provider")
        return False


def test_provider_switching():
    """æµ‹è¯•2ï¼šProvider åŠ¨æ€åˆ‡æ¢"""
    print_section("æµ‹è¯•2ï¼šProvider åŠ¨æ€åˆ‡æ¢")

    try:
        # å…ˆåˆ›å»ºä¸€ä¸ª OpenAI client
        print("ğŸ“Œ åˆå§‹åŒ–ä¸º OpenAI Provider...")
        llm_client = LLMBase(provider="openai")

        initial_info = llm_client.get_provider_info()
        print(f"âœ… åˆå§‹ Provider: {initial_info['provider']}")
        print(f"   - Chat Model: {initial_info['chat_model_type']}")

        # å°è¯•åˆ‡æ¢åˆ°å…¶ä»–providerï¼ˆå¦‚æœå¯ç”¨ï¼‰
        print("\nğŸ“Œ å°è¯•åˆ‡æ¢åˆ° Azure Provider...")

        try:
            llm_client.update_provider_config(provider="azure")
            updated_info = llm_client.get_provider_info()

            print(f"âœ… åˆ‡æ¢æˆåŠŸï¼")
            print(f"   - æ–° Provider: {updated_info['provider']}")
            print(f"   - æ–° Chat Model: {updated_info['chat_model_type']}")

        except Exception as e:
            print(f"âš ï¸  åˆ‡æ¢åˆ° Azure å¤±è´¥: {e}")
            print("   æç¤º: Azure å¯èƒ½æœªé…ç½®ï¼Œè¿™æ˜¯æ­£å¸¸çš„")

        print("\nâœ… æµ‹è¯•2é€šè¿‡ï¼šProvider åˆ‡æ¢åŠŸèƒ½æ­£å¸¸ï¼")
        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•2å¤±è´¥: {e}")
        logger.exception("æµ‹è¯•2è¯¦ç»†é”™è¯¯:")
        return False


def test_provider_basic_call():
    """æµ‹è¯•3ï¼šæµ‹è¯•æ¯ä¸ªå¯ç”¨ Provider çš„åŸºæœ¬è°ƒç”¨"""
    print_section("æµ‹è¯•3ï¼šProvider åŸºæœ¬è°ƒç”¨æµ‹è¯•")

    providers_to_test = ["openai"]  # é»˜è®¤åªæµ‹è¯• OpenAI

    # æ£€æŸ¥æ˜¯å¦å¯ä»¥æµ‹è¯•å…¶ä»– provider
    try:
        from src.config.settings import LLM_CONFIG
        if LLM_CONFIG.get("api_key") and LLM_CONFIG.get("azure_endpoint"):
            providers_to_test.append("azure")
    except:
        pass

    test_message = "è¯·ç”¨ä¸€å¥è¯å›ç­”ï¼š1+1ç­‰äºå‡ ï¼Ÿ"
    successful_calls = 0

    for provider in providers_to_test:
        try:
            print(f"\nğŸ“Œ æµ‹è¯• {provider.upper()} Provider...")
            llm_client = LLMBase(provider=provider)

            print(f"ğŸ‘¤ ç”¨æˆ·: {test_message}")

            response = llm_client.call_llm_chain(
                role=CommonRole.CHAPTER_MATCHER,
                input_prompt=test_message,
                session_id=f"test_{provider}"
            )

            print(f"ğŸ¤– {provider.upper()} å›å¤: {response}")
            print(f"âœ… {provider.upper()} è°ƒç”¨æˆåŠŸï¼")

            successful_calls += 1

        except Exception as e:
            print(f"âš ï¸  {provider.upper()} è°ƒç”¨å¤±è´¥: {e}")

    if successful_calls > 0:
        print(f"\nâœ… æµ‹è¯•3é€šè¿‡ï¼š{successful_calls} ä¸ª Provider è°ƒç”¨æˆåŠŸï¼")
        return True
    else:
        print("\nâŒ æµ‹è¯•3å¤±è´¥ï¼šæ²¡æœ‰æˆåŠŸçš„ Provider è°ƒç”¨")
        return False


def test_provider_classes():
    """æµ‹è¯•4ï¼šç›´æ¥æµ‹è¯• Provider ç±»"""
    print_section("æµ‹è¯•4ï¼šProvider ç±»ç›´æ¥æµ‹è¯•")

    provider_classes = {
        "OpenAI": OpenAILLMProvider,
        "Azure": AzureLLMProvider,
        "Ollama": OllamaLLMProvider
    }

    successful_providers = []

    for name, provider_class in provider_classes.items():
        try:
            print(f"ğŸ“Œ æµ‹è¯• {name}LLMProvider ç±»...")
            provider = provider_class()

            # è·å–chat model
            chat_model = provider.get_chat_model()
            print(f"   - Chat Model: {type(chat_model).__name__}")

            # è·å–embedding model
            embedding_model = provider.get_embedding_model()
            print(f"   - Embedding Model: {type(embedding_model).__name__}")

            print(f"âœ… {name}LLMProvider ç±»æµ‹è¯•æˆåŠŸï¼\n")
            successful_providers.append(name)

        except Exception as e:
            print(f"âš ï¸  {name}LLMProvider ç±»æµ‹è¯•å¤±è´¥: {e}")
            print(f"   æç¤º: {name} å¯èƒ½æœªé…ç½®\n")

    if successful_providers:
        print(f"âœ… æµ‹è¯•4é€šè¿‡ï¼š{len(successful_providers)} ä¸ª Provider ç±»æµ‹è¯•æˆåŠŸ")
        return True
    else:
        print("âŒ æµ‹è¯•4å¤±è´¥ï¼šæ²¡æœ‰æˆåŠŸçš„ Provider ç±»")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸš€"*35)
    print("  AgenticReader - LLM Provider åˆ‡æ¢æµ‹è¯•")
    print("ğŸš€"*35)

    print("\nğŸ“‹ è¯´æ˜ï¼š")
    print("   - æœ¬æµ‹è¯•ä¼šå°è¯•æµ‹è¯•æ‰€æœ‰é…ç½®çš„ Provider")
    print("   - å¦‚æœæŸä¸ª Provider æœªé…ç½®ï¼Œä¼šæ˜¾ç¤ºè­¦å‘Šä½†ä¸å½±å“å…¶ä»–æµ‹è¯•")
    print("   - å»ºè®®è‡³å°‘é…ç½®ä¸€ä¸ª Provider (OpenAI æˆ– Azure)")

    results = []

    # è¿è¡Œæµ‹è¯•
    results.append(("Provideråˆå§‹åŒ–", test_provider_initialization()))
    results.append(("Provideråˆ‡æ¢", test_provider_switching()))
    results.append(("Providerè°ƒç”¨", test_provider_basic_call()))
    results.append(("Providerç±»æµ‹è¯•", test_provider_classes()))

    # æ±‡æ€»ç»“æœ
    print_section("æµ‹è¯•æ±‡æ€»")

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status} - {test_name}")

    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    main()
