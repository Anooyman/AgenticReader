"""
Reader å¹¶è¡Œå¤„ç†æ¨¡å—

æä¾›ä¸æ–‡æ¡£é˜…è¯»å™¨ç›¸å…³çš„å¹¶è¡Œå¤„ç†åŠŸèƒ½ï¼Œç”¨äºåŠ é€Ÿç« èŠ‚å¤„ç†ã€æ‘˜è¦ç”Ÿæˆç­‰è€—æ—¶æ“ä½œã€‚
"""

import asyncio
import logging
from typing import Any, Dict, List, Tuple

from src.utils.async_utils import run_async, parallel_process_with_filter
from src.config.prompts.reader_prompts import ReaderRole

logger = logging.getLogger(__name__)


class ChapterProcessor:
    """
    ç« èŠ‚å¹¶è¡Œå¤„ç†å™¨
    
    å°è£…ç« èŠ‚å¤„ç†çš„å¸¸è§å¹¶è¡Œæ“ä½œæ¨¡å¼ï¼Œä¸ ReaderBase é…åˆä½¿ç”¨ã€‚
    """
    
    def __init__(self, llm_client: Any, max_concurrent: int = 5):
        """
        åˆå§‹åŒ–ç« èŠ‚å¤„ç†å™¨
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹ï¼ˆéœ€è¦æœ‰ async_call_llm_chain æ–¹æ³•ï¼‰
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
        """
        self.llm_client = llm_client
        self.max_concurrent = max_concurrent
    
    async def process_chapters_summary_and_refactor(
        self,
        agenda_data_list: List[Dict[str, Any]],
        summary_role: Any = ReaderRole.SUMMARY,
        refactor_role: Any = ReaderRole.REFACTOR
    ) -> List[Tuple[str, str, str, Any, Any]]:
        """
        å¹¶è¡Œå¤„ç†ç« èŠ‚çš„æ€»ç»“å’Œé‡æ„
        
        å¯¹æ¯ä¸ªç« èŠ‚ï¼š
        1. å¹¶è¡Œæ‰§è¡Œ summary å’Œ refactor ä¸¤ä¸ª LLM è°ƒç”¨
        2. å¤šä¸ªç« èŠ‚ä¹‹é—´ä¹Ÿæ˜¯å¹¶è¡Œå¤„ç†
        
        Args:
            agenda_data_list: ç« èŠ‚æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« title, data, pages
            summary_role: æ€»ç»“è§’è‰²é…ç½®
            refactor_role: é‡æ„è§’è‰²é…ç½®
            
        Returns:
            List[Tuple[title, summary, refactor_content, pages, data]]
        """
        async def process_single_chapter(agenda_data: Dict[str, Any]) -> Tuple[str, str, str, Any, Any]:
            title = agenda_data.get("title")
            data = agenda_data.get("data")
            pages = agenda_data.get("pages")
            
            content_values = list(data.values()) if isinstance(data, dict) else data
            
            # å¹¶è¡Œæ‰§è¡Œæ€»ç»“å’Œé‡æ„
            summary_prompt = f"è¯·æ€»ç»“{title}çš„å†…å®¹ï¼Œä¸Šä¸‹æ–‡å¦‚ä¸‹ï¼š{content_values}"
            refactor_prompt = f"è¯·é‡æ–°æ•´ç†Contentä¸­çš„å†…å®¹ã€‚\n\n Contentï¼š{content_values}"
            
            summary, refactor_content = await asyncio.gather(
                self.llm_client.async_call_llm_chain(summary_role, summary_prompt, "summary"),
                self.llm_client.async_call_llm_chain(refactor_role, refactor_prompt, "refactor")
            )
            
            logger.info(f"ç« èŠ‚ '{title}' å¤„ç†å®Œæˆ")
            return title, summary or "", refactor_content or "", pages, data
        
        results = await parallel_process_with_filter(
            agenda_data_list,
            process_single_chapter,
            self.max_concurrent
        )
        
        return results
    
    async def process_detail_summaries(
        self,
        chapters: List[Dict[str, Any]],
        answer_role: Any = ReaderRole.ANSWER
    ) -> List[Tuple[str, str]]:
        """
        å¹¶è¡Œç”Ÿæˆè¯¦ç»†æ‘˜è¦
        
        Args:
            chapters: ç« èŠ‚æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« title, context_data, query
            answer_role: å›ç­”è§’è‰²é…ç½®
            
        Returns:
            List[Tuple[title, answer]]
        """
        async def process_single_summary(chapter_data: Dict[str, Any]) -> Tuple[str, str]:
            title = chapter_data['title']
            context_data = chapter_data['context_data']
            query = chapter_data['query']
            
            logger.info(f"å¹¶è¡Œå¤„ç†è¯¦ç»†æ‘˜è¦: {title}")
            
            input_prompt = (
                f"è¯·ç»“åˆæ£€ç´¢å›æ¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯(Context data)å›ç­”å®¢æˆ·é—®é¢˜\n\n"
                f"===== \n\nQuestion: {query}\n\n"
                f"===== \n\nContext data: {context_data}"
            )
            
            try:
                answer = await self.llm_client.async_call_llm_chain(
                    answer_role, input_prompt, "answer"
                )
                return (title, answer if answer and answer.strip() else "")
            except Exception as e:
                logger.error(f"ç”Ÿæˆæ ‡é¢˜ '{title}' çš„æ‘˜è¦æ—¶å‡ºé”™: {e}")
                return (title, "")
        
        results = await parallel_process_with_filter(
            chapters,
            process_single_summary,
            self.max_concurrent
        )
        
        return results


def run_parallel_chapter_processing(
    llm_client: Any,
    agenda_data_list: List[Dict[str, Any]],
    summary_role: Any = ReaderRole.SUMMARY,
    refactor_role: Any = ReaderRole.REFACTOR,
    max_concurrent: int = 5
) -> List[Tuple[str, str, str, Any, Any]]:
    """
    åŒæ­¥æ¥å£ï¼šå¹¶è¡Œå¤„ç†ç« èŠ‚çš„æ€»ç»“å’Œé‡æ„
    
    è¿™æ˜¯ä¸€ä¸ªä¾¿æ·çš„åŒæ­¥åŒ…è£…å‡½æ•°ï¼Œå†…éƒ¨ä½¿ç”¨å¼‚æ­¥å¹¶è¡Œå¤„ç†ã€‚
    
    Args:
        llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹ï¼ˆéœ€è¦æœ‰ async_call_llm_chain æ–¹æ³•ï¼‰
        agenda_data_list: ç« èŠ‚æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«:
            - title: ç« èŠ‚æ ‡é¢˜
            - data: ç« èŠ‚æ•°æ®å­—å…¸ {page: content}
            - pages: é¡µç åˆ—è¡¨
        summary_role: æ€»ç»“è§’è‰²é…ç½®
        refactor_role: é‡æ„è§’è‰²é…ç½®
        max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤5ï¼Œé¿å…APIé™æµï¼‰
        
    Returns:
        List[Tuple[title, summary, refactor_content, pages, data]]
        
    Example:
        results = run_parallel_chapter_processing(
            llm_client=pdf_reader,
            agenda_data_list=agenda_data_list,
            max_concurrent=5
        )
        for title, summary, refactor, pages, data in results:
            # å¤„ç†ç»“æœ...
    """
    processor = ChapterProcessor(llm_client, max_concurrent)
    
    return run_async(
        processor.process_chapters_summary_and_refactor(
            agenda_data_list, summary_role, refactor_role
        )
    )


def run_parallel_detail_summaries(
    llm_client: Any,
    chapters: List[Dict[str, Any]],
    answer_role: Any = ReaderRole.ANSWER,
    max_concurrent: int = 5
) -> List[Tuple[str, str]]:
    """
    åŒæ­¥æ¥å£ï¼šå¹¶è¡Œç”Ÿæˆè¯¦ç»†æ‘˜è¦
    
    è¿™æ˜¯ä¸€ä¸ªä¾¿æ·çš„åŒæ­¥åŒ…è£…å‡½æ•°ï¼Œå†…éƒ¨ä½¿ç”¨å¼‚æ­¥å¹¶è¡Œå¤„ç†ã€‚
    
    Args:
        llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹ï¼ˆéœ€è¦æœ‰ async_call_llm_chain æ–¹æ³•ï¼‰
        chapters: ç« èŠ‚æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«:
            - title: ç« èŠ‚æ ‡é¢˜
            - context_data: ä¸Šä¸‹æ–‡æ•°æ®
            - query: æŸ¥è¯¢é—®é¢˜
        answer_role: å›ç­”è§’è‰²é…ç½®
        max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤5ï¼Œé¿å…APIé™æµï¼‰
        
    Returns:
        List[Tuple[title, answer]]
        
    Example:
        chapters = [
            {'title': 'ç¬¬ä¸€ç« ', 'context_data': [...], 'query': 'æ€»ç»“å†…å®¹'},
            {'title': 'ç¬¬äºŒç« ', 'context_data': [...], 'query': 'æ€»ç»“å†…å®¹'},
        ]
        results = run_parallel_detail_summaries(
            llm_client=pdf_reader,
            chapters=chapters,
            max_concurrent=5
        )
        for title, answer in results:
            # å¤„ç†ç»“æœ...
    """
    processor = ChapterProcessor(llm_client, max_concurrent)
    
    return run_async(
        processor.process_detail_summaries(chapters, answer_role)
    )


class PageExtractor:
    """
    PDFé¡µé¢å¹¶è¡Œæå–å™¨
    
    å°è£…PDFé¡µé¢å›¾ç‰‡å†…å®¹çš„å¹¶è¡Œæå–æ“ä½œã€‚
    """
    
    def __init__(self, llm_client: Any, extract_prompt: str, max_concurrent: int = 5):
        """
        åˆå§‹åŒ–é¡µé¢æå–å™¨
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹ï¼ˆéœ€è¦æœ‰ chat_model.invoke æ–¹æ³•ï¼‰
            extract_prompt: å›¾ç‰‡å†…å®¹æå–çš„æç¤ºè¯
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
        """
        self.llm_client = llm_client
        self.extract_prompt = extract_prompt
        self.max_concurrent = max_concurrent
    
    async def extract_pages_parallel(
        self,
        image_paths: List[str]
    ) -> List[Dict[str, Any]]:
        """
        å¹¶è¡Œæå–å¤šé¡µå›¾ç‰‡å†…å®¹
        
        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆå·²æŒ‰é¡µç æ’åºï¼‰
            
        Returns:
            æå–ç»“æœåˆ—è¡¨ï¼ˆæŒ‰é¡µç æ’åºï¼‰ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {"data": str, "page": str}
        """
        import base64
        import re
        from langchain_core.messages import HumanMessage
        
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def extract_single_page(idx: int, path: str) -> Dict[str, Any]:
            """æå–å•é¡µå†…å®¹"""
            async with semaphore:
                encoded_image = None
                try:
                    # è¯»å–å¹¶ç¼–ç å›¾ç‰‡æ–‡ä»¶
                    with open(path, 'rb') as img_file:
                        img_data = img_file.read()
                        encoded_image = base64.b64encode(img_data).decode('ascii')
                        del img_data

                    # æ„å»ºLLMæ¶ˆæ¯
                    message = [HumanMessage(
                        content=[
                            {
                                "type": "text",
                                "text": self.extract_prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{encoded_image}"}
                            },
                        ],
                    )]

                    # å¼‚æ­¥è°ƒç”¨LLMå¤„ç†
                    loop = asyncio.get_event_loop()
                    response = await loop.run_in_executor(
                        None, self.llm_client.chat_model.invoke, message
                    )

                    if not response or not response.content:
                        logger.warning(f"é¡µé¢ {idx + 1} LLMè¿”å›ç©ºå†…å®¹")
                        return None

                    # æå–é¡µç 
                    match = re.search(r'page_(\d+)\.png', path)
                    page_num = match.group(1) if match else str(idx + 1)

                    return {
                        "data": response.content,
                        "page": page_num,
                        "_idx": idx  # ç”¨äºæ’åº
                    }

                except FileNotFoundError:
                    logger.error(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {path}")
                    return None
                except MemoryError:
                    logger.error(f"å¤„ç†å›¾ç‰‡æ—¶å†…å­˜ä¸è¶³: {path}")
                    import gc
                    gc.collect()
                    return None
                except Exception as e:
                    logger.error(f"å¤„ç†å›¾ç‰‡ {path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    return None
                finally:
                    if encoded_image is not None:
                        del encoded_image

        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [extract_single_page(idx, path) for idx, path in enumerate(image_paths)]
        
        logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡Œæå– {len(tasks)} é¡µå†…å®¹ (æœ€å¤§å¹¶å‘: {self.max_concurrent})")
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        all_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        results = []
        for result in all_results:
            if isinstance(result, Exception):
                logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {result}")
            elif result is not None:
                results.append(result)
        
        # æŒ‰åŸå§‹é¡ºåºæ’åº
        results.sort(key=lambda x: x.get('_idx', 0))
        
        # ç§»é™¤ä¸´æ—¶æ’åºå­—æ®µ
        for r in results:
            r.pop('_idx', None)
        
        logger.info(f"âœ… å¹¶è¡Œæå–å®Œæˆ: æˆåŠŸ {len(results)} é¡µ, å¤±è´¥ {len(image_paths) - len(results)} é¡µ")
        
        return results


def run_parallel_page_extraction(
    llm_client: Any,
    image_paths: List[str],
    extract_prompt: str,
    max_concurrent: int = 5
) -> List[Dict[str, Any]]:
    """
    åŒæ­¥æ¥å£ï¼šå¹¶è¡Œæå–PDFé¡µé¢å›¾ç‰‡å†…å®¹
    
    è¿™æ˜¯ä¸€ä¸ªä¾¿æ·çš„åŒæ­¥åŒ…è£…å‡½æ•°ï¼Œå†…éƒ¨ä½¿ç”¨å¼‚æ­¥å¹¶è¡Œå¤„ç†ã€‚
    
    Args:
        llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹ï¼ˆéœ€è¦æœ‰ chat_model.invoke æ–¹æ³•ï¼‰
        image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆåº”å·²æŒ‰é¡µç æ’åºï¼‰
        extract_prompt: å›¾ç‰‡å†…å®¹æå–çš„æç¤ºè¯
        max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤5ï¼Œé¿å…APIé™æµï¼‰
        
    Returns:
        æå–ç»“æœåˆ—è¡¨ï¼ˆæŒ‰é¡µç æ’åºï¼‰ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {"data": str, "page": str}
        
    Example:
        results = run_parallel_page_extraction(
            llm_client=pdf_reader,
            image_paths=sorted_image_paths,
            extract_prompt="è¯·æå–å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹",
            max_concurrent=5
        )
        for item in results:
            print(f"Page {item['page']}: {item['data'][:100]}...")
    """
    extractor = PageExtractor(llm_client, extract_prompt, max_concurrent)
    
    return run_async(
        extractor.extract_pages_parallel(image_paths)
    )
