import json
import os
import re
import logging
from typing import List, Dict, Any

from langchain_core.messages import AIMessage

from src.readers.retrieval import RetrivalAgent
from src.readers.base import ReaderBase
from src.config.settings import (
    PDF_IMAGE_PATH,
    PDF_PATH,
    PDF_IMAGE_CONFIG,
)
from src.config.constants import ReaderConstants
from src.config.prompts.reader_prompts import ReaderRole, READER_PROMPTS
from src.utils.helpers import *
from src.readers.parallel_processor import run_parallel_page_extraction
from src.core.vector_db.vector_db_client import VectorDBClient

# Setup logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

class PDFReader(ReaderBase):
    """
    PDFReader ç±»ç”¨äºå¤„ç† PDF æ–‡ä»¶ï¼ŒåŒ…æ‹¬ï¼š
    1. PDF è½¬å›¾ç‰‡
    2. å›¾ç‰‡å†…å®¹æå–
    3. è°ƒç”¨ LLM è¿›è¡Œå†…å®¹åˆ†æä¸æ€»ç»“
    4. æ„å»ºå’Œä½¿ç”¨å‘é‡æ•°æ®åº“
    5. æ”¯æŒäº¤äº’å¼é—®ç­”

    This class provides a full pipeline for PDF document analysis, including image conversion, content extraction, LLM-based summarization, vector DB construction, and interactive Q&A.
    """
    def __init__(self, provider: str = "openai", pdf_preset: str = "high") -> None:
        """
        åˆå§‹åŒ– PDFReader å¯¹è±¡ï¼Œæ”¯æŒå¤š LLM providerã€‚
        Args:
            provider: LLMæœåŠ¡æä¾›å•†ï¼Œå¯é€‰ï¼š'azure'ã€'openai'ã€'ollama'
            pdf_preset: PDFè½¬å›¾ç‰‡è´¨é‡é¢„è®¾ï¼Œå¯é€‰ï¼š"fast", "balanced", "high", "ultra"
            pdf_dpi: è‡ªå®šä¹‰DPIåˆ†è¾¨ç‡ï¼ˆä¼˜å…ˆçº§é«˜äºpresetï¼‰
            pdf_quality: è‡ªå®šä¹‰è´¨é‡çº§åˆ«ï¼ˆä¼˜å…ˆçº§é«˜äºpresetï¼‰

        PDFè´¨é‡é¢„è®¾è¯´æ˜ï¼š
        - fast: 150 DPI + low quality (å¿«é€Ÿå¤„ç†ï¼Œé€‚åˆé¢„è§ˆ)
        - balanced: 200 DPI + medium quality (å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡)
        - high: 300 DPI + high quality (é«˜è´¨é‡ï¼Œæ¨èç”¨äºOCR)
        - ultra: 600 DPI + ultra quality (è¶…é«˜è´¨é‡ï¼Œé€‚åˆç²¾ç»†æ–‡æ¡£)
        """
        super().__init__(provider)
        self.pdf_image_path = PDF_IMAGE_PATH
        self.pdf_path = PDF_PATH
        self.pdf_raw_data = None
        self.chunk_count = ReaderConstants.DEFAULT_CHUNK_COUNT  # æ¯ä¸ªåˆ†å—çš„å¤§å°
        self.retrieval_data_agent = None

        # é…ç½®PDFè½¬å›¾ç‰‡å‚æ•°
        try:
            if pdf_preset in PDF_IMAGE_CONFIG.get("presets", {}):
                # ä½¿ç”¨é¢„è®¾é…ç½®
                preset_config = PDF_IMAGE_CONFIG["presets"][pdf_preset]
                self.pdf_dpi = preset_config.get("dpi", PDF_IMAGE_CONFIG.get("dpi", 300))
                # æ³¨æ„ï¼šé¢„è®¾ä¸­ä½¿ç”¨çš„æ˜¯scaleï¼Œä¸æ˜¯qualityå­—ç¬¦ä¸²
                self.pdf_quality = pdf_preset  # ç›´æ¥ä½¿ç”¨é¢„è®¾åç§°ä½œä¸ºquality
                logger.info(f"ä½¿ç”¨PDFè½¬å›¾ç‰‡é¢„è®¾'{pdf_preset}': DPI={self.pdf_dpi}, è´¨é‡çº§åˆ«={self.pdf_quality}")
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                self.pdf_dpi = PDF_IMAGE_CONFIG.get("dpi", 300)
                self.pdf_quality = PDF_IMAGE_CONFIG.get("quality", "high")
                logger.info(f"ä½¿ç”¨é»˜è®¤PDFè½¬å›¾ç‰‡é…ç½®: DPI={self.pdf_dpi}, è´¨é‡={self.pdf_quality}")
        except Exception as e:
            # å›é€€åˆ°å®‰å…¨çš„é»˜è®¤å€¼
            logger.warning(f"PDFå›¾ç‰‡é…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            self.pdf_dpi = 300
            self.pdf_quality = "high"

        for path in [self.pdf_image_path, self.pdf_path]:
            makedir(path)

    def extract_pdf_data(self, pdf_file_path: str) -> List[Dict[str, Any]]:
        """
        å°† PDF è½¬ä¸ºå›¾ç‰‡å¹¶ç”¨ LLM æå–æ¯é¡µå†…å®¹ï¼Œç»“æœä¿å­˜ä¸º JSON
        æ”¯æŒå¹¶è¡Œå¤„ç†ä»¥åŠ é€Ÿæå–è¿‡ç¨‹

        Args:
            pdf_file_path: PDF æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„å’Œæ‰©å±•åï¼‰

        Returns:
            æ¯é¡µæå–çš„å†…å®¹åˆ—è¡¨

        Raises:
            ValueError: è¾“å…¥å‚æ•°æ— æ•ˆ
            FileNotFoundError: PDFæ–‡ä»¶ä¸å­˜åœ¨
            Exception: å¤„ç†è¿‡ç¨‹ä¸­çš„å…¶ä»–é”™è¯¯
        """
        # è¾“å…¥éªŒè¯
        if not pdf_file_path or not isinstance(pdf_file_path, str):
            raise ValueError("PDFæ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²")

        # æ„å»ºè·¯å¾„
        output_folder_path = os.path.join(self.pdf_image_path, pdf_file_path)
        pdf_path = os.path.join(self.pdf_path, f"{pdf_file_path}.pdf")
        output_json_path = os.path.join(self.json_data_path, f"{pdf_file_path}.json")

        # éªŒè¯PDFæ–‡ä»¶å­˜åœ¨
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")

        logger.info(f"å¼€å§‹å¤„ç†PDF: {pdf_path}")

        try:
            # è½¬æ¢PDFä¸ºå›¾ç‰‡
            conversion_stats = pdf_to_images(
                pdf_path, output_folder_path,
                dpi=self.pdf_dpi, quality=self.pdf_quality
            )
            logger.info(f"PDFè½¬å›¾ç‰‡å®Œæˆ: æˆåŠŸ{conversion_stats['successful_pages']}é¡µ")

            # è·å–å›¾ç‰‡è·¯å¾„å¹¶æ’åº
            image_paths = read_images_in_directory(output_folder_path)
            if not image_paths:
                logger.error("æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„å›¾ç‰‡æ–‡ä»¶")
                return []

            # å®‰å…¨çš„é¡µç æ’åº
            def safe_page_sort(path):
                try:
                    match = re.search(r'page_(\d+)\.png', path)
                    return int(match.group(1)) if match else float('inf')
                except:
                    return float('inf')

            sorted_image_paths = sorted(image_paths, key=safe_page_sort)
            logger.info(f"æ‰¾åˆ° {len(sorted_image_paths)} ä¸ªå›¾ç‰‡æ–‡ä»¶å¾…å¤„ç†")

            # ğŸ”¥ ä½¿ç”¨å¹¶è¡Œå¤„ç†æå–å›¾ç‰‡å†…å®¹
            extract_prompt = READER_PROMPTS.get(
                ReaderRole.IMAGE_EXTRACT, "è¯·æå–å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹"
            )
            image_content_list = run_parallel_page_extraction(
                llm_client=self,
                image_paths=sorted_image_paths,
                extract_prompt=extract_prompt,
                max_concurrent=5
            )

            # ä¿å­˜æå–ç»“æœåˆ°JSONæ–‡ä»¶
            if image_content_list:
                try:
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    os.makedirs(os.path.dirname(output_json_path), exist_ok=True)

                    with open(output_json_path, 'w', encoding='utf-8') as file:
                        json.dump(image_content_list, file, ensure_ascii=False, indent=2)

                    logger.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {output_json_path}")
                    logger.info(f"æå–ç»Ÿè®¡: æˆåŠŸ{len(image_content_list)}é¡µ")
                except Exception as e:
                    logger.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {e}")
                    raise
            else:
                logger.error("æ²¡æœ‰æˆåŠŸæå–ä»»ä½•é¡µé¢å†…å®¹")

            return image_content_list

        except Exception as e:
            logger.error(f"PDFæ•°æ®æå–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise

    def split_pdf_raw_data(self):
        """
        å°† self.pdf_raw_data æŒ‰ç…§ self.chunk_count è¿›è¡Œåˆ‡åˆ†ã€‚
        Split self.pdf_raw_data into chunks of size self.chunk_count.
        Returns:
            List[List[Any]]: åˆ‡åˆ†åçš„æ•°æ®å—åˆ—è¡¨ã€‚
        """
        if not isinstance(self.pdf_raw_data, list):
            logger.error("pdf_raw_data ä¸æ˜¯ listï¼Œæ— æ³•åˆ‡åˆ†ã€‚")
            return []
        chunks = [self.pdf_raw_data[i:i + self.chunk_count] for i in range(0, len(self.pdf_raw_data), self.chunk_count)]
        logger.info(f"å·²å°† pdf_raw_data åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªå—ï¼Œæ¯å—æœ€å¤š {self.chunk_count} æ¡ã€‚")
        return chunks

    def process_pdf(self, pdf_file_path: str, save_data_flag: bool=True) -> Any:
        """
        ä¸»æµç¨‹ï¼šè¯»å– PDF æ•°æ®ï¼Œæå–ç»“æ„ï¼Œåˆ†ç« èŠ‚æ€»ç»“ï¼Œæœ€ç»ˆç”Ÿæˆè¯¦ç»†å›ç­”ã€‚
        Main pipeline: read PDF data, extract structure, summarize by section, and generate final answer.
        Args:
            pdf_file_path (str): PDF æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰ã€‚
        Returns:
            None
        """
        vector_db_path = os.path.join(f"{self.vector_db_path}/{pdf_file_path}_data_index")
        self.vector_db_obj = VectorDBClient(vector_db_path, embedding_model=self.embedding_model)
        logger.info(f"å¼€å§‹å¤„ç†PDFä¸»æµç¨‹: {pdf_file_path}")
        try:
            with open(f"{self.json_data_path}/{pdf_file_path}.json", 'r', encoding='utf-8') as f:
                self.pdf_raw_data = json.load(f)
        except Exception as e:
            logger.warning(f"è¯»å–æœ¬åœ°JSONå¤±è´¥ï¼Œå°†é‡æ–°æå–: {e}")
            self.pdf_raw_data = self.extract_pdf_data(pdf_file_path)
        if self.vector_db_obj.vector_db is not None:
            # å‘é‡æ•°æ®åº“å·²åœ¨åˆå§‹åŒ–æ—¶è‡ªåŠ¨åŠ è½½
            self.get_data_from_vector_db()
        else:
            # æŒ‰ chunk_count åˆ‡åˆ† pdf_raw_dataï¼Œä¾¿äºå¤§æ–‡ä»¶åˆ†æ‰¹å¤„ç†
            chunks = self.split_pdf_raw_data()
            self.get_data_from_json_dict(chunks, self.pdf_raw_data)

        if save_data_flag:
            self.generate_output_file(pdf_file_path, self.raw_data_dict)

        logger.info(f"PDFå¤„ç†æµç¨‹ç»“æŸã€‚")

    def chat(self, input_prompt: str) -> Any:
        """
        é’ˆå¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œå¯¹è¯ã€‚
        Interactive chat for user input.
        Args:
            input_prompt (str): ç”¨æˆ·è¾“å…¥ã€‚
        Returns:
            Any: å›ç­”å†…å®¹ã€‚
        """
        #response = self.call_llm_chain(
        #    ReaderRole.QUERY_REWRITE,
        #    input_prompt,
        #    "chat",
        #)
        ##self.delete_last_message_in_history(session_id="chat")
        #print("====="*10)
        #print(response)

        if self.retrieval_data_agent is None:
            self.retrieval_data_agent = RetrivalAgent(
                agenda_dict=self.agenda_dict,
                provider=self.provider,
                vector_db_obj=self.vector_db_obj,
            )
        context_data = self.retrieval_data_agent.retrieval_data(input_prompt)

        answer = self.get_answer(context_data, input_prompt)

        logger.info(f"å¯¹è¯å›ç­”ç”Ÿæˆå®Œæ¯•ã€‚")
        return answer

    def main(self, pdf_file_path: str, save_data_flag: bool=True) -> None:
        """
        ä¸»å…¥å£ï¼Œå¯åŠ¨ PDF å¤„ç†å’Œå¯¹è¯ã€‚
        Main entry point, starts PDF processing and interactive chat.
        Args:
            pdf_file_path (str): PDF æ–‡ä»¶åã€‚
            save_data_flag (bool): æ˜¯å¦éœ€è¦å­˜å‚¨æ–‡ä»¶
        Returns:
            None
        """
        logger.info(f"å¯åŠ¨ä¸»æµç¨‹ï¼Œå¤„ç† PDF æ–‡ä»¶: {pdf_file_path}")

        self.process_pdf(get_pdf_name(pdf_file_path), save_data_flag)
        while True:
            user_input = input("You: ")
            if user_input.lower() in ["é€€å‡º", "å†è§", "bye", "exit", "quit"]:
                print("Chatbot: å†è§ï¼æœŸå¾…ä¸‹æ¬¡ä¸æ‚¨å¯¹è¯ã€‚")
                logger.info("ç”¨æˆ·ä¸»åŠ¨é€€å‡ºå¯¹è¯ã€‚")
                break

            answer = self.chat(user_input)
            self.add_message_to_history(session_id="chat", message=AIMessage(answer))
            print(f"User: {user_input}")
            print(f"ChatBot: {answer}")
            print("======"*10)