"""
Retrieval Agent Module

This module provides the RetrivalAgent class for intelligent document retrieval
from vector databases using both context-based and title-based search strategies.
"""
from typing import List, Dict, Any

from src.core.llm.client import LLMBase
from src.config.prompts.reader_prompts import ReaderRole
from src.config.tools.retrieval_tools import get_enabled_tools, format_tool_description, format_all_tools_for_llm
from src.core.vector_db.vector_db_client import VectorDBClient
from src.utils.helpers import *

# Setup logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

# ä½¿ç”¨LangChainåŸç”Ÿçš„@toolè£…é¥°å™¨ï¼Œä¸éœ€è¦è‡ªå®šä¹‰

class RetrivalAgent(LLMBase):
    """
    æ™ºèƒ½æ£€ç´¢ä»£ç†ç±»
    
    è¯¥ç±»ç»§æ‰¿è‡ªLLMBaseï¼Œæä¾›åŸºäºå‘é‡æ•°æ®åº“çš„æ™ºèƒ½æ–‡æ¡£æ£€ç´¢åŠŸèƒ½ã€‚
    æ”¯æŒä¸¤ç§æ£€ç´¢ç­–ç•¥ï¼šåŸºäºä¸Šä¸‹æ–‡çš„è¯­ä¹‰æ£€ç´¢å’ŒåŸºäºæ ‡é¢˜çš„ç²¾ç¡®æ£€ç´¢ã€‚
    
    Attributes:
        agenda_dict (Dict[str, Any]): è®®ç¨‹å­—å…¸ï¼ŒåŒ…å«æ–‡æ¡£ç»“æ„ä¿¡æ¯
        vector_db_obj (VectorDBClient): å‘é‡æ•°æ®åº“å®¢æˆ·ç«¯å®ä¾‹
        retrieval_data_dict (Dict[str, Any]): æ£€ç´¢ç»“æœç¼“å­˜å­—å…¸
    """

    def __init__(self, agenda_dict: Dict[str, Any], provider: str = "openai", vector_db_obj: VectorDBClient = None) -> None:
        """
        åˆå§‹åŒ–æ£€ç´¢ä»£ç†
        
        Args:
            agenda_dict (Dict[str, Any]): æ–‡æ¡£è®®ç¨‹å­—å…¸
            provider (str, optional): LLMæä¾›å•†. Defaults to "openai".
            vector_db_obj (VectorDBClient, optional): å‘é‡æ•°æ®åº“å®¢æˆ·ç«¯. Defaults to None.
        """
        logger.info(f"æ­£åœ¨åˆå§‹åŒ–æ£€ç´¢ä»£ç†ï¼ŒLLMæä¾›å•†: {provider}")
        super().__init__(provider)
        self.agenda_dict = agenda_dict
        self.vector_db_obj = vector_db_obj
        self.retrieval_data_dict: Dict[str, Any] = {}
        
        # éªŒè¯åˆå§‹åŒ–å‚æ•°
        if not agenda_dict:
            logger.warning("è®®ç¨‹å­—å…¸ä¸ºç©ºï¼Œå¯èƒ½å½±å“æ ‡é¢˜æ£€ç´¢åŠŸèƒ½")
        if not vector_db_obj:
            logger.warning("å‘é‡æ•°æ®åº“å®¢æˆ·ç«¯æœªæä¾›ï¼Œæ£€ç´¢åŠŸèƒ½å°†ä¸å¯ç”¨")
        else:
            logger.info("æ£€ç´¢ä»£ç†åˆå§‹åŒ–å®Œæˆ")

    def _build_retrieval_tools(self) -> Dict[str, Dict[str, Any]]:
        """
        ä»é…ç½®æ–‡ä»¶æ„å»ºæ£€ç´¢å·¥å…·å­—å…¸ï¼ˆReAct æ¡†æ¶ï¼‰

        å·¥å…·é…ç½®æ¥æºï¼šsrc/config/tools/retrieval_tools.py

        æ·»åŠ æ–°å·¥å…·çš„æ­¥éª¤ï¼š
        1. åœ¨ src/config/tools/retrieval_tools.py ä¸­æ·»åŠ å·¥å…·é…ç½®
        2. åœ¨æœ¬ç±»ä¸­å®ç°å¯¹åº”çš„æ–¹æ³•ï¼ˆæ–¹æ³•åä¸é…ç½®ä¸­çš„ method_name ä¸€è‡´ï¼‰
        3. å·¥å…·ä¼šè‡ªåŠ¨åŠ è½½ï¼Œæ— éœ€ä¿®æ”¹æ­¤æ–¹æ³•

        Returns:
            Dict[str, Dict[str, Any]]: å·¥å…·å­—å…¸ï¼Œkey ä¸ºå·¥å…·åç§°ï¼Œvalue åŒ…å«å·¥å…·çš„è¯¦ç»†ä¿¡æ¯
        """
        # ä»é…ç½®æ–‡ä»¶è·å–å¯ç”¨çš„å·¥å…·
        enabled_tools_config = get_enabled_tools()

        # æ„å»ºå·¥å…·å­—å…¸
        tools = {}
        for tool_config in enabled_tools_config:
            tool_name = tool_config["name"]
            method_name = tool_config["method_name"]

            # è·å–å¯¹åº”çš„æ–¹æ³•
            if hasattr(self, method_name):
                tool_method = getattr(self, method_name)

                # æ„å»ºå·¥å…·ä¿¡æ¯
                tools[tool_name] = {
                    "name": tool_name,
                    "description": tool_config["description"],
                    "parameters": tool_config["parameters"],
                    "function": tool_method,
                    "priority": tool_config.get("priority", 999),
                }

                logger.debug(f"å·²åŠ è½½å·¥å…·: {tool_name} (æ–¹æ³•: {method_name})")
            else:
                logger.warning(f"å·¥å…· '{tool_name}' é…ç½®çš„æ–¹æ³• '{method_name}' åœ¨ RetrievalAgent ä¸­æœªæ‰¾åˆ°ï¼Œå·²è·³è¿‡")

        logger.info(f"æˆåŠŸåŠ è½½ {len(tools)} ä¸ªæ£€ç´¢å·¥å…·")
        return tools

    def retrieval_data(self, query: str, max_iterations: int = 5, max_context_length: int = 10000, reset_history: bool = True) -> List[str]:
        """
        ä¸»æ£€ç´¢æ–¹æ³• - ä½¿ç”¨ ReAct æ¡†æ¶æ™ºèƒ½é€‰æ‹©æ£€ç´¢ç­–ç•¥å¹¶è¯„ä¼°ç»“æœ

        è¯¥æ–¹æ³•æ˜¯ RetrivalAgent çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œä½¿ç”¨ ReAct (Reasoning + Acting) æ¡†æ¶ï¼Œ
        é€šè¿‡ LLM æ™ºèƒ½åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œå†³å®šä½¿ç”¨å“ªä¸ªæ£€ç´¢å·¥å…·ï¼Œæ‰§è¡Œæ£€ç´¢ï¼Œè¯„ä¼°ç»“æœæ˜¯å¦è¶³å¤Ÿï¼Œ
        å¹¶å†³å®šæ˜¯å¦ç»§ç»­æ£€ç´¢ã€‚

        å®Œæ•´ ReAct å·¥ä½œæµç¨‹ï¼š
        1. Thought: LLM åˆ†ææŸ¥è¯¢ï¼Œå†³å®šä½¿ç”¨å“ªä¸ªå·¥å…·
        2. Action: æ‰§è¡Œé€‰å®šçš„å·¥å…·
        3. Observation: è®°å½•å·¥å…·æ‰§è¡Œç»“æœ
        4. Evaluation: LLM è¯„ä¼°å½“å‰æ£€ç´¢ç»“æœæ˜¯å¦è¶³å¤Ÿå›ç­”é—®é¢˜
        5. Decision: æ ¹æ®è¯„ä¼°å†³å®šæ˜¯å¦ç»§ç»­æ£€ç´¢ï¼ˆé‡å¤ 1-4ï¼‰

        å¯ç”¨å·¥å…·ï¼š
        - retrieval_data_by_title: åŸºäºæ ‡é¢˜çš„ç²¾ç¡®æ£€ç´¢
        - retrieval_data_by_context: åŸºäºè¯­ä¹‰çš„ä¸Šä¸‹æ–‡æ£€ç´¢
        - get_document_structure: è·å–æ–‡æ¡£ç›®å½•ç»“æ„

        å»é‡æœºåˆ¶ï¼š
        - ä½¿ç”¨æ–‡æ¡£å†…å®¹å“ˆå¸Œé˜²æ­¢åœ¨ ReAct å¾ªç¯ä¸­é‡å¤æ£€ç´¢ç›¸åŒæ–‡æ¡£
        - æ¯æ¬¡æ–°æŸ¥è¯¢å¼€å§‹æ—¶é»˜è®¤é‡ç½®æ£€ç´¢å†å²ï¼ˆå¯é€šè¿‡ reset_history=False ç¦ç”¨ï¼‰

        Args:
            query (str): ç”¨æˆ·æŸ¥è¯¢å­—ç¬¦ä¸²
            max_iterations (int): æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ 5
            max_context_length (int): è§¦å‘ä¸Šä¸‹æ–‡æ€»ç»“çš„æœ€å¤§é•¿åº¦ï¼Œé»˜è®¤ 10000
            reset_history (bool): æ˜¯å¦é‡ç½®æ£€ç´¢å†å²ï¼Œé»˜è®¤ True

        Returns:
            List[str]: æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹åˆ—è¡¨ï¼ˆå·²å»é‡å’Œå¯èƒ½æ€»ç»“ï¼‰

        Examples:
            >>> agent = RetrivalAgent(agenda_dict, vector_db_obj=db_client)
            >>> results = agent.retrieval_data("æŸ¥æ‰¾å…³äºæœºå™¨å­¦ä¹ çš„ç« èŠ‚")
            >>> print(f"æ£€ç´¢åˆ° {len(results)} ä¸ªç›¸å…³å†…å®¹")
        """
        logger.info(f"å¼€å§‹å¤„ç†æ£€ç´¢è¯·æ±‚: {query[:100]}{'...' if len(query) > 100 else ''}")

        # è¾“å…¥éªŒè¯
        if not query or not query.strip():
            logger.warning("æŸ¥è¯¢å­—ç¬¦ä¸²ä¸ºç©º")
            return []

        if not self.vector_db_obj:
            logger.error("å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿›è¡Œæ£€ç´¢")
            return []

        # é‡ç½®æ£€ç´¢å†å²ï¼Œé˜²æ­¢è·¨æŸ¥è¯¢çš„å»é‡å¹²æ‰°
        if reset_history:
            self.vector_db_obj.reset_retrieval_history()

        # æ„å»ºå¯ç”¨çš„æ£€ç´¢å·¥å…·
        available_tools = self._build_retrieval_tools()
        tools_description = format_all_tools_for_llm()

        # ReAct å¾ªç¯çŠ¶æ€
        all_results = []
        iteration = 0

        try:
            while iteration < max_iterations:
                iteration += 1
                logger.info(f"ReAct å¾ªç¯ - ç¬¬ {iteration}/{max_iterations} è½®")

                # Step 1: Thought - è®© LLM å†³å®šä½¿ç”¨å“ªä¸ªå·¥å…·
                prompt = f"""ç”¨æˆ·æŸ¥è¯¢: {query}

å½“å‰å·²æ£€ç´¢åˆ° {len(all_results)} ä¸ªå†…å®¹ç‰‡æ®µã€‚

è¯·åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å·¥å…·æ¥æ£€ç´¢ä¿¡æ¯ã€‚

ä½ å¿…é¡»è¿”å›ä»¥ä¸‹ JSON æ ¼å¼çš„å“åº”:
{{
    "thought": "ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œåˆ†æä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªå·¥å…·",
    "action": "é€‰æ‹©çš„å·¥å…·åç§°",
    "action_input": "ä¼ é€’ç»™å·¥å…·çš„æŸ¥è¯¢å‚æ•°"
}}

åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚"""

                response = self.call_llm_chain(
                    ReaderRole.RETRIEVAL,
                    prompt,
                    "retrieval",
                    system_format_dict={"tool_info_dict": tools_description}
                )

                # Step 2: è§£æ LLM å“åº”
                try:
                    action_decision = extract_data_from_LLM_res(response)
                    thought = action_decision.get("thought", "")
                    action = action_decision.get("action", "")
                    action_input = action_decision.get("action_input", query)

                    logger.info(f"LLM é€‰æ‹©: {action}")
                    logger.debug(f"æ€è€ƒè¿‡ç¨‹: {thought}")

                except Exception as e:
                    logger.error(f"æ— æ³•è§£æ LLM å“åº”: {e}")
                    logger.info("ä½¿ç”¨é»˜è®¤ä¸Šä¸‹æ–‡æ£€ç´¢")
                    action = "retrieval_data_by_context"
                    action_input = query

                # Step 3: Action - æ‰§è¡Œé€‰å®šçš„å·¥å…·
                if action in available_tools:
                    tool_func = available_tools[action]["function"]
                    try:
                        logger.info(f"æ‰§è¡Œå·¥å…·: {action}")
                        result = tool_func(action_input)

                        # Step 4: Observation - è®°å½•ç»“æœ
                        if isinstance(result, list):
                            all_results.extend(result)
                            logger.info(f"å·¥å…·è¿”å› {len(result)} ä¸ªç»“æœ")
                        elif result:
                            all_results.append(str(result))
                            logger.info(f"å·¥å…·è¿”å› 1 ä¸ªç»“æœ")

                    except Exception as e:
                        logger.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                        continue
                else:
                    logger.warning(f"æœªçŸ¥å·¥å…·: {action}ï¼Œä½¿ç”¨é»˜è®¤æ£€ç´¢")
                    result = self.retrieval_data_by_context(query)
                    all_results.extend(result)

                # Step 5: Evaluation - è¯„ä¼°å½“å‰æ£€ç´¢ç»“æœæ˜¯å¦è¶³å¤Ÿ
                if all_results:
                    # å…ˆå»é‡
                    unique_results = list(dict.fromkeys(all_results))

                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ€»ç»“
                    total_length = sum(len(r) for r in unique_results)
                    if total_length > max_context_length:
                        logger.info(f"æ£€ç´¢å†…å®¹è¶…è¿‡é•¿åº¦é™åˆ¶ï¼Œè¿›è¡Œæ€»ç»“")
                        summarized_for_eval = self._summarize_context(
                            unique_results,
                            query,
                            max_length=max_context_length
                        )
                        evaluation_context = summarized_for_eval
                    else:
                        evaluation_context = "\n\n".join(unique_results)

                    # è¯„ä¼°æ£€ç´¢ç»“æœ
                    evaluation = self._evaluate_retrieval_results(query, evaluation_context)

                    # Step 6: Decision - æ ¹æ®è¯„ä¼°å†³å®šæ˜¯å¦ç»§ç»­
                    should_continue = evaluation.get("continue", False)
                    reason = evaluation.get("reason", "")

                    logger.info(f"è¯„ä¼°ç»“æœ: {'ç»§ç»­æ£€ç´¢' if should_continue else 'åœæ­¢æ£€ç´¢'}")
                    logger.info(f"ç†ç”±: {reason}")

                    if not should_continue:
                        # åœæ­¢æ£€ç´¢
                        logger.info(f"æ£€ç´¢å®Œæˆï¼Œå…± {len(unique_results)} ä¸ªå†…å®¹ç‰‡æ®µ")
                        break

                    # å¦‚æœéœ€è¦ç»§ç»­ï¼ŒæŸ¥çœ‹å»ºè®®çš„è¡ŒåŠ¨
                    suggested_action = evaluation.get("suggested_action")
                    if suggested_action:
                        logger.info(f"å»ºè®®ä¸‹ä¸€æ­¥ä½¿ç”¨å·¥å…·: {suggested_action}")

            # æœ€ç»ˆå¤„ç†
            unique_results = list(dict.fromkeys(all_results))

            logger.info(f"ReAct æ£€ç´¢å¾ªç¯ç»“æŸï¼Œå…±æ‰§è¡Œ {iteration} è½®")
            logger.info(f"æœ€ç»ˆç»“æœ: {len(unique_results)} ä¸ªå†…å®¹ç‰‡æ®µ")

            return unique_results

        except Exception as e:
            logger.error(f"æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            logger.debug(f"{traceback.format_exc()}")
            return []

    def retrieval_data_by_context(self, query: str) -> List[str]:
        """
        åŸºäºä¸Šä¸‹æ–‡çš„è¯­ä¹‰æ£€ç´¢æ–¹æ³•

        é€šè¿‡å‘é‡ç›¸ä¼¼åº¦æœç´¢åœ¨æ–‡æ¡£ä¸­æŸ¥æ‰¾ä¸æŸ¥è¯¢è¯­ä¹‰ç›¸å…³çš„å†…å®¹æ®µè½ã€‚
        è¿™ä¸ªæ–¹æ³•ä½¿ç”¨å‘é‡æ•°æ®åº“çš„è¯­ä¹‰æœç´¢åŠŸèƒ½ï¼Œèƒ½å¤Ÿç†è§£æŸ¥è¯¢çš„è¯­ä¹‰å«ä¹‰ï¼Œ
        å¹¶æ‰¾åˆ°åœ¨è¯­ä¹‰ä¸Šç›¸å…³çš„æ–‡æ¡£å†…å®¹ï¼Œå³ä½¿å…³é”®è¯ä¸å®Œå…¨åŒ¹é…ã€‚

        Args:
            query (str): æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œåº”æè¿°è¦æŸ¥æ‰¾çš„å†…å®¹è¯­ä¹‰

        Returns:
            List[str]: æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£å†…å®¹åˆ—è¡¨
        """
        if not query or not query.strip():
            logger.warning("ä¸Šä¸‹æ–‡æ£€ç´¢: æŸ¥è¯¢å­—ç¬¦ä¸²ä¸ºç©º")
            return []

        if not self.vector_db_obj:
            logger.error("ä¸Šä¸‹æ–‡æ£€ç´¢: å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
            return []

        try:
            # ä½¿ç”¨ type='context' è¿‡æ»¤å™¨è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œå¯ç”¨å»é‡
            doc_res = self.vector_db_obj.search_with_metadata_filter(
                query=query,
                k=3,
                field_name="type",
                field_value="context",
                enable_dedup=True  # å¯ç”¨å»é‡è¿‡æ»¤
            )

            context_data = []
            chapter_info_list = []  # å­˜å‚¨ç« èŠ‚ä¿¡æ¯ç”¨äºæ±‡æ€»

            if doc_res and len(doc_res) > 0:
                for idx, doc_item in enumerate(doc_res):
                    try:
                        # è§£ææ–‡æ¡£ç»“æ„
                        document = doc_item[0] if isinstance(doc_item, tuple) else doc_item
                        metadata = document.metadata

                        refactor_data = metadata.get("refactor", "")
                        raw_data = metadata.get("raw_data", {})
                        page_number = list(raw_data.keys()) if isinstance(raw_data, dict) else []

                        # æå–ç« èŠ‚æ ‡é¢˜ä¿¡æ¯
                        chapter_title = metadata.get("title", "æœªçŸ¥ç« èŠ‚")

                        # æ•´ç†å¹¶è¿”å›æ£€ç´¢åˆ°çš„æ•°æ®
                        if refactor_data and refactor_data.strip():
                            if refactor_data not in context_data:
                                context_data.append(refactor_data)

                                # è®°å½•ç« èŠ‚ä¿¡æ¯ç”¨äºæœ€åæ±‡æ€»
                                chapter_info_list.append({
                                    "title": chapter_title,
                                    "pages": sorted(page_number, key=lambda x: int(x) if str(x).isdigit() else 0) if page_number else []
                                })

                    except Exception as e:
                        logger.error(f"å¤„ç†ç¬¬ {idx+1} ä¸ªæ–‡æ¡£æ—¶å‡ºé”™: {e}")
                        continue

                # ========== æ±‡æ€»æ—¥å¿— ==========
                logger.info(f"")
                logger.info(f"{'='*60}")
                logger.info(f"âœ… [CONTEXT RETRIEVAL] ä¸Šä¸‹æ–‡æ£€ç´¢ç»“æœ")
                logger.info(f"{'='*60}")
                logger.info(f"ğŸ“Š è¿”å› {len(context_data)} æ¡å†…å®¹ç‰‡æ®µ")
                
                # ğŸ”¥ æ˜¾ç¤ºæœ¬æ¬¡è¿”å›å†…å®¹å¯¹åº”çš„ç« èŠ‚å’Œé¡µç 
                if chapter_info_list:
                    logger.info(f"ğŸ“š æ£€ç´¢åˆ°çš„ç« èŠ‚:")
                    for idx, chapter in enumerate(chapter_info_list, 1):
                        pages_str = f"é¡µç : {', '.join(map(str, chapter['pages']))}" if chapter['pages'] else "æ— é¡µç "
                        logger.info(f"   {idx}. {chapter['title']} ({pages_str})")
                else:
                    logger.info(f"ğŸ“š æœªæ£€ç´¢åˆ°ä»»ä½•ç« èŠ‚")

                logger.info(f"{'='*60}")
                logger.info(f"")
            else:
                logger.warning(f"åœ¨å‘é‡æ•°æ®åº“ä¸­æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ç›¸å…³çš„å†…å®¹")

            return context_data

        except Exception as e:
            logger.error(f"é€šè¿‡ä¸Šä¸‹æ–‡æ£€ç´¢æ•°æ®æ—¶å‡ºé”™: {e}")
            return []

    def retrieval_data_by_title(self, query: str) -> List[str]:
        """
        åŸºäºæ ‡é¢˜çš„ç²¾ç¡®æ£€ç´¢æ–¹æ³•

        è¿™ä¸ªæ–¹æ³•é¦–å…ˆä½¿ç”¨LLMä»ç”¨æˆ·æŸ¥è¯¢ä¸­æ™ºèƒ½æå–ç›¸å…³çš„ç« èŠ‚æ ‡é¢˜å…³é”®è¯ï¼Œ
        ç„¶ååœ¨å‘é‡æ•°æ®åº“ä¸­ç²¾ç¡®åŒ¹é…è¿™äº›æ ‡é¢˜æ¥æ£€ç´¢å¯¹åº”çš„æ–‡æ¡£å†…å®¹ã€‚

        Args:
            query (str): åŒ…å«æ ‡é¢˜ä¿¡æ¯çš„æŸ¥è¯¢å­—ç¬¦ä¸²

        Returns:
            List[str]: æ£€ç´¢åˆ°çš„åŒ¹é…æ ‡é¢˜çš„æ–‡æ¡£å†…å®¹åˆ—è¡¨
        """
        if not query or not query.strip():
            logger.warning("æ ‡é¢˜æ£€ç´¢: æŸ¥è¯¢å­—ç¬¦ä¸²ä¸ºç©º")
            return []

        try:
            response = self.call_llm_chain(
                ReaderRole.GETTITILE,
                query,
                "chat",
                system_format_dict={
                    "agenda_dict": self.agenda_dict
                }
            )

            response = extract_data_from_LLM_res(response)
            title_list = response.get("title", [])
            logger.info(f"æå–åˆ° {len(title_list) if isinstance(title_list, list) else 0} ä¸ªæ ‡é¢˜: {title_list}")

        except Exception as e:
            logger.error(f"LLMæ ‡é¢˜æå–å¤±è´¥: {e}")
            return []

        # è¾“å…¥éªŒè¯
        if not isinstance(title_list, list):
            logger.warning("æ ‡é¢˜åˆ—è¡¨æ ¼å¼æ— æ•ˆï¼ŒæœŸæœ›listç±»å‹")
            return []

        if len(title_list) == 0:
            logger.info("æœªæå–åˆ°ä»»ä½•æ ‡é¢˜ï¼Œè¿”å›ç©ºç»“æœ")
            return []

        # éªŒè¯å‘é‡æ•°æ®åº“æ˜¯å¦å¯ç”¨
        if not self.vector_db_obj or not self.vector_db_obj.vector_db:
            logger.error("å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
            return []

        context_data = []
        successful_retrievals = 0
        cache_hits = 0
        returned_titles = []  # ğŸ”¥ è¿½è¸ªå®é™…è¿”å›åˆ° context_data çš„æ ‡é¢˜

        for idx, title in enumerate(title_list):
            if not title or not isinstance(title, str):
                continue

            title = title.strip()
            if not title:
                continue

            try:
                refactor_data = ""
                page_number = []  # åˆå§‹åŒ– page_numberï¼Œé¿å…æœªå®šä¹‰é”™è¯¯
                is_from_cache = False  # ğŸ”¥ è¿½è¸ªæ˜¯å¦æ¥è‡ªç¼“å­˜

                # æ£€æŸ¥ç¼“å­˜
                if title in self.retrieval_data_dict:
                    cached_data = self.retrieval_data_dict[title]
                    refactor_data = cached_data.get("data", "")
                    page_number = cached_data.get("page", [])
                    cache_hits += 1
                    is_from_cache = True  # ğŸ”¥ æ ‡è®°ä¸ºç¼“å­˜å‘½ä¸­
                else:
                    # ä»å‘é‡æ•°æ®åº“æ£€ç´¢ï¼ˆä»…æ£€ç´¢ type='title' çš„æ–‡æ¡£ï¼‰ï¼Œå¯ç”¨å»é‡
                    try:
                        doc_res = self.vector_db_obj.search_by_title(title, doc_type="title", enable_dedup=True)

                        if doc_res and len(doc_res) > 0:
                            # å¤„ç†è¿”å›çš„åˆ—è¡¨ä¸­çš„æ¯ä¸ªæ–‡æ¡£
                            all_refactor_data = []
                            all_page_numbers = []

                            for doc_idx, doc_item in enumerate(doc_res):
                                document = doc_item[0] if isinstance(doc_item, tuple) else doc_item
                                metadata = document.metadata

                                item_refactor_data = metadata.get("refactor", "")
                                item_raw_data = metadata.get("raw_data", {})
                                item_page_numbers = list(item_raw_data.keys()) if isinstance(item_raw_data, dict) else []

                                if item_refactor_data and item_refactor_data.strip():
                                    all_refactor_data.append(item_refactor_data)

                                if item_page_numbers:
                                    all_page_numbers.extend(item_page_numbers)

                            # åˆå¹¶æ‰€æœ‰æ£€ç´¢åˆ°çš„æ•°æ®
                            refactor_data = "\n\n".join(all_refactor_data) if all_refactor_data else ""
                            page_number = list(set(all_page_numbers))  # å»é‡é¡µé¢ç¼–å·

                            # ç¼“å­˜æ£€ç´¢ç»“æœ
                            self.retrieval_data_dict[title] = {
                                "data": refactor_data,
                                "page": page_number
                            }

                            successful_retrievals += 1
                        else:
                            logger.warning(f"ç« èŠ‚ '{title}' åœ¨å‘é‡æ•°æ®åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")

                    except Exception as e:
                        logger.error(f"æ£€ç´¢ç« èŠ‚ '{title}' æ—¶å‡ºé”™: {e}")
                        continue

                # æ·»åŠ åˆ°ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆå»é‡ï¼‰
                if refactor_data and refactor_data.strip():
                    if refactor_data not in context_data:
                        context_data.append(refactor_data)
                        # ğŸ”¥ è®°å½•å®é™…æ·»åŠ åˆ° context_data çš„æ ‡é¢˜ã€é¡µç å’Œæ˜¯å¦ç¼“å­˜å‘½ä¸­
                        returned_titles.append({
                            "title": title,
                            "pages": page_number,
                            "from_cache": is_from_cache
                        })

            except Exception as e:
                logger.error(f"å¤„ç†ç« èŠ‚ '{title}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue

        # ========== æ±‡æ€»æ—¥å¿— ==========
        logger.info(f"")
        logger.info(f"{'='*60}")
        logger.info(f"âœ… [TITLE RETRIEVAL] æ ‡é¢˜æ£€ç´¢ç»“æœ")
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“Š è¿”å› {len(context_data)} æ¡å†…å®¹ç‰‡æ®µ (æ–°æ£€ç´¢: {successful_retrievals}, ç¼“å­˜: {cache_hits})")
        
        # ğŸ”¥ åªæ˜¾ç¤ºæœ¬æ¬¡å®é™…è¿”å›åˆ° context_data çš„ç« èŠ‚å’Œé¡µç 
        if returned_titles:
            logger.info(f"ğŸ“š æœ¬æ¬¡è¿”å›çš„ç« èŠ‚:")
            for item in returned_titles:
                title = item["title"]
                pages = item["pages"]
                from_cache = item.get("from_cache", False)
                
                # ğŸ”¥ æ·»åŠ ç¼“å­˜æ ‡è®°
                cache_tag = " [ç¼“å­˜]" if from_cache else " [æ–°æ£€ç´¢]"
                
                if pages:
                    sorted_pages = sorted(pages, key=lambda x: int(x) if str(x).isdigit() else 0)
                    pages_str = f"é¡µç : {', '.join(map(str, sorted_pages))}"
                else:
                    pages_str = "æ— é¡µç "
                logger.info(f"   âœ“ {title} ({pages_str}){cache_tag}")
        else:
            logger.info(f"ğŸ“š æœªæ£€ç´¢åˆ°ä»»ä½•å†…å®¹")
        
        logger.info(f"{'='*60}")
        logger.info(f"")

        return context_data

    def get_document_structure(self, query: str = "") -> List[str]:
        """
        è·å–æ–‡æ¡£çš„ç›®å½•ç»“æ„

        è¿”å›å½“å‰PDFæ–‡æ¡£çš„å®Œæ•´ç›®å½•ï¼ˆç« èŠ‚ï¼‰ç»“æ„ï¼ŒåŒ…æ‹¬æ‰€æœ‰ç« èŠ‚æ ‡é¢˜å’Œå¯¹åº”çš„é¡µç ä¿¡æ¯ã€‚
        è¿™ä¸ªæ–¹æ³•ä¸è¿›è¡Œå®é™…çš„å†…å®¹æ£€ç´¢ï¼Œåªè¿”å›æ–‡æ¡£çš„ç»„ç»‡ç»“æ„ã€‚

        Args:
            query (str): æŸ¥è¯¢å‚æ•°ï¼ˆæ­¤æ–¹æ³•å¿½ç•¥è¯¥å‚æ•°ï¼Œæ€»æ˜¯è¿”å›å®Œæ•´ç›®å½•ï¼‰

        Returns:
            List[str]: åŒ…å«æ ¼å¼åŒ–çš„æ–‡æ¡£ç›®å½•ç»“æ„çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªç« èŠ‚çš„æè¿°

        Examples:
            >>> agent = RetrivalAgent(agenda_dict, vector_db_obj=db_client)
            >>> structure = agent.get_document_structure()
            >>> print(structure[0])  # "ç¬¬ä¸€ç«  å¼•è¨€ (é¡µç : 1-10)"
        """
        if not self.agenda_dict:
            logger.warning("æ–‡æ¡£ç›®å½•ä¿¡æ¯ï¼ˆagenda_dictï¼‰ä¸å¯ç”¨")
            return ["æ–‡æ¡£ç›®å½•ä¿¡æ¯ä¸å¯ç”¨ï¼Œæ— æ³•è·å–æ–‡æ¡£ç»“æ„ã€‚"]

        try:
            structure_list = []

            # æ„å»ºæ ¼å¼åŒ–çš„ç›®å½•ç»“æ„
            structure_header = "=" * 60 + "\n"
            structure_header += "ğŸ“‘ æ–‡æ¡£ç›®å½•ç»“æ„\n"
            structure_header += "=" * 60
            structure_list.append(structure_header)

            # éå† agenda_dict å¹¶æ ¼å¼åŒ–æ¯ä¸ªç« èŠ‚
            for title, page_info in self.agenda_dict.items():
                # æ ¼å¼åŒ–é¡µç ä¿¡æ¯
                if isinstance(page_info, list):
                    if len(page_info) == 0:
                        page_str = "é¡µç æœªçŸ¥"
                    elif len(page_info) == 1:
                        page_str = f"é¡µç : {page_info[0]}"
                    else:
                        # æ’åºé¡µç 
                        sorted_pages = sorted(page_info, key=lambda x: int(x) if str(x).isdigit() else 0)
                        page_str = f"é¡µç : {sorted_pages[0]}-{sorted_pages[-1]}"
                elif isinstance(page_info, (int, str)):
                    page_str = f"é¡µç : {page_info}"
                else:
                    page_str = "é¡µç æœªçŸ¥"

                # æ ¼å¼åŒ–ç« èŠ‚æ¡ç›®ï¼ˆä¸æ·»åŠ ç´¢å¼•ç¼–å·ï¼‰
                chapter_entry = f"{title} ({page_str})"
                structure_list.append(chapter_entry)

            # æ·»åŠ ç»“å°¾åˆ†éš”çº¿
            structure_list.append("=" * 60)

            logger.info(f"æ–‡æ¡£ç›®å½•ç»“æ„è·å–å®Œæˆï¼Œå…±è§£æ {len(self.agenda_dict)} ä¸ªç« èŠ‚")

            return structure_list

        except Exception as e:
            logger.error(f"è·å–æ–‡æ¡£ç›®å½•ç»“æ„æ—¶å‡ºé”™: {e}")
            return [f"è·å–æ–‡æ¡£ç›®å½•ç»“æ„å¤±è´¥: {str(e)}"]

    def _summarize_context(self, context_list: List[str], query: str, max_length: int = 10000) -> str:
        """
        æ€»ç»“æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å†…å®¹

        å½“æ£€ç´¢åˆ°çš„å†…å®¹è¿‡é•¿æ—¶ï¼Œä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ€»ç»“ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ã€‚

        Args:
            context_list (List[str]): æ£€ç´¢åˆ°çš„å†…å®¹åˆ—è¡¨
            query (str): ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            max_length (int): è§¦å‘æ€»ç»“çš„æœ€å¤§é•¿åº¦é˜ˆå€¼

        Returns:
            str: æ€»ç»“åçš„å†…å®¹ï¼ˆå¦‚æœæœªè¶…è¿‡é˜ˆå€¼åˆ™è¿”å›åŸå†…å®¹ï¼‰
        """
        # è®¡ç®—æ€»é•¿åº¦
        total_context = "\n\n".join(context_list)
        total_length = len(total_context)

        logger.info(f"æ£€ç´¢å†…å®¹æ€»é•¿åº¦: {total_length} å­—ç¬¦")

        # å¦‚æœæœªè¶…è¿‡é˜ˆå€¼ï¼Œç›´æ¥è¿”å›
        if total_length <= max_length:
            logger.info(f"å†…å®¹é•¿åº¦æœªè¶…è¿‡é˜ˆå€¼ ({max_length})ï¼Œæ— éœ€æ€»ç»“")
            return total_context

        # éœ€è¦æ€»ç»“
        logger.info(f"å†…å®¹é•¿åº¦è¶…è¿‡é˜ˆå€¼ï¼Œå¼€å§‹æ€»ç»“...")

        try:
            # è°ƒç”¨ LLM è¿›è¡Œæ€»ç»“
            summarized = self.call_llm_chain(
                ReaderRole.CONTEXT_SUMMARIZER,
                "",
                "context_summarization",
                system_format_dict={
                    "context": total_context,
                    "query": query
                }
            )

            logger.info(f"æ€»ç»“å®Œæˆï¼Œå‹ç¼©æ¯”: {len(summarized)}/{total_length} = {len(summarized)/total_length*100:.1f}%")
            return summarized

        except Exception as e:
            logger.error(f"æ€»ç»“ä¸Šä¸‹æ–‡æ—¶å‡ºé”™: {e}")
            # å¦‚æœæ€»ç»“å¤±è´¥ï¼Œè¿”å›æˆªæ–­çš„åŸå§‹å†…å®¹
            logger.warning(f"æ€»ç»“å¤±è´¥ï¼Œè¿”å›æˆªæ–­çš„åŸå§‹å†…å®¹ï¼ˆå‰ {max_length} å­—ç¬¦ï¼‰")
            return total_context[:max_length] + "\n\n[å†…å®¹å·²æˆªæ–­...]"

    def _evaluate_retrieval_results(self, query: str, retrieved_context: str) -> Dict[str, Any]:
        """
        è¯„ä¼°æ£€ç´¢ç»“æœæ˜¯å¦è¶³å¤Ÿå›ç­”ç”¨æˆ·é—®é¢˜

        ä½¿ç”¨ LLM è¯„ä¼°å½“å‰æ£€ç´¢åˆ°çš„å†…å®¹æ˜¯å¦è¶³å¤Ÿï¼Œä»¥åŠæ˜¯å¦éœ€è¦ç»§ç»­æ£€ç´¢ã€‚

        Args:
            query (str): ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            retrieved_context (str): å·²æ£€ç´¢åˆ°çš„å†…å®¹æ‘˜è¦

        Returns:
            Dict[str, Any]: è¯„ä¼°ç»“æœ
                {
                    "continue": bool,  # æ˜¯å¦éœ€è¦ç»§ç»­æ£€ç´¢
                    "reason": str,  # è¯„ä¼°ç†ç”±
                    "suggested_action": str  # å»ºè®®çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼ˆå·¥å…·åç§°ï¼‰
                }
        """
        logger.info("æ­£åœ¨è¯„ä¼°æ£€ç´¢ç»“æœ...")

        try:
            # è°ƒç”¨è¯„ä¼° prompt
            response = self.call_llm_chain(
                ReaderRole.RETRIEVAL_EVALUATOR,
                "",
                "evaluation",
                system_format_dict={
                    "query": query,
                    "retrieved_summary": retrieved_context
                }
            )

            # è§£æ JSON å“åº”
            evaluation = extract_data_from_LLM_res(response)

            logger.info(f"è¯„ä¼°ç»“æœ: continue={evaluation.get('continue')}, reason={evaluation.get('reason')}")

            return evaluation

        except Exception as e:
            logger.error(f"è¯„ä¼°æ£€ç´¢ç»“æœæ—¶å‡ºé”™: {e}")
            # é»˜è®¤åœæ­¢æ£€ç´¢
            return {
                "continue": False,
                "reason": f"è¯„ä¼°å¤±è´¥: {e}",
                "suggested_action": None
            }