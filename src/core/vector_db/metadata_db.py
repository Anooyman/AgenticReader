"""
æ–‡æ¡£å…ƒæ•°æ®å‘é‡æ•°æ®åº“

å­˜å‚¨å’Œæ£€ç´¢æ–‡æ¡£å…ƒæ•°æ®çš„è¯­ä¹‰å‘é‡ï¼Œç”¨äºæ™ºèƒ½æ–‡æ¡£é€‰æ‹©
"""

import logging
from pathlib import Path
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)


class MetadataVectorDB:
    """æ–‡æ¡£å…ƒæ•°æ®å‘é‡æ•°æ®åº“"""

    def __init__(self):
        """åˆå§‹åŒ–å…ƒæ•°æ®å‘é‡æ•°æ®åº“"""
        from src.config.settings import DATA_ROOT

        self.index_path = Path(DATA_ROOT) / "vector_db" / "_metadata"
        self.vector_client = None
        self._initialize()

    def _initialize(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        from src.core.vector_db.vector_db_client import VectorDBClient
        from src.core.llm import get_embeddings

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.index_path.mkdir(parents=True, exist_ok=True)

        # è·å– embedding æ¨¡å‹
        embedding_model = get_embeddings()

        # åˆ›å»º VectorDBClientï¼ˆä¼šè‡ªåŠ¨å°è¯•åŠ è½½å·²å­˜åœ¨çš„æ•°æ®åº“ï¼‰
        try:
            self.vector_client = VectorDBClient(
                db_path=str(self.index_path),
                embedding_model=embedding_model
            )
            logger.info(f"âœ… åˆå§‹åŒ–å…ƒæ•°æ®å‘é‡æ•°æ®åº“: {self.index_path}")
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            self.vector_client = None

    def document_exists(self, doc_id: str) -> bool:
        """
        æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²å­˜åœ¨äºå…ƒæ•°æ®å‘é‡æ•°æ®åº“

        Args:
            doc_id: æ–‡æ¡£ID

        Returns:
            bool: æ˜¯å¦å­˜åœ¨
        """
        if not self.vector_client or not self.vector_client.vector_db:
            return False

        try:
            # ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤æœç´¢ï¼ŒæŸ¥æ‰¾æŒ‡å®š doc_id
            from src.core.document_management import DocumentRegistry

            registry = DocumentRegistry()
            doc_info = registry.get(doc_id)

            if not doc_info:
                return False

            doc_name = doc_info.get("doc_name")

            # æœç´¢è¯¥æ–‡æ¡£åï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨
            results = self.vector_client.search_with_metadata_filter(
                query=doc_name,
                k=10,
                field_name="doc_id",
                field_value=doc_id,
                enable_dedup=False
            )

            exists = len(results) > 0
            if exists:
                logger.debug(f"ğŸ“Œ [MetadataDB] æ–‡æ¡£å·²å­˜åœ¨: {doc_name} (ID: {doc_id})")

            return exists

        except Exception as e:
            logger.debug(f"âŒ [MetadataDB] æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å­˜åœ¨å¤±è´¥: {e}")
            return False

    def add_document(self, doc_id: str, doc_name: str, embedding_summary: str, update_if_exists: bool = True):
        """
        æ·»åŠ æ–‡æ¡£åˆ°å…ƒæ•°æ®ç´¢å¼•ï¼ˆæ”¯æŒå»é‡ï¼‰

        Args:
            doc_id: æ–‡æ¡£ID
            doc_name: æ–‡æ¡£åç§°
            embedding_summary: ç”¨äºå‘é‡åŒ–çš„æ–‡æœ¬ï¼ˆtitle + keywords + abstractï¼‰
            update_if_exists: å¦‚æœæ–‡æ¡£å·²å­˜åœ¨ï¼Œæ˜¯å¦æ›´æ–°ï¼ˆåˆ é™¤æ—§çš„å†æ·»åŠ æ–°çš„ï¼‰
        """
        if not self.vector_client:
            logger.error("âŒ [MetadataDB] å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
            return

        if not embedding_summary or not embedding_summary.strip():
            logger.warning(f"âš ï¸ [MetadataDB] æ–‡æ¡£ {doc_name} çš„ embedding_summary ä¸ºç©ºï¼Œè·³è¿‡")
            return

        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if update_if_exists and self.document_exists(doc_id):
                logger.info(f"ğŸ”„ [MetadataDB] æ–‡æ¡£ {doc_name} å·²å­˜åœ¨ï¼Œå°†æ›´æ–°å…ƒæ•°æ®")
                # åˆ é™¤æ—§çš„å…ƒæ•°æ®ï¼ˆé€šè¿‡é‡å»ºç´¢å¼•ï¼‰
                self.delete_document(doc_id)

            from langchain.docstore.document import Document

            # ä½¿ç”¨ç‰¹æ®Šçš„ type="metadata" æ ‡è®°
            metadata = {
                "type": "metadata",
                "doc_id": doc_id,
                "doc_name": doc_name,
                "refactor": embedding_summary  # å¤ç”¨ç°æœ‰å­—æ®µ
            }

            # åˆ›å»º Document å¯¹è±¡
            doc = Document(
                page_content=embedding_summary,
                metadata=metadata
            )

            # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            if self.vector_client.vector_db is None:
                # ç¬¬ä¸€æ¬¡æ·»åŠ ï¼Œæ„å»ºæ•°æ®åº“
                self.vector_client.build_vector_db([doc])
                logger.info(f"âœ… [MetadataDB] åˆ›å»ºå…ƒæ•°æ®å‘é‡æ•°æ®åº“å¹¶æ·»åŠ æ–‡æ¡£: {doc_name}")
            else:
                # å·²æœ‰æ•°æ®åº“ï¼Œæ·»åŠ æ–°æ–‡æ¡£
                self.vector_client.add_data(self.vector_client.vector_db, [doc])
                logger.info(f"âœ… [MetadataDB] æ·»åŠ æ–‡æ¡£å…ƒæ•°æ®åˆ°å‘é‡ç´¢å¼•: {doc_name} (ID: {doc_id})")

        except Exception as e:
            logger.error(f"âŒ [MetadataDB] æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())

    def search_similar_docs(
        self,
        query: str,
        top_k: int = 10,
        enable_dedup: bool = False
    ) -> List[Dict[str, Any]]:
        """
        æ ¹æ®æŸ¥è¯¢è¯­ä¹‰æœç´¢ç›¸å…³æ–‡æ¡£

        Args:
            query: æœç´¢æŸ¥è¯¢
            top_k: è¿”å›æ–‡æ¡£æ•°é‡
            enable_dedup: æ˜¯å¦å»é‡ï¼ˆå…ƒæ•°æ®æ£€ç´¢é€šå¸¸ä¸éœ€è¦ï¼‰

        Returns:
        [
            {
                "doc_id": "xxx",
                "doc_name": "xxx",
                "similarity_score": 0.85,
                "metadata": {...}
            },
            ...
        ]
        """
        if not self.vector_client:
            logger.error("âŒ [MetadataDB] å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
            return []

        if not query or not query.strip():
            logger.warning("âš ï¸ [MetadataDB] æŸ¥è¯¢å­—ç¬¦ä¸²ä¸ºç©º")
            return []

        try:
            logger.info(f"ğŸ” [MetadataDB] æ£€ç´¢ç›¸å…³æ–‡æ¡£: {query[:50]}...")

            # åœ¨å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢ï¼ˆtype="metadata"ï¼‰
            doc_res = self.vector_client.search_with_metadata_filter(
                query=query,
                k=top_k,
                field_name="type",
                field_value="metadata",
                enable_dedup=enable_dedup
            )

            if not doc_res or len(doc_res) == 0:
                logger.warning("âš ï¸ [MetadataDB] æœªæ‰¾åˆ°ä»»ä½•ç›¸å…³æ–‡æ¡£")
                return []

            # è§£æç»“æœ
            from src.core.document_management import DocumentRegistry

            registry = DocumentRegistry()
            similar_docs = []

            for idx, doc_item in enumerate(doc_res):
                try:
                    # search_with_metadata_filter è¿”å› (Document, score) tuple
                    if isinstance(doc_item, tuple) and len(doc_item) >= 2:
                        document = doc_item[0]
                        score = doc_item[1]
                    else:
                        # å…¼å®¹å…¶ä»–æ ¼å¼
                        document = doc_item[0] if isinstance(doc_item, tuple) else doc_item
                        score = 1.0

                    metadata = document.metadata
                    doc_id = metadata.get("doc_id")
                    doc_name = metadata.get("doc_name", "æœªçŸ¥æ–‡æ¡£")

                    if not doc_id:
                        logger.warning(f"âš ï¸ [MetadataDB] ç¬¬ {idx+1} ä¸ªç»“æœç¼ºå°‘ doc_idï¼Œè·³è¿‡")
                        continue

                    # ä» registry è·å–å®Œæ•´æ–‡æ¡£ä¿¡æ¯
                    doc_info = registry.get(doc_id)
                    if doc_info:
                        similar_docs.append({
                            "doc_id": doc_id,
                            "doc_name": doc_info["doc_name"],
                            "similarity_score": float(score),  # ä½™å¼¦ç›¸ä¼¼åº¦åˆ†æ•°
                            "metadata": doc_info.get("metadata_enhanced", {})
                        })
                    else:
                        logger.warning(f"âš ï¸ [MetadataDB] æ–‡æ¡£ {doc_id} åœ¨æ³¨å†Œè¡¨ä¸­ä¸å­˜åœ¨")

                except Exception as e:
                    logger.error(f"âŒ [MetadataDB] å¤„ç†ç¬¬ {idx+1} ä¸ªæ£€ç´¢ç»“æœå¤±è´¥: {e}")
                    import traceback
                    logger.debug(traceback.format_exc())
                    continue

            logger.info(f"âœ… [MetadataDB] æ£€ç´¢å®Œæˆï¼Œè¿”å› {len(similar_docs)} ä¸ªç›¸å…³æ–‡æ¡£")

            return similar_docs

        except Exception as e:
            logger.error(f"âŒ [MetadataDB] æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
            return []

    def delete_document(self, doc_id: str) -> bool:
        """
        åˆ é™¤æ–‡æ¡£çš„å…ƒæ•°æ®

        é€šè¿‡é‡å»ºç´¢å¼•å®ç°åˆ é™¤ï¼ˆè¿‡æ»¤æ‰è¦åˆ é™¤çš„æ–‡æ¡£ï¼‰

        Args:
            doc_id: æ–‡æ¡£ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ é™¤
        """
        if not self.vector_client:
            logger.error("âŒ [MetadataDB] å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
            return False

        try:
            from src.core.document_management import DocumentRegistry

            # è·å–æ–‡æ¡£åç”¨äºæ—¥å¿—
            registry = DocumentRegistry()
            doc_info = registry.get(doc_id)
            doc_name = doc_info.get("doc_name", "æœªçŸ¥") if doc_info else "æœªçŸ¥"

            logger.info(f"ğŸ—‘ï¸  [MetadataDB] å¼€å§‹åˆ é™¤æ–‡æ¡£å…ƒæ•°æ®: {doc_name} (ID: {doc_id})")

            # è·å–æ‰€æœ‰æ–‡æ¡£ï¼ˆä» DocumentRegistryï¼‰
            all_docs = registry.list_all()

            if not all_docs:
                logger.warning(f"âš ï¸  [MetadataDB] æ–‡æ¡£æ³¨å†Œè¡¨ä¸ºç©º")
                return False

            # è¿‡æ»¤æ‰è¦åˆ é™¤çš„æ–‡æ¡£ï¼Œé‡å»ºç´¢å¼•
            from langchain.docstore.document import Document

            documents = []
            excluded_count = 0

            for doc in all_docs:
                current_doc_id = doc.get("doc_id")
                current_doc_name = doc.get("doc_name")
                metadata_enhanced = doc.get("metadata_enhanced", {})

                # è·³è¿‡è¦åˆ é™¤çš„æ–‡æ¡£
                if current_doc_id == doc_id:
                    excluded_count += 1
                    logger.debug(f"   - è·³è¿‡æ–‡æ¡£: {current_doc_name} (ID: {doc_id})")
                    continue

                # åªæ·»åŠ æœ‰ embedding_summary çš„æ–‡æ¡£
                embedding_summary = metadata_enhanced.get("embedding_summary", "")
                if embedding_summary and embedding_summary.strip():
                    metadata = {
                        "type": "metadata",
                        "doc_id": current_doc_id,
                        "doc_name": current_doc_name,
                        "refactor": embedding_summary
                    }
                    documents.append(Document(
                        page_content=embedding_summary,
                        metadata=metadata
                    ))

            # é‡å»ºå‘é‡æ•°æ®åº“
            if documents:
                # æ¸…ç©ºç°æœ‰ç´¢å¼•
                import shutil
                if self.index_path.exists():
                    shutil.rmtree(self.index_path)
                self.index_path.mkdir(parents=True, exist_ok=True)

                # é‡æ–°åˆå§‹åŒ–
                self._initialize()

                if not self.vector_client:
                    logger.error("âŒ [MetadataDB] é‡æ–°åˆå§‹åŒ–å¤±è´¥")
                    return False

                # æ‰¹é‡æ„å»º
                self.vector_client.build_vector_db(documents)
                logger.info(f"âœ… [MetadataDB] å…ƒæ•°æ®ç´¢å¼•å·²é‡å»ºï¼Œæ’é™¤äº† {excluded_count} ä¸ªæ–‡æ¡£")
                logger.info(f"   - å‰©ä½™æ–‡æ¡£æ•°: {len(documents)}")
            else:
                # æ²¡æœ‰å‰©ä½™æ–‡æ¡£ï¼Œæ¸…ç©ºç´¢å¼•
                import shutil
                if self.index_path.exists():
                    shutil.rmtree(self.index_path)
                logger.info(f"âœ… [MetadataDB] å…ƒæ•°æ®ç´¢å¼•å·²æ¸…ç©ºï¼ˆæ— å‰©ä½™æ–‡æ¡£ï¼‰")

            return True

        except Exception as e:
            logger.error(f"âŒ [MetadataDB] åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return False

    def rebuild_index(self):
        """
        é‡å»ºæ•´ä¸ªå…ƒæ•°æ®ç´¢å¼•

        ä» DocumentRegistry è¯»å–æ‰€æœ‰æ–‡æ¡£çš„å…ƒæ•°æ®ï¼Œé‡æ–°æ„å»ºå‘é‡ç´¢å¼•
        """
        from src.core.document_management import DocumentRegistry
        from langchain.docstore.document import Document

        logger.info("ğŸ”„ [MetadataDB] å¼€å§‹é‡å»ºå…ƒæ•°æ®ç´¢å¼•")

        try:
            # æ¸…ç©ºç°æœ‰ç´¢å¼•
            import shutil
            if self.index_path.exists():
                shutil.rmtree(self.index_path)
            self.index_path.mkdir(parents=True, exist_ok=True)

            # é‡æ–°åˆå§‹åŒ–
            self._initialize()

            if not self.vector_client:
                logger.error("âŒ [MetadataDB] é‡æ–°åˆå§‹åŒ–å¤±è´¥")
                return

            # ä»æ³¨å†Œè¡¨è·å–æ‰€æœ‰æ–‡æ¡£
            registry = DocumentRegistry()
            all_docs = registry.list_all()

            logger.info(f"ğŸ“š [MetadataDB] æ‰¾åˆ° {len(all_docs)} ä¸ªæ–‡æ¡£")

            # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„æ–‡æ¡£
            documents = []
            for doc in all_docs:
                doc_id = doc.get("doc_id")
                doc_name = doc.get("doc_name")
                metadata_enhanced = doc.get("metadata_enhanced", {})

                embedding_summary = metadata_enhanced.get("embedding_summary", "")

                if embedding_summary and embedding_summary.strip():
                    # åˆ›å»º Document å¯¹è±¡
                    metadata = {
                        "type": "metadata",
                        "doc_id": doc_id,
                        "doc_name": doc_name,
                        "refactor": embedding_summary
                    }
                    documents.append(Document(
                        page_content=embedding_summary,
                        metadata=metadata
                    ))
                else:
                    logger.warning(f"âš ï¸ [MetadataDB] æ–‡æ¡£ {doc_name} ç¼ºå°‘ embedding_summaryï¼Œè·³è¿‡")

            # æ‰¹é‡æ„å»ºå‘é‡æ•°æ®åº“
            if documents:
                self.vector_client.build_vector_db(documents)
                logger.info(f"âœ… [MetadataDB] å…ƒæ•°æ®ç´¢å¼•é‡å»ºå®Œæˆï¼Œå…±æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£")
            else:
                logger.warning("âš ï¸ [MetadataDB] æ²¡æœ‰å¯ç”¨çš„æ–‡æ¡£å…ƒæ•°æ®")

        except Exception as e:
            logger.error(f"âŒ [MetadataDB] é‡å»ºç´¢å¼•å¤±è´¥: {e}", exc_info=True)

    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–å…ƒæ•°æ®æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {
            "index_path": str(self.index_path),
            "index_exists": (self.index_path / "index.faiss").exists(),
            "total_documents": 0
        }

        if self.vector_client and self.vector_client.vector_db:
            try:
                # å°è¯•è·å–æ–‡æ¡£æ•°é‡
                # FAISS å‘é‡æ•°æ®åº“çš„ index å±æ€§
                if hasattr(self.vector_client.vector_db, 'index'):
                    faiss_index = self.vector_client.vector_db.index
                    if hasattr(faiss_index, 'ntotal'):
                        stats["total_documents"] = faiss_index.ntotal
            except Exception as e:
                logger.debug(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

        return stats
