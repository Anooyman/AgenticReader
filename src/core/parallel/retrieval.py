"""
å¹¶è¡Œæ£€ç´¢åè°ƒå™¨

å¹¶è¡Œè°ƒç”¨å¤šä¸ªRetrievalAgentï¼Œé«˜æ•ˆå®Œæˆè·¨æ–‡æ¡£æ£€ç´¢
"""

import logging
import asyncio
from typing import List, Dict, Any

logger = logging.getLogger(__name__)


class ParallelRetrievalCoordinator:
    """å¹¶è¡Œæ£€ç´¢åè°ƒå™¨ - åè°ƒå¤šä¸ªRetrievalAgentå¹¶è¡Œå·¥ä½œ"""

    def __init__(self, answer_agent):
        """
        Args:
            answer_agent: AnswerAgentå®ä¾‹ï¼ˆéœ€è¦è®¿é—®retrieval_agentsæ± å’Œconversation_turnsï¼‰
        """
        self.answer_agent = answer_agent

    async def retrieve_from_multiple_docs(
        self,
        query: str,
        doc_list: List[Dict[str, Any]],
        doc_specific_queries: Dict[str, str] = None,
        max_iterations: int = 10,
        max_concurrent: int = 3,
        timeout_per_doc: int = 120
    ) -> Dict[str, Any]:
        """
        å¹¶è¡Œä»å¤šä¸ªæ–‡æ¡£ä¸­æ£€ç´¢

        Args:
            query: åŸå§‹ç”¨æˆ·æŸ¥è¯¢ï¼ˆä½œä¸ºå¤‡ä»½ï¼‰
            doc_list: æ–‡æ¡£åˆ—è¡¨ï¼ˆæ¥è‡ªDocumentSelectorï¼‰
            doc_specific_queries: æ¯ä¸ªæ–‡æ¡£çš„å®šåˆ¶æŸ¥è¯¢ {doc_name: rewritten_query}
            max_iterations: æ¯ä¸ªæ£€ç´¢çš„æœ€å¤§è¿­ä»£æ¬¡æ•°
            max_concurrent: æœ€å¤§å¹¶å‘æ£€ç´¢æ•°
            timeout_per_doc: å•ä¸ªæ–‡æ¡£æ£€ç´¢è¶…æ—¶ï¼ˆç§’ï¼‰

        Returns:
        {
            "doc1_name": {
                "final_summary": "...",
                "formatted_data": [...],
                "is_complete": True,
                "source_metadata": {...},
                "used_query": "å®é™…ä½¿ç”¨çš„æŸ¥è¯¢"
            },
            "doc2_name": {...},
            ...
        }
        """
        logger.info(f"")
        logger.info(f"=" * 80)
        logger.info(f"ğŸš€ [ParallelCoordinator] ========== å¹¶è¡Œæ£€ç´¢å¤šæ–‡æ¡£ ==========")
        logger.info(f"=" * 80)
        logger.info(f"ğŸ“ [ParallelCoordinator] åŸå§‹æŸ¥è¯¢: {query[:100]}...")
        logger.info(f"ğŸ“Š [ParallelCoordinator] é…ç½®:")
        logger.info(f"   - æ–‡æ¡£æ•°é‡: {len(doc_list)}")
        logger.info(f"   - æœ€å¤§è¿­ä»£: {max_iterations}")
        logger.info(f"   - æœ€å¤§å¹¶å‘: {max_concurrent}")
        logger.info(f"   - å•æ–‡æ¡£è¶…æ—¶: {timeout_per_doc}ç§’")
        logger.info(f"   - ä½¿ç”¨å®šåˆ¶æŸ¥è¯¢: {'æ˜¯' if doc_specific_queries else 'å¦'}")

        if not doc_list:
            logger.warning(f"âš ï¸  [ParallelCoordinator] æ–‡æ¡£åˆ—è¡¨ä¸ºç©ºï¼Œè¿”å›ç©ºç»“æœ")
            return {}

        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(max_concurrent)

        # åˆ›å»ºæ£€ç´¢ä»»åŠ¡åˆ—è¡¨
        tasks = []
        for doc_info in doc_list:
            doc_name = doc_info["doc_name"]

            # ä¸ºæ¯ä¸ªæ–‡æ¡£ä½¿ç”¨å®šåˆ¶çš„æŸ¥è¯¢ï¼ˆå¦‚æœæœ‰ï¼‰
            doc_query = query  # é»˜è®¤ä½¿ç”¨åŸå§‹æŸ¥è¯¢
            if doc_specific_queries and doc_name in doc_specific_queries:
                doc_query = doc_specific_queries[doc_name]
                logger.info(f"ğŸ“„ [ParallelCoordinator] æ–‡æ¡£ '{doc_name}' ä½¿ç”¨å®šåˆ¶æŸ¥è¯¢: {doc_query[:60]}...")
            else:
                logger.info(f"ğŸ“„ [ParallelCoordinator] æ–‡æ¡£ '{doc_name}' ä½¿ç”¨åŸå§‹æŸ¥è¯¢")

            task = self._retrieve_single_doc_with_limit(
                semaphore=semaphore,
                doc_info=doc_info,
                query=doc_query,  # ä½¿ç”¨å®šåˆ¶æŸ¥è¯¢
                max_iterations=max_iterations,
                timeout=timeout_per_doc
            )
            tasks.append((doc_name, task))

        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ£€ç´¢ä»»åŠ¡
        logger.info(f"")
        logger.info(f"ğŸ”„ [ParallelCoordinator] å¼€å§‹å¹¶è¡Œæ£€ç´¢...")

        results = {}
        task_results = await asyncio.gather(
            *[task for _, task in tasks],
            return_exceptions=True
        )

        # æ•´ç†ç»“æœ
        for (doc_name, _), result in zip(tasks, task_results):
            if isinstance(result, Exception):
                logger.error(f"âŒ [ParallelCoordinator] æ£€ç´¢æ–‡æ¡£ '{doc_name}' å¤±è´¥: {result}")
                results[doc_name] = {
                    "error": str(result),
                    "is_complete": False
                }
            else:
                results[doc_name] = result

        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results.values() if r.get("is_complete", False))
        error_count = len(results) - success_count

        logger.info(f"")
        logger.info(f"=" * 80)
        logger.info(f"âœ… [ParallelCoordinator] å¹¶è¡Œæ£€ç´¢å®Œæˆ")
        logger.info(f"=" * 80)
        logger.info(f"ğŸ“Š [ParallelCoordinator] ç»“æœç»Ÿè®¡:")
        logger.info(f"   - æˆåŠŸ: {success_count} ä¸ªæ–‡æ¡£")
        logger.info(f"   - å¤±è´¥: {error_count} ä¸ªæ–‡æ¡£")
        logger.info(f"=" * 80)
        logger.info(f"")

        return results

    async def _retrieve_single_doc_with_limit(
        self,
        semaphore: asyncio.Semaphore,
        doc_info: Dict[str, Any],
        query: str,
        max_iterations: int,
        timeout: int
    ) -> Dict[str, Any]:
        """
        å¸¦å¹¶å‘é™åˆ¶å’Œè¶…æ—¶çš„å•æ–‡æ¡£æ£€ç´¢

        Args:
            semaphore: å¹¶å‘æ§åˆ¶ä¿¡å·é‡
            doc_info: æ–‡æ¡£ä¿¡æ¯ï¼ˆåŒ…å«doc_name, similarity_scoreç­‰ï¼‰
            query: ç”¨æˆ·æŸ¥è¯¢
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            æ£€ç´¢ç»“æœå­—å…¸
        """
        doc_name = doc_info["doc_name"]

        async with semaphore:
            try:
                logger.info(f"ğŸ“– [ParallelCoordinator] å¼€å§‹æ£€ç´¢æ–‡æ¡£: {doc_name} (ç›¸ä¼¼åº¦: {doc_info.get('similarity_score', 'N/A')})")

                # è®¾ç½®è¶…æ—¶
                result = await asyncio.wait_for(
                    self._retrieve_single_doc(
                        doc_info=doc_info,
                        query=query,
                        max_iterations=max_iterations
                    ),
                    timeout=timeout
                )

                logger.info(f"âœ… [ParallelCoordinator] æ–‡æ¡£ '{doc_name}' æ£€ç´¢å®Œæˆ")
                return result

            except asyncio.TimeoutError:
                logger.error(f"â±ï¸  [ParallelCoordinator] æ–‡æ¡£ '{doc_name}' æ£€ç´¢è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
                return {
                    "error": f"æ£€ç´¢è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰",
                    "is_complete": False
                }
            except Exception as e:
                logger.error(f"âŒ [ParallelCoordinator] æ–‡æ¡£ '{doc_name}' æ£€ç´¢å¼‚å¸¸: {e}")
                return {
                    "error": str(e),
                    "is_complete": False
                }

    async def _retrieve_single_doc(
        self,
        doc_info: Dict[str, Any],
        query: str,
        max_iterations: int
    ) -> Dict[str, Any]:
        """
        æ£€ç´¢å•ä¸ªæ–‡æ¡£

        Args:
            doc_info: æ–‡æ¡£ä¿¡æ¯
            query: ç”¨æˆ·æŸ¥è¯¢
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°

        Returns:
            æ£€ç´¢ç»“æœ
        """
        doc_name = doc_info["doc_name"]

        # è·å–æˆ–åˆ›å»ºè¯¥æ–‡æ¡£çš„RetrievalAgent
        if doc_name not in self.answer_agent.retrieval_agents:
            from src.agents.retrieval import RetrievalAgent
            self.answer_agent.retrieval_agents[doc_name] = RetrievalAgent(doc_name=doc_name)
            logger.info(f"âœ¨ [ParallelCoordinator] ä¸ºæ–‡æ¡£ '{doc_name}' åˆ›å»ºæ–°çš„ Retrieval Agent")

        retrieval_agent = self.answer_agent.retrieval_agents[doc_name]

        # è·å–å¯¹è¯è½®æ¬¡
        if doc_name not in self.answer_agent.conversation_turns:
            self.answer_agent.conversation_turns[doc_name] = 0

        current_turn = self.answer_agent.conversation_turns[doc_name]

        # è°ƒç”¨RetrievalAgent
        from src.config.constants import ProcessingLimits

        # è®¡ç®—é€’å½’é™åˆ¶
        recursion_limit = max_iterations * 5 + 10

        result = await retrieval_agent.graph.ainvoke(
            {
                "query": query,
                "doc_name": doc_name,
                "max_iterations": max_iterations,
                "conversation_turn": current_turn,
                "current_iteration": 0,
                "is_complete": False,
                "thoughts": [],
                "actions": [],
                "observations": [],
                "retrieved_content": []
            },
            config={"recursion_limit": recursion_limit}
        )

        # é€’å¢å¯¹è¯è½®æ¬¡
        self.answer_agent.conversation_turns[doc_name] += 1

        # æ·»åŠ æºæ–‡æ¡£å…ƒæ•°æ®å’Œä½¿ç”¨çš„æŸ¥è¯¢åˆ°ç»“æœ
        result["source_metadata"] = doc_info
        result["used_query"] = query  # è®°å½•å®é™…ä½¿ç”¨çš„æŸ¥è¯¢ï¼ˆå¯èƒ½æ˜¯åŸå§‹æŸ¥è¯¢æˆ–æ”¹å†™åçš„æŸ¥è¯¢ï¼‰

        return result
