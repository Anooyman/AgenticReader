"""Webå†…å®¹å¤„ç†ç›¸å…³APIç«¯ç‚¹"""

import sys
import logging
import asyncio
import json
from pathlib import Path
from typing import Optional
from urllib.parse import urlparse
from fastapi import APIRouter, HTTPException, Depends, Body
from pydantic import BaseModel

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„åˆ°sys.path
PROJECT_ROOT = Path(__file__).resolve().parents[5]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from ...config import get_logger, settings
from ...services.chat_service import chat_service
from .config import get_current_provider, update_document_state

router = APIRouter(prefix="/web", tags=["Web"])
logger = get_logger(__name__)


class WebProcessRequest(BaseModel):
    url: str
    save_outputs: bool = True


@router.post("/process")
async def process_web_url(request: WebProcessRequest):
    """å¤„ç†ç½‘é¡µURL"""
    try:
        url = request.url.strip()

        if not url or not (url.startswith('http://') or url.startswith('https://')):
            raise HTTPException(status_code=400, detail="è¯·è¾“å…¥æœ‰æ•ˆçš„URL")

        logger.info(f"ğŸŒ å¼€å§‹å¤„ç†ç½‘é¡µ: {url}")

        # å¯¼å…¥WebReader
        from src.readers.web import WebReader
        from src.utils.helpers import extract_name_from_url

        # ç”Ÿæˆæ–‡æ¡£åï¼ˆåŸºäºURLï¼‰
        doc_name = extract_name_from_url(url)
        logger.info(f"ğŸ“ ç”Ÿæˆæ–‡æ¡£å: {doc_name}")

        # åˆå§‹åŒ–WebReaderï¼ˆä½¿ç”¨configä¸­é…ç½®çš„providerï¼‰
        provider = get_current_provider()
        web_reader = WebReader(provider=provider)

        # å¤„ç†ç½‘é¡µå†…å®¹ï¼ˆå¼‚æ­¥è°ƒç”¨ï¼‰
        await web_reader.process_web(url, save_data_flag=request.save_outputs)

        logger.info(f"âœ… ç½‘é¡µå†…å®¹å¤„ç†å®Œæˆ: {url} -> {doc_name}")

        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        json_path = settings.data_dir / "json_data" / f"{doc_name}.json"
        has_json = json_path.exists()

        # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†æ‘˜è¦æ–‡ä»¶
        output_path = settings.data_dir / "output" / doc_name
        has_summary = output_path.exists()

        # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†å‘é‡æ•°æ®åº“
        vector_db_path = settings.data_dir / "vector_db" / f"{doc_name}_vector_db"
        has_vector_db = vector_db_path.exists()

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ›´æ–°æœåŠ¡å™¨ç«¯æ–‡æ¡£çŠ¶æ€
        if has_json or has_vector_db:
            update_document_state(doc_name, has_pdf_reader=False, has_web_reader=True)
            logger.info(f"ğŸ“„ æ–‡æ¡£çŠ¶æ€å·²æ›´æ–°: {doc_name}, has_web_reader=True")

        return {
            "status": "success",
            "message": f"ç½‘é¡µå†…å®¹å¤„ç†å®Œæˆ: {url}",
            "doc_name": doc_name,
            "url": url,
            "save_outputs": request.save_outputs,
            "files_generated": {
                "json_data": has_json,
                "summary": has_summary,
                "vector_db": has_vector_db
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å¤„ç†ç½‘é¡µå†…å®¹å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¤„ç†ç½‘é¡µå†…å®¹å¤±è´¥: {str(e)}")


@router.get("/summary/{doc_name}")
async def get_web_summary(doc_name: str, summary_type: str = "brief"):
    """è·å–Webæ‘˜è¦ - æ‰«æç›®å½•æŸ¥æ‰¾ä»»æ„ .md æ–‡ä»¶"""
    try:
        import glob

        # Web å†…å®¹å­˜å‚¨åœ¨ output/<doc_name>/ ç›®å½•ä¸‹
        doc_output_dir = settings.data_dir / "output" / doc_name

        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not doc_output_dir.exists():
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†å‘é‡æ•°æ®åº“ï¼ˆå¤§æ–‡ä»¶æ¨¡å¼ï¼‰
            vector_db_path = settings.data_dir / "vector_db" / f"{doc_name}_vector_db"
            if vector_db_path.exists():
                return {
                    "status": "not_ready",
                    "message": f"è¯¥ç½‘é¡µå†…å®¹è¾ƒå¤§ï¼Œå·²ä½¿ç”¨å‘é‡æ•°æ®åº“å­˜å‚¨ï¼Œæš‚ä¸æ”¯æŒæ‘˜è¦æ˜¾ç¤ºã€‚è¯·ç›´æ¥ä½¿ç”¨èŠå¤©åŠŸèƒ½è¿›è¡Œé—®ç­”ã€‚",
                    "content": "",
                    "is_large_file": True
                }
            else:
                return {
                    "status": "not_ready",
                    "message": f"æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆå¤„ç†ç½‘é¡µå†…å®¹",
                    "content": "",
                    "is_large_file": False
                }

        # æ‰«æç›®å½•ä¸‹çš„æ‰€æœ‰ .md æ–‡ä»¶
        md_files = list(doc_output_dir.glob("*.md"))

        if not md_files:
            return {
                "status": "not_ready",
                "message": f"æ‘˜è¦æ–‡ä»¶å°šæœªç”Ÿæˆï¼Œè¯·ç­‰å¾…å¤„ç†å®Œæˆ",
                "content": "",
                "is_large_file": False
            }

        # ä¼˜å…ˆçº§åŒ¹é…ï¼šæ ¹æ® summary_type é€‰æ‹©æ–‡ä»¶
        summary_file = None

        if summary_type == "brief":
            # ä¼˜å…ˆæŸ¥æ‰¾ brief_summary.md æˆ– summary.md
            for pattern in ["brief_summary.md", "summary.md"]:
                for f in md_files:
                    if f.name == pattern:
                        summary_file = f
                        break
                if summary_file:
                    break
        else:
            # æŸ¥æ‰¾ detail_summary.md
            for f in md_files:
                if f.name == "detail_summary.md":
                    summary_file = f
                    break

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª .md æ–‡ä»¶
        if not summary_file and md_files:
            summary_file = md_files[0]
            logger.info(f"æœªæ‰¾åˆ°ç‰¹å®šæ‘˜è¦æ–‡ä»¶ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª .md æ–‡ä»¶: {summary_file.name}")

        if not summary_file or not summary_file.exists():
            return {
                "status": "not_ready",
                "message": f"æ‘˜è¦æ–‡ä»¶ä¸å¯ç”¨",
                "content": "",
                "is_large_file": False
            }

        # è¯»å–æ‘˜è¦å†…å®¹
        content = summary_file.read_text(encoding='utf-8')
        
        # ğŸ”¥ ä¿®å¤ï¼šå»é™¤ LLM ç”Ÿæˆçš„ä»£ç å—åŒ…è£¹ç¬¦å·
        # æŸäº› LLM ä¼šå°†æ•´ä¸ª Markdown å†…å®¹åŒ…è£¹åœ¨ ```markdown``` æˆ– ``` ä¸­
        content = content.strip()
        if content.startswith('```'):
            # å»é™¤å¼€å¤´çš„ ``` æˆ– ```markdown
            lines = content.split('\n')
            if lines[0].strip().startswith('```'):
                lines = lines[1:]  # å»æ‰ç¬¬ä¸€è¡Œ
            # å»é™¤ç»“å°¾çš„ ```
            if lines and lines[-1].strip() == '```':
                lines = lines[:-1]  # å»æ‰æœ€åä¸€è¡Œ
            content = '\n'.join(lines)

        logger.info(f"âœ… æˆåŠŸåŠ è½½Webæ‘˜è¦: {summary_file.name}")

        return {
            "status": "success",
            "summary_type": summary_type,
            "content": content,
            "file": str(summary_file),
            "file_name": summary_file.name
        }

    except Exception as e:
        logger.error(f"âŒ è·å–Webæ‘˜è¦å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–Webæ‘˜è¦å¤±è´¥: {str(e)}")


@router.get("/content/{doc_name}")
async def get_web_raw_content(doc_name: str):
    """è·å–WebåŸå§‹JSONå†…å®¹ï¼ˆç”¨äºèŠå¤©æ¨¡å¼å³ä¾§å±•ç¤ºï¼‰"""
    try:
        # æŸ¥æ‰¾ JSON æ–‡ä»¶
        json_data_dir = settings.data_dir / "json_data"
        json_path = json_data_dir / f"{doc_name}.json"
        
        # å¦‚æœæ ‡å‡†æ–‡ä»¶åä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
        if not json_path.exists():
            logger.warning(f"æ ‡å‡†æ–‡ä»¶åä¸å­˜åœ¨: {json_path.name}")
            
            if json_data_dir.exists():
                doc_name_normalized = doc_name.replace(' ', '').lower()
                
                for candidate in json_data_dir.glob("*.json"):
                    # è·³è¿‡ _format_data.json æ–‡ä»¶
                    if candidate.stem.endswith('_format_data'):
                        continue
                    candidate_normalized = candidate.stem.replace(' ', '').lower()
                    if candidate_normalized.startswith(doc_name_normalized):
                        json_path = candidate
                        logger.info(f"âœ… æ‰¾åˆ°åŒ¹é…æ–‡ä»¶: {json_path.name}")
                        break
        
        if not json_path.exists():
            return {
                "status": "not_found",
                "message": f"æœªæ‰¾åˆ°æ–‡æ¡£ {doc_name} çš„åŸå§‹å†…å®¹",
                "content": ""
            }
        
        # è¯»å– JSON å†…å®¹
        with open(json_path, 'r', encoding='utf-8') as f:
            raw_content = json.load(f)
        
        # å°† JSON å†…å®¹è½¬æ¢ä¸ºå¯è¯»çš„ Markdown æ ¼å¼
        if isinstance(raw_content, list):
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°†æ¯ä¸ªå…ƒç´ ä½œä¸ºæ®µè½
            formatted_content = "\n\n".join(raw_content)
        elif isinstance(raw_content, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼Œæ ¼å¼åŒ–æ˜¾ç¤º
            formatted_content = json.dumps(raw_content, ensure_ascii=False, indent=2)
        else:
            formatted_content = str(raw_content)
        
        logger.info(f"âœ… æˆåŠŸåŠ è½½WebåŸå§‹å†…å®¹: {json_path.name}, é•¿åº¦: {len(formatted_content)} å­—ç¬¦")
        
        return {
            "status": "success",
            "content": formatted_content,
            "file": str(json_path),
            "file_name": json_path.name,
            "content_length": len(formatted_content)
        }
    
    except Exception as e:
        logger.error(f"âŒ è·å–WebåŸå§‹å†…å®¹å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–WebåŸå§‹å†…å®¹å¤±è´¥: {str(e)}")


class WebInitializeRequest(BaseModel):
    url: Optional[str] = None


@router.post("/initialize/{doc_name}")
async def initialize_web_reader(
    doc_name: str, 
    request: WebInitializeRequest = Body(default=None)
):
    """åˆå§‹åŒ–Webé˜…è¯»å™¨ï¼ˆç”¨äºèŠå¤©æœåŠ¡ï¼‰"""
    try:
        # æå– URLï¼ˆå¦‚æœæä¾›ï¼‰
        url = request.url if request and request.url else None

        # ğŸ”¥ å‘åå…¼å®¹ï¼šæ£€æŸ¥å¤šç§å¯èƒ½çš„æ–‡ä»¶åæ ¼å¼
        json_data_dir = settings.data_dir / "json_data"
        json_path = json_data_dir / f"{doc_name}.json"
        
        # å¦‚æœæ ‡å‡†æ–‡ä»¶åä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ—§æ–‡ä»¶å
        if not json_path.exists():
            logger.warning(f"æ ‡å‡†æ–‡ä»¶åä¸å­˜åœ¨: {json_path.name}")
            logger.info(f"ğŸ” å°è¯•åœ¨ {json_data_dir} ä¸­æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶...")
            
            # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½åŒ¹é…çš„ JSON æ–‡ä»¶
            if json_data_dir.exists():
                # è§„èŒƒåŒ– doc_name ç”¨äºæ¯”è¾ƒ
                doc_name_normalized = doc_name.replace(' ', '').lower()
                
                for candidate in json_data_dir.glob("*.json"):
                    # è§„èŒƒåŒ–å€™é€‰æ–‡ä»¶åç”¨äºæ¯”è¾ƒ
                    candidate_normalized = candidate.stem.replace(' ', '').lower()
                    
                    # å¦‚æœå€™é€‰æ–‡ä»¶åä»¥ doc_name å¼€å¤´ï¼ˆå¿½ç•¥ç‰¹æ®Šå­—ç¬¦ï¼‰
                    if candidate_normalized.startswith(doc_name_normalized):
                        json_path = candidate
                        logger.info(f"âœ… æ‰¾åˆ°åŒ¹é…æ–‡ä»¶: {json_path.name}")
                        # æ›´æ–° doc_name ä¸ºå®é™…æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
                        doc_name = candidate.stem
                        break
        
        if not json_path.exists():
            logger.warning(f"âš ï¸ JSONæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•åˆå§‹åŒ–Webé˜…è¯»å™¨: {doc_name}")
            return {
                "status": "needs_processing",
                "message": f"Webå†…å®¹ {doc_name} éœ€è¦é‡æ–°å¤„ç†",
                "doc_name": doc_name,
                "has_json": False
            }

        # åˆå§‹åŒ–èŠå¤©æœåŠ¡
        logger.info(f"ğŸ”„ æ­£åœ¨åˆå§‹åŒ–WebèŠå¤©æœåŠ¡: {doc_name}")
        logger.info(f"ğŸ“Š åˆå§‹åŒ–å‰ChatServiceçŠ¶æ€: {chat_service.get_status()}")

        # è·å–å½“å‰é…ç½®çš„ provider
        from .config import get_current_provider
        current_provider = get_current_provider()
        logger.info(f"ğŸ”§ ä½¿ç”¨ LLM provider: {current_provider}")

        # è°ƒç”¨å¼‚æ­¥åˆå§‹åŒ–æ–¹æ³•
        success = await chat_service.initialize_web_reader(doc_name, url=url, provider=current_provider)

        logger.info(f"ğŸ“Š åˆå§‹åŒ–åChatServiceçŠ¶æ€: {chat_service.get_status()}")

        if success:
            logger.info(f"âœ… Webé˜…è¯»å™¨å’ŒèŠå¤©æœåŠ¡åˆå§‹åŒ–æˆåŠŸ: {doc_name}")
            return {
                "status": "success",
                "message": f"Webé˜…è¯»å™¨å·²åˆå§‹åŒ–: {doc_name}",
                "doc_name": doc_name,
                "has_json": True,
                "chat_initialized": True
            }
        else:
            logger.warning(f"âš ï¸ WebèŠå¤©æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {doc_name}")
            return {
                "status": "partial_success",
                "message": f"Webå†…å®¹æ£€æŸ¥å®Œæˆï¼Œä½†èŠå¤©æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {doc_name}",
                "doc_name": doc_name,
                "has_json": True,
                "chat_initialized": False
            }

    except Exception as e:
        logger.error(f"âŒ åˆå§‹åŒ–Webé˜…è¯»å™¨å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆå§‹åŒ–Webé˜…è¯»å™¨å¤±è´¥: {str(e)}")