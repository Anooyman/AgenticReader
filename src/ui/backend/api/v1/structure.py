"""æ–‡æ¡£ç»“æ„ç®¡ç† API"""

from fastapi import APIRouter, HTTPException
from typing import Dict, Any, List
from pydantic import BaseModel
import json
from pathlib import Path

from ...config import JSON_DATA_DIR, PDF_DIR

router = APIRouter()


class StructureUpdate(BaseModel):
    """ç»“æ„æ›´æ–°æ¨¡å‹"""
    agenda_dict: Dict[str, List[int]]  # {ç« èŠ‚æ ‡é¢˜: [é¡µç åˆ—è¡¨]}
    has_toc: bool = False


@router.get("/{doc_name}")
async def get_structure(doc_name: str) -> Dict[str, Any]:
    """
    è·å–æ–‡æ¡£çš„ç»“æ„ä¿¡æ¯

    Args:
        doc_name: æ–‡æ¡£åç§°

    Returns:
        structure.json å†…å®¹
    """
    try:
        # Strip .pdf extension if present to get base name for folder lookup
        doc_name_base = doc_name.replace('.pdf', '') if doc_name.endswith('.pdf') else doc_name

        # æ„å»º structure.json è·¯å¾„
        structure_path = JSON_DATA_DIR / doc_name_base / "structure.json"

        if not structure_path.exists():
            raise HTTPException(
                status_code=404,
                detail=f"ç»“æ„æ–‡ä»¶ä¸å­˜åœ¨: {doc_name}"
            )

        # è¯»å– structure.json
        with open(structure_path, 'r', encoding='utf-8') as f:
            structure_data = json.load(f)

        # å…¼å®¹æ–°æ—§æ ¼å¼
        if isinstance(structure_data, dict):
            if "agenda_dict" in structure_data:
                # æ–°æ ¼å¼
                agenda_dict = structure_data.get("agenda_dict", {})
                has_toc = structure_data.get("has_toc", False)
            else:
                # æ—§æ ¼å¼ï¼šæ•´ä¸ªæ–‡ä»¶å°±æ˜¯ agenda_dict
                agenda_dict = structure_data
                has_toc = True
        else:
            raise HTTPException(
                status_code=400,
                detail="ç»“æ„æ–‡ä»¶æ ¼å¼é”™è¯¯"
            )

        # åŒæ—¶è¯»å– PDF æ•°æ®ä»¥è·å–æ€»é¡µæ•°
        data_path = JSON_DATA_DIR / doc_name_base / "data.json"
        total_pages = 0
        if data_path.exists():
            with open(data_path, 'r', encoding='utf-8') as f:
                pdf_data = json.load(f)
                if isinstance(pdf_data, list):
                    total_pages = len(pdf_data)

        print(f"âœ… è·å–ç»“æ„æˆåŠŸ: {doc_name}, {len(agenda_dict)} ä¸ªç« èŠ‚")

        return {
            "success": True,
            "doc_name": doc_name,
            "agenda_dict": agenda_dict,
            "has_toc": has_toc,
            "total_pages": total_pages,
            "total_chapters": len(agenda_dict)
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ è·å–ç»“æ„å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.put("/{doc_name}")
async def update_structure(
    doc_name: str,
    structure: StructureUpdate
) -> Dict[str, Any]:
    """
    æ›´æ–°æ–‡æ¡£çš„ç»“æ„ä¿¡æ¯

    Args:
        doc_name: æ–‡æ¡£åç§°
        structure: æ–°çš„ç»“æ„æ•°æ®

    Returns:
        æ›´æ–°ç»“æœ
    """
    try:
        # Strip .pdf extension if present to get base name for folder lookup
        doc_name_base = doc_name.replace('.pdf', '') if doc_name.endswith('.pdf') else doc_name

        # æ„å»ºè·¯å¾„
        doc_json_folder = JSON_DATA_DIR / doc_name_base
        structure_path = doc_json_folder / "structure.json"

        if not doc_json_folder.exists():
            raise HTTPException(
                status_code=404,
                detail=f"æ–‡æ¡£æ•°æ®ç›®å½•ä¸å­˜åœ¨: {doc_name}"
            )

        # éªŒè¯é¡µç èŒƒå›´
        data_path = doc_json_folder / "data.json"
        if data_path.exists():
            with open(data_path, 'r', encoding='utf-8') as f:
                pdf_data = json.load(f)
                if isinstance(pdf_data, list):
                    max_page = len(pdf_data)

                    # æ£€æŸ¥æ‰€æœ‰ç« èŠ‚çš„é¡µç æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    for title, pages in structure.agenda_dict.items():
                        for page in pages:
                            if page < 1 or page > max_page:
                                raise HTTPException(
                                    status_code=400,
                                    detail=f"ç« èŠ‚ '{title}' çš„é¡µç  {page} è¶…å‡ºèŒƒå›´ (1-{max_page})"
                                )

        # ä¿å­˜æ–°çš„ç»“æ„
        structure_data = {
            "agenda_dict": structure.agenda_dict,
            "has_toc": structure.has_toc
        }

        with open(structure_path, 'w', encoding='utf-8') as f:
            json.dump(structure_data, f, ensure_ascii=False, indent=2)

        print(f"âœ… ç»“æ„æ›´æ–°æˆåŠŸ: {doc_name}, {len(structure.agenda_dict)} ä¸ªç« èŠ‚")

        return {
            "success": True,
            "message": "ç»“æ„æ›´æ–°æˆåŠŸ",
            "doc_name": doc_name,
            "total_chapters": len(structure.agenda_dict)
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ æ›´æ–°ç»“æ„å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/{doc_name}/rebuild")
async def rebuild_from_structure(
    doc_name: str
) -> Dict[str, Any]:
    """
    åŸºäºæ›´æ–°åçš„ structure å…¨é¢é‡å»ºæ–‡æ¡£æ•°æ®

    ä¿æŒä¸å˜çš„æ–‡ä»¶ï¼š
    - structure.json: æ‰‹åŠ¨ç¼–è¾‘çš„ç»“æ„
    - data.json: PDF åŸå§‹æ•°æ®
    - pdf_image/: PDF å›¾ç‰‡æ–‡ä»¶

    é‡æ–°ç”Ÿæˆçš„å†…å®¹ï¼š
    - chunks.json: ç« èŠ‚æ•°æ®
    - ç« èŠ‚æ‘˜è¦: æ‰€æœ‰ç« èŠ‚çš„æ‘˜è¦å’Œé‡æ„å†…å®¹
    - å‘é‡æ•°æ®åº“: FAISS ç´¢å¼•
    - ç®€è¦æ‘˜è¦: æ•´ä½“æ–‡æ¡£æ‘˜è¦

    Args:
        doc_name: æ–‡æ¡£åç§°

    Returns:
        é‡å»ºç»“æœ
    """
    try:
        from src.agents.indexing import IndexingAgent

        # Strip .pdf extension if present to get base name for folder lookup
        doc_name_base = doc_name.replace('.pdf', '') if doc_name.endswith('.pdf') else doc_name

        # éªŒè¯æ–‡æ¡£å­˜åœ¨
        structure_path = JSON_DATA_DIR / doc_name_base / "structure.json"
        if not structure_path.exists():
            raise HTTPException(
                status_code=404,
                detail=f"ç»“æ„æ–‡ä»¶ä¸å­˜åœ¨: {doc_name}"
            )

        # è·å–æ–‡æ¡£è·¯å¾„
        pdf_path = PDF_DIR / f"{doc_name_base}.pdf"
        if not pdf_path.exists():
            raise HTTPException(
                status_code=404,
                detail=f"PDF æ–‡ä»¶ä¸å­˜åœ¨: {doc_name}.pdf"
            )

        print(f"ğŸ”„ å¼€å§‹å…¨é¢é‡å»ºæ–‡æ¡£æ•°æ®: {doc_name}")
        print(f"   é‡å»ºå†…å®¹: chunks + summaries + vectordb + brief_summary")

        # åˆå§‹åŒ– IndexingAgent
        indexing_agent = IndexingAgent()

        # è°ƒç”¨é‡å»ºæ–¹æ³•ï¼ˆå…¨é¢é‡å»ºï¼‰
        result = await indexing_agent.rebuild_from_structure(
            doc_name=doc_name_base,
            doc_path=str(pdf_path)
        )

        if result.get("success"):
            print(f"âœ… é‡å»ºå®Œæˆ: {doc_name}")
            return {
                "success": True,
                "message": "æ–‡æ¡£æ•°æ®é‡å»ºå®Œæˆ",
                "doc_name": doc_name,
                "details": result
            }
        else:
            error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
            print(f"âŒ é‡å»ºå¤±è´¥: {error_msg}")
            raise HTTPException(
                status_code=500,
                detail=f"é‡å»ºå¤±è´¥: {error_msg}"
            )

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ é‡å»ºå¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/{doc_name}/chapter/{chapter_title}")
async def delete_chapter(
    doc_name: str,
    chapter_title: str
) -> Dict[str, Any]:
    """
    åˆ é™¤æŒ‡å®šç« èŠ‚

    Args:
        doc_name: æ–‡æ¡£åç§°
        chapter_title: ç« èŠ‚æ ‡é¢˜

    Returns:
        åˆ é™¤ç»“æœ
    """
    try:
        # Strip .pdf extension if present to get base name for folder lookup
        doc_name_base = doc_name.replace('.pdf', '') if doc_name.endswith('.pdf') else doc_name

        # è¯»å–å½“å‰ç»“æ„
        structure_path = JSON_DATA_DIR / doc_name_base / "structure.json"

        if not structure_path.exists():
            raise HTTPException(
                status_code=404,
                detail=f"ç»“æ„æ–‡ä»¶ä¸å­˜åœ¨: {doc_name}"
            )

        with open(structure_path, 'r', encoding='utf-8') as f:
            structure_data = json.load(f)

        # å…¼å®¹æ ¼å¼
        if "agenda_dict" in structure_data:
            agenda_dict = structure_data["agenda_dict"]
            has_toc = structure_data.get("has_toc", False)
        else:
            agenda_dict = structure_data
            has_toc = True

        # åˆ é™¤ç« èŠ‚
        if chapter_title not in agenda_dict:
            raise HTTPException(
                status_code=404,
                detail=f"ç« èŠ‚ä¸å­˜åœ¨: {chapter_title}"
            )

        del agenda_dict[chapter_title]

        # ä¿å­˜
        new_structure = {
            "agenda_dict": agenda_dict,
            "has_toc": has_toc
        }

        with open(structure_path, 'w', encoding='utf-8') as f:
            json.dump(new_structure, f, ensure_ascii=False, indent=2)

        print(f"âœ… ç« èŠ‚åˆ é™¤æˆåŠŸ: {chapter_title}")

        return {
            "success": True,
            "message": f"ç« èŠ‚ '{chapter_title}' å·²åˆ é™¤",
            "remaining_chapters": len(agenda_dict)
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ åˆ é™¤ç« èŠ‚å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
