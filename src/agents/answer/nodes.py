"""
AnswerAgent WorkflowèŠ‚ç‚¹æ–¹æ³•

æ‰€æœ‰workflowèŠ‚ç‚¹çš„å®ç°
"""

from __future__ import annotations
from typing import Dict, TYPE_CHECKING
import logging
import json
import re

from .state import AnswerState

if TYPE_CHECKING:
    from .agent import AnswerAgent

logger = logging.getLogger(__name__)


class AnswerNodes:
    """AnswerAgent WorkflowèŠ‚ç‚¹æ–¹æ³•é›†åˆ"""

    def __init__(self, agent: 'AnswerAgent'):
        """
        Args:
            agent: AnswerAgentå®ä¾‹ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
        """
        self.agent = agent

    async def analyze_intent(self, state: AnswerState) -> AnswerState:
        """
        æ­¥éª¤1ï¼šåˆ†æç”¨æˆ·æ„å›¾

        åŸºäºå¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢æ–‡æ¡£å†…å®¹æ¥å›ç­”å½“å‰é—®é¢˜
        æ³¨æ„ï¼šå¯¹è¯å†å²å·²ç”± LLM Client è‡ªåŠ¨ç®¡ç†ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†
        """
        from .prompts import AnswerRole

        logger.info("=" * 80)
        logger.info("ğŸ¤” [Analyze] ========== æ­¥éª¤0: åˆ†æç”¨æˆ·æ„å›¾ ==========")
        logger.info("=" * 80)

        user_query = state['user_query']
        current_doc = state.get('current_doc', 'æ— ')

        logger.info(f"ğŸ“ [Analyze] è¾“å…¥ä¿¡æ¯:")
        logger.info(f"   - ç”¨æˆ·æŸ¥è¯¢: {user_query}")
        logger.info(f"   - å½“å‰æ–‡æ¡£: {current_doc}")
        logger.info(f"   - æŸ¥è¯¢é•¿åº¦: {len(user_query)} å­—ç¬¦")

        try:
            # ç®€åŒ–çš„ promptï¼ˆå¯¹è¯å†å²ç”± LLM Client ç®¡ç†ï¼‰
            prompt = f"""
å½“å‰ç”¨æˆ·é—®é¢˜ï¼š{user_query}

è¯·åˆ¤æ–­æ˜¯å¦éœ€è¦ä»æ–‡æ¡£ä¸­æ£€ç´¢æ–°ä¿¡æ¯æ¥å›ç­”è¿™ä¸ªé—®é¢˜ã€‚

è¿”å›JSONæ ¼å¼ï¼š
{{
    "needs_retrieval": true/false,
    "reason": "ç®€è¦è¯´æ˜åˆ¤æ–­ç†ç”±ï¼ˆ20å­—ä»¥å†…ï¼‰"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

            logger.info(f"ğŸ¤– [Analyze] è°ƒç”¨ LLM è¿›è¡Œæ„å›¾åˆ†æ...")

            # ä½¿ç”¨ä¸“é—¨çš„æ„å›¾åˆ†æ Role
            response = await self.agent.llm.async_call_llm_chain(
                role=AnswerRole.INTENT_ANALYZER,
                input_prompt=prompt,
                session_id="analyze_intent"
            )

            logger.info(f"ğŸ“¤ [Analyze] LLM å“åº”é¢„è§ˆ: {response[:100]}...")

            # è§£æJSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                needs_retrieval = result.get("needs_retrieval", True)
                reason = result.get("reason", "")
            else:
                # é»˜è®¤éœ€è¦æ£€ç´¢
                logger.warning("âš ï¸ [Analyze] JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
                needs_retrieval = True
                reason = "JSONè§£æå¤±è´¥ï¼Œé»˜è®¤æ£€ç´¢"

            logger.info("")
            logger.info("=" * 80)
            logger.info("âœ… [Analyze] æ„å›¾åˆ†æç»“æœ")
            logger.info("=" * 80)
            logger.info(f"ğŸ“Š [Analyze] è¾“å‡ºä¿¡æ¯:")
            logger.info(f"   - æ˜¯å¦éœ€è¦æ£€ç´¢: {'æ˜¯' if needs_retrieval else 'å¦'}")
            logger.info(f"   - åˆ¤æ–­ç†ç”±: {reason}")
            logger.info(f"   - ä¸‹ä¸€æ­¥: {'è°ƒç”¨ Retrieval Agent' if needs_retrieval else 'ç›´æ¥ç”Ÿæˆç­”æ¡ˆ'}")
            logger.info("=" * 80)
            logger.info("")

            # æ›´æ–° state å¹¶è¿”å›
            state["needs_retrieval"] = needs_retrieval
            state["analysis_reason"] = reason
            return state

        except Exception as e:
            logger.error(f"âŒ [Analyze] æ„å›¾åˆ†æå¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())

            # å¤±è´¥æ—¶é»˜è®¤éœ€è¦æ£€ç´¢ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
            state["needs_retrieval"] = True
            state["analysis_reason"] = "åˆ†æå¤±è´¥ï¼Œé‡‡ç”¨ä¿å®ˆç­–ç•¥"

            logger.warning("")
            logger.warning("=" * 80)
            logger.warning("âš ï¸ [Analyze] ä½¿ç”¨é»˜è®¤ç­–ç•¥")
            logger.warning("=" * 80)
            logger.warning(f"   - æ˜¯å¦éœ€è¦æ£€ç´¢: æ˜¯ï¼ˆä¿å®ˆç­–ç•¥ï¼‰")
            logger.warning(f"   - åŸå› : {state['analysis_reason']}")
            logger.warning("=" * 80)
            logger.warning("")

            return state

    async def call_retrieval(self, state: AnswerState) -> AnswerState:
        """
        æ­¥éª¤2ï¼šè°ƒç”¨Retrieval Agentæ£€ç´¢ï¼ˆä½¿ç”¨å·¥å…·æ–¹æ³•ï¼‰

        ç¼–æ’Retrieval Agentè¿›è¡Œå†…å®¹æ£€ç´¢ï¼Œç›´æ¥è¿”å›æ£€ç´¢ç»“æœä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
        """
        from langchain_core.messages import AIMessage

        logger.info("=" * 80)
        logger.info("ğŸ” [Retrieve] ========== æ­¥éª¤1: è°ƒç”¨æ£€ç´¢ä»£ç† ==========")
        logger.info("=" * 80)

        user_query = state["user_query"]
        current_doc = state.get("current_doc")

        logger.info(f"ğŸ“ [Retrieve] è¾“å…¥ä¿¡æ¯:")
        logger.info(f"   - ç”¨æˆ·æŸ¥è¯¢: {user_query}")
        logger.info(f"   - ç›®æ ‡æ–‡æ¡£: {current_doc if current_doc else 'æœªæŒ‡å®š'}")

        try:
            # æ›´æ–°å½“å‰æ–‡æ¡£ä¸Šä¸‹æ–‡
            self.agent.current_doc = current_doc

            logger.info(f"ğŸ¤– [Retrieve] è°ƒç”¨ Retrieval Agent è¿›è¡Œæ£€ç´¢...")

            # è°ƒç”¨å·¥å…·æ–¹æ³•
            context = await self.agent.tools.call_retrieval_impl(user_query)

            context_length = len(context) if context else 0
            context_preview = context[:200] if context else "æ— å†…å®¹"

            logger.info("")
            logger.info("=" * 80)
            logger.info("âœ… [Retrieve] æ£€ç´¢å®Œæˆ")
            logger.info("=" * 80)
            logger.info(f"ğŸ“Š [Retrieve] è¾“å‡ºä¿¡æ¯:")
            logger.info(f"   - æ£€ç´¢çŠ¶æ€: {'æˆåŠŸ' if context else 'æ— ç»“æœ'}")
            logger.info(f"   - ç­”æ¡ˆé•¿åº¦: {context_length} å­—ç¬¦")
            if context:
                logger.info(f"   - ç­”æ¡ˆé¢„è§ˆ: {context_preview}...")
            logger.info("=" * 80)
            logger.info("")

            # ç›´æ¥å°†æ£€ç´¢ç»“æœä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
            final_answer = context if context else "æŠ±æ­‰ï¼Œæœªèƒ½æ£€ç´¢åˆ°ç›¸å…³å†…å®¹ã€‚"

            # å°†ç»“æœæ·»åŠ åˆ°ä¸¤ä¸ª session çš„å†å²è®°å½•ä¸­ï¼ˆä½œä¸º AI æ¶ˆæ¯ï¼‰
            ai_message = AIMessage(content=final_answer)

            # æ·»åŠ åˆ° generate_answer session
            self.agent.llm.add_message_to_history(
                session_id="generate_answer",
                message=ai_message,
                enable_llm_summary=True
            )
            logger.info(f"ğŸ“ [Retrieve] å·²å°†ç­”æ¡ˆæ·»åŠ åˆ° generate_answer session å†å²")

            # æ·»åŠ åˆ° analyze_intent session
            self.agent.llm.add_message_to_history(
                session_id="analyze_intent",
                message=ai_message,
                enable_llm_summary=True
            )
            logger.info(f"ğŸ“ [Retrieve] å·²å°†ç­”æ¡ˆæ·»åŠ åˆ° analyze_intent session å†å²")

            # æ·»åŠ åˆ° rewrite_query session
            self.agent.llm.add_message_to_history(
                session_id="rewrite_query",
                message=ai_message,
                enable_llm_summary=True
            )
            logger.info(f"ğŸ“ [Retrieve] å·²å°†ç­”æ¡ˆæ·»åŠ åˆ° rewrite_query session å†å²")

            # æ›´æ–° state å¹¶è¿”å›
            state["context"] = context
            state["final_answer"] = final_answer
            state["is_complete"] = True

            logger.info(f"âœ… [Retrieve] ç›´æ¥è¿”å›æ£€ç´¢ç»“æœï¼Œè·³è¿‡ generate_answer èŠ‚ç‚¹")
            return state

        except Exception as e:
            logger.error(f"âŒ [Retrieve] æ£€ç´¢å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())

            logger.error("")
            logger.error("=" * 80)
            logger.error("âŒ [Retrieve] æ£€ç´¢å¤±è´¥")
            logger.error("=" * 80)
            logger.error(f"   - é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error(f"   - å°†ç»§ç»­æ‰§è¡Œ generate_answer èŠ‚ç‚¹")
            logger.error("=" * 80)
            logger.error("")

            # æ›´æ–° state å¹¶è¿”å›ï¼ˆä¸è®¾ç½® final_answerï¼Œè®© generate_answer å¤„ç†ï¼‰
            state["context"] = ""
            return state

    async def generate_answer(self, state: AnswerState) -> AnswerState:
        """
        æ­¥éª¤3ï¼šç”Ÿæˆæœ€ç»ˆå›ç­”

        ç»“åˆæ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœ‰ï¼‰å’Œå†å²å¯¹è¯ï¼ˆç”±LLM Clientè‡ªåŠ¨ç®¡ç†ï¼‰ç”Ÿæˆå›ç­”

        æ³¨æ„ï¼šå¦‚æœ call_retrieval å·²ç»è®¾ç½®äº† final_answerï¼Œåˆ™ç›´æ¥è¿”å›
        """
        from .prompts import AnswerRole

        logger.info("=" * 80)
        logger.info("ğŸ’¬ [Generate] ========== æ­¥éª¤2: ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ ==========")
        logger.info("=" * 80)

        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æœ€ç»ˆç­”æ¡ˆï¼ˆç”± call_retrieval è®¾ç½®ï¼‰
        if state.get("final_answer"):
            logger.info("âœ… [Generate] æ£€æµ‹åˆ°å·²æœ‰æœ€ç»ˆç­”æ¡ˆï¼ˆç”±æ£€ç´¢ä»£ç†æä¾›ï¼‰ï¼Œç›´æ¥è¿”å›")
            logger.info(f"ğŸ“Š [Generate] ç­”æ¡ˆé•¿åº¦: {len(state['final_answer'])} å­—ç¬¦")
            logger.info(f"ğŸ“Š [Generate] ç­”æ¡ˆé¢„è§ˆ: {state['final_answer'][:200]}...")
            logger.info("=" * 80)
            logger.info("")
            return state

        context = state.get("context", "")
        user_query = state['user_query']

        logger.info(f"ğŸ“ [Generate] è¾“å…¥ä¿¡æ¯:")
        logger.info(f"   - ç”¨æˆ·æŸ¥è¯¢: {user_query}")
        logger.info(f"   - æ˜¯å¦æœ‰æ£€ç´¢ä¸Šä¸‹æ–‡: {'æ˜¯' if context else 'å¦'}")
        if context:
            logger.info(f"   - ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
            logger.info(f"   - ä¸Šä¸‹æ–‡é¢„è§ˆ: {context[:150]}...")

        try:
            if context:
                # æœ‰æ£€ç´¢ä¸Šä¸‹æ–‡ - æä¾›æ–‡æ¡£å‚è€ƒå†…å®¹
                prompt = f"""
ç”¨æˆ·é—®é¢˜ï¼š{user_query}

æ–‡æ¡£å‚è€ƒå†…å®¹ï¼š
{context}
"""
                logger.info(f"ğŸ“š [Generate] å›ç­”æ¨¡å¼: æ–‡æ¡£ä¸Šä¸‹æ–‡ + å†å²å¯¹è¯")
            else:
                # æ— æ£€ç´¢ä¸Šä¸‹æ–‡ - ä»…æä¾›ç”¨æˆ·é—®é¢˜
                prompt = f"""
ç”¨æˆ·é—®é¢˜ï¼š{user_query}
"""
                logger.info(f"ğŸ’¬ [Generate] å›ç­”æ¨¡å¼: ä»…å†å²å¯¹è¯")

            logger.info(f"ğŸ¤– [Generate] è°ƒç”¨ LLM ç”Ÿæˆç­”æ¡ˆ...")

            # ä½¿ç”¨ä¸“é—¨çš„å¯¹è¯å¼é—®ç­” roleï¼ˆå†å²å¯¹è¯ç”± LLM Client è‡ªåŠ¨ç®¡ç†ï¼‰
            answer = await self.agent.llm.async_call_llm_chain(
                role=AnswerRole.CONVERSATIONAL_QA,
                input_prompt=prompt,
                session_id="generate_answer"
            )

            answer_preview = answer[:200] if len(answer) > 200 else answer

            logger.info("")
            logger.info("=" * 80)
            logger.info("âœ… [Generate] ç­”æ¡ˆç”Ÿæˆå®Œæˆ")
            logger.info("=" * 80)
            logger.info(f"ğŸ“Š [Generate] è¾“å‡ºä¿¡æ¯:")
            logger.info(f"   - ç­”æ¡ˆé•¿åº¦: {len(answer)} å­—ç¬¦")
            logger.info(f"   - ç­”æ¡ˆé¢„è§ˆ: {answer_preview}...")
            logger.info(f"   - å·¥ä½œæµçŠ¶æ€: å®Œæˆ")
            logger.info("=" * 80)
            logger.info("")

            # æ›´æ–° state å¹¶è¿”å›
            state["final_answer"] = answer
            state["is_complete"] = True
            return state

        except Exception as e:
            logger.error(f"âŒ [Generate] å›ç­”ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())

            error_msg = f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"

            logger.error("")
            logger.error("=" * 80)
            logger.error("âŒ [Generate] ç”Ÿæˆå¤±è´¥")
            logger.error("=" * 80)
            logger.error(f"   - é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error(f"   - è¿”å›é”™è¯¯æ¶ˆæ¯")
            logger.error("=" * 80)
            logger.error("")

            # æ›´æ–° state å¹¶è¿”å›
            state["final_answer"] = error_msg
            state["is_complete"] = True
            return state

    def route_by_intent(self, state: AnswerState) -> str:
        """
        æ ¹æ®æ„å›¾è·¯ç”±åˆ°ä¸åŒèŠ‚ç‚¹

        Returns:
            "retrieve" æˆ– "direct"
        """
        needs_retrieval = state.get("needs_retrieval", False)
        reason = state.get("analysis_reason", "")

        if needs_retrieval:
            logger.info("ğŸ”€ [Route] è·¯ç”±å†³ç­–: éœ€è¦æ£€ç´¢ â†’ call_retrieval èŠ‚ç‚¹")
            logger.info(f"   - åŸå› : {reason}")
            return "retrieve"
        else:
            logger.info("ğŸ”€ [Route] è·¯ç”±å†³ç­–: ç›´æ¥å›ç­” â†’ generate_answer èŠ‚ç‚¹")
            logger.info(f"   - åŸå› : {reason}")
            return "direct"
