"""
Answer Agent - ç”¨æˆ·å¯¹è¯æ¥å£Agent

è´Ÿè´£ï¼š
1. åˆ†æç”¨æˆ·æ„å›¾
2. å†³å®šæ˜¯å¦éœ€è¦æ£€ç´¢
3. è°ƒç”¨Retrieval Agentè·å–ä¸Šä¸‹æ–‡
4. ç”Ÿæˆæœ€ç»ˆå›ç­”
"""

from langgraph.graph import StateGraph, END
from typing import Dict, Optional, List
import logging
import json
import re

from ..base import AgentBase
from .state import AnswerState

logger = logging.getLogger(__name__)


class AnswerAgent(AgentBase):
    """
    å¯¹è¯Agent

    å·¥ä½œæµç¨‹ï¼š
    1. analyze_intent - åˆ†æç”¨æˆ·æ„å›¾
    2. retrieve (å¯é€‰) - è°ƒç”¨Retrieval Agentæ£€ç´¢
    3. generate_answer - ç”Ÿæˆæœ€ç»ˆå›ç­”

    å·¥å…·æ–¹æ³•ï¼ˆç›´æ¥åœ¨ç±»ä¸­å®ç°ï¼‰ï¼š
    - call_retrieval_impl - è°ƒç”¨æ£€ç´¢Agent
    - direct_answer_impl - ç›´æ¥å›ç­”
    """

    def __init__(self, doc_name: str = None):
        super().__init__(name="AnswerAgent")

        # å»¶è¿ŸåŠ è½½Retrieval Agent
        self.retrieval_agent = None

        # å½“å‰æ–‡æ¡£ä¸Šä¸‹æ–‡
        self.current_doc = doc_name

        self.graph = self.build_graph()

    # ==================== å·¥å…·æ–¹æ³•å®ç° ====================

    async def call_retrieval_impl(self, query: str) -> str:
        """
        è°ƒç”¨Retrieval Agentæ£€ç´¢æ–‡æ¡£å†…å®¹ï¼ˆå·¥å…·æ–¹æ³•ï¼‰

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢

        Returns:
            æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å†…å®¹
        """
        logger.info(f"ğŸ” [Tool:call_retrieval] è°ƒç”¨æ£€ç´¢: {query[:50]}...")

        try:
            # å»¶è¿ŸåŠ è½½Retrieval Agent
            if self.retrieval_agent is None:
                from ..retrieval import RetrievalAgent
                self.retrieval_agent = RetrievalAgent(doc_name=self.current_doc)
                logger.info("âœ… Retrieval Agentå·²åŠ è½½")

            # è°ƒç”¨Retrieval Agentçš„graph
            result = await self.retrieval_agent.graph.ainvoke({
                "query": query,
                "doc_name": self.current_doc,
                "tags": None,
                "max_iterations": 5,
                # åˆå§‹åŒ–å…¶ä»–å¿…éœ€å­—æ®µ
                "thoughts": [],
                "actions": [],
                "observations": [],
                "current_iteration": 0,
                "retrieved_content": {},
                "is_complete": False
            })

            # æå–æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
            context = result.get("final_context", "")

            logger.info(f"âœ… [Tool:call_retrieval] æ£€ç´¢å®Œæˆï¼Œä¸Šä¸‹æ–‡é•¿åº¦: {len(context)}")
            return context

        except Exception as e:
            logger.error(f"âŒ [Tool:call_retrieval] æ£€ç´¢å¤±è´¥: {e}")
            return ""

    async def direct_answer_impl(self, query: str) -> str:
        """
        ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼ˆå·¥å…·æ–¹æ³•ï¼‰

        Args:
            query: ç”¨æˆ·é—®é¢˜

        Returns:
            å›ç­”æ–‡æœ¬
        """
        logger.info(f"ğŸ’¬ [Tool:direct_answer] ç›´æ¥å›ç­”: {query[:50]}...")

        try:
            prompt = f"""
è¯·å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¦æ±‚ï¼š
1. ç¤¼è²Œå‹å¥½
2. ç®€æ´æ˜äº†
"""

            # ä½¿ç”¨Agentçš„LLMå®ä¾‹
            answer = await self.llm.async_get_response(prompt)

            logger.info(f"âœ… [Tool:direct_answer] å›ç­”ç”Ÿæˆå®Œæˆ")
            return answer

        except Exception as e:
            logger.error(f"âŒ [Tool:direct_answer] å›ç­”ç”Ÿæˆå¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"

    # ==================== WorkflowèŠ‚ç‚¹æ–¹æ³• ====================

    def build_graph(self) -> StateGraph:
        """æ„å»ºworkflow"""
        workflow = StateGraph(AnswerState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("analyze", self.analyze_intent)
        workflow.add_node("retrieve", self.call_retrieval)
        workflow.add_node("generate", self.generate_answer)

        # æ·»åŠ æ¡ä»¶è¾¹ï¼šæ ¹æ®æ˜¯å¦éœ€è¦æ£€ç´¢é€‰æ‹©è·¯å¾„
        workflow.add_conditional_edges(
            "analyze",
            self.route_by_intent,
            {
                "retrieve": "retrieve",  # éœ€è¦æ£€ç´¢
                "direct": "generate"  # ç›´æ¥å›ç­”
            }
        )

        workflow.add_edge("retrieve", "generate")
        workflow.add_edge("generate", END)

        # è®¾ç½®å…¥å£
        workflow.set_entry_point("analyze")

        return workflow.compile()

    async def analyze_intent(self, state: AnswerState) -> Dict:
        """
        æ­¥éª¤1ï¼šåˆ†æç”¨æˆ·æ„å›¾

        åˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢æ–‡æ¡£å†…å®¹
        """
        logger.info(f"ğŸ¤” [Analyze] åˆ†ææ„å›¾: {state['user_query'][:50]}...")

        try:
            # ä½¿ç”¨Agentçº§åˆ«çš„LLMå®ä¾‹
            llm = self.llm

            prompt = f"""
åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢æ–‡æ¡£å†…å®¹ã€‚

ç”¨æˆ·æŸ¥è¯¢ï¼š{state['user_query']}

å¦‚æœæŸ¥è¯¢æ˜¯ä»¥ä¸‹ç±»å‹ï¼Œéœ€è¦æ£€ç´¢ï¼š
- è¯¢é—®æ–‡æ¡£å…·ä½“å†…å®¹
- éœ€è¦å¼•ç”¨æ–‡æ¡£ç»†èŠ‚
- éœ€è¦æŸ¥æ‰¾ç‰¹å®šä¿¡æ¯

å¦‚æœæŸ¥è¯¢æ˜¯ä»¥ä¸‹ç±»å‹ï¼Œä¸éœ€è¦æ£€ç´¢ï¼š
- æ‰“æ‹›å‘¼ã€é—²èŠ
- ä¸€èˆ¬æ€§é—®é¢˜ï¼ˆä¸æ¶‰åŠæ–‡æ¡£ï¼‰
- è¯·æ±‚å¸®åŠ©ã€è¯´æ˜

è¿”å›JSONæ ¼å¼ï¼š
{{
    "needs_retrieval": true/false,
    "reason": "åˆ¤æ–­åŸå› "
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

            response = await llm.async_get_response(prompt)

            # è§£æJSON
            import json
            import re

            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                needs_retrieval = result.get("needs_retrieval", True)
                reason = result.get("reason", "")
            else:
                # é»˜è®¤éœ€è¦æ£€ç´¢
                needs_retrieval = True
                reason = "é»˜è®¤ç­–ç•¥"

            logger.info(
                f"âœ… [Analyze] æ„å›¾åˆ†æå®Œæˆ: "
                f"{'éœ€è¦æ£€ç´¢' if needs_retrieval else 'ç›´æ¥å›ç­”'} - {reason}"
            )

            return {
                "needs_retrieval": needs_retrieval
            }

        except Exception as e:
            logger.error(f"âŒ [Analyze] æ„å›¾åˆ†æå¤±è´¥: {e}")

            # å¤±è´¥æ—¶é»˜è®¤éœ€è¦æ£€ç´¢
            return {
                "needs_retrieval": True
            }

    def route_by_intent(self, state: AnswerState) -> str:
        """
        æ ¹æ®æ„å›¾è·¯ç”±åˆ°ä¸åŒèŠ‚ç‚¹

        Returns:
            "retrieve" æˆ– "direct"
        """
        if state.get("needs_retrieval", False):
            return "retrieve"
        else:
            return "direct"

    async def call_retrieval(self, state: AnswerState) -> Dict:
        """
        æ­¥éª¤2ï¼šè°ƒç”¨Retrieval Agentæ£€ç´¢ï¼ˆä½¿ç”¨å·¥å…·æ–¹æ³•ï¼‰

        ç¼–æ’Retrieval Agentè¿›è¡Œå†…å®¹æ£€ç´¢
        """
        logger.info(f"ğŸ” [Retrieve] è°ƒç”¨Retrieval Agent")

        try:
            # æ›´æ–°å½“å‰æ–‡æ¡£ä¸Šä¸‹æ–‡
            self.current_doc = state.get("current_doc")

            # è°ƒç”¨å·¥å…·æ–¹æ³•
            context = await self.call_retrieval_impl(state["user_query"])

            return {
                "context": context
            }

        except Exception as e:
            logger.error(f"âŒ [Retrieve] æ£€ç´¢å¤±è´¥: {e}")

            return {
                "context": ""
            }

    async def generate_answer(self, state: AnswerState) -> Dict:
        """
        æ­¥éª¤3ï¼šç”Ÿæˆæœ€ç»ˆå›ç­”ï¼ˆä½¿ç”¨å·¥å…·æ–¹æ³•ï¼‰
        """
        logger.info(f"ğŸ’¬ [Generate] ç”Ÿæˆå›ç­”")

        try:
            context = state.get("context", "")

            if context:
                # æœ‰æ£€ç´¢ä¸Šä¸‹æ–‡ - åŸºäºæ–‡æ¡£å›ç­”
                prompt = f"""
è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{state['user_query']}

ç›¸å…³å†…å®¹ï¼š
{context}

è¦æ±‚ï¼š
1. åŸºäºæ–‡æ¡£å†…å®¹å›ç­”
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. ä¿æŒå›ç­”ç®€æ´å‡†ç¡®
"""
                # ä½¿ç”¨Agentçš„LLMå®ä¾‹
                answer = await self.llm.async_get_response(prompt)
            else:
                # æ— æ£€ç´¢ä¸Šä¸‹æ–‡ - ç›´æ¥å›ç­”
                answer = await self.direct_answer_impl(state['user_query'])

            logger.info(f"âœ… [Generate] å›ç­”ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(answer)}")

            return {
                "final_answer": answer,
                "is_complete": True
            }

        except Exception as e:
            logger.error(f"âŒ [Generate] å›ç­”ç”Ÿæˆå¤±è´¥: {e}")

            return {
                "final_answer": f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}",
                "is_complete": True
            }
