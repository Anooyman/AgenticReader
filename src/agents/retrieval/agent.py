"""
Retrieval Agent - æ™ºèƒ½æ£€ç´¢Agent

ä½¿ç”¨ReActï¼ˆReasoning + Actingï¼‰æ¨¡å¼è¿›è¡Œæ™ºèƒ½æ£€ç´¢
"""

from langgraph.graph import StateGraph, END
from langgraph.types import Command
from typing import Dict, List, Any
import logging
import json
import re

from ..base import AgentBase
from .state import RetrievalState
from src.config.prompts.reader_prompts import ReaderRole
from src.utils.helpers import extract_data_from_LLM_res

logger = logging.getLogger(__name__)


class RetrievalAgent(AgentBase):
    """
    æ£€ç´¢Agentï¼ˆReActæ¨¡å¼ï¼‰

    å·¥ä½œæµç¨‹ï¼ˆå¾ªç¯ï¼‰ï¼š
    1. think - æ€è€ƒä¸‹ä¸€æ­¥ä½¿ç”¨å“ªä¸ªå·¥å…·
    2. act - æ‰§è¡Œå·¥å…·è°ƒç”¨
    3. observe - è§‚å¯Ÿç»“æœ
    4. evaluate - è¯„ä¼°æ˜¯å¦å®Œæˆ

    å·¥å…·æ–¹æ³•ï¼ˆç›´æ¥åœ¨ç±»ä¸­å®ç°ï¼‰ï¼š
    - search_by_context - è¯­ä¹‰ç›¸ä¼¼æ£€ç´¢
    - search_by_title - æŒ‰æ ‡é¢˜æ£€ç´¢
    - get_document_structure - è·å–æ–‡æ¡£ç»“æ„

    æ”¯æŒï¼š
    - å•æ–‡æ¡£æ£€ç´¢ï¼šæŒ‡å®šdoc_name
    - å¤šæ–‡æ¡£æ£€ç´¢ï¼šdoc_name=None
    - æ ‡ç­¾è¿‡æ»¤ï¼šæŒ‡å®štags
    """

    def __init__(self, doc_name: str = None):
        super().__init__(name="RetrievalAgent")

        # å½“å‰æ–‡æ¡£ä¸Šä¸‹æ–‡
        self.current_doc = doc_name
        self.current_tags = None

        # åˆå§‹åŒ– VectorDBClientï¼ˆå¤ç”¨å®ä¾‹ï¼Œé¿å…é‡å¤åŠ è½½ï¼‰
        self.vector_db_client = None
        if doc_name:
            self.vector_db_client = self._create_vector_db_client(doc_name)

        # æ£€ç´¢ç¼“å­˜å­—å…¸ï¼ˆæå‡æ€§èƒ½ï¼Œé¿å…é‡å¤æ£€ç´¢ï¼‰
        self.retrieval_data_dict: Dict[str, Any] = {}

        self.graph = self.build_graph()

    def _get_db_path_from_doc_name(self, doc_name: str) -> str:
        """
        å°†æ–‡æ¡£åç§°è½¬æ¢ä¸ºå‘é‡æ•°æ®åº“è·¯å¾„

        Args:
            doc_name: æ–‡æ¡£åç§°

        Returns:
            str: å‘é‡æ•°æ®åº“çš„å®Œæ•´è·¯å¾„
        """
        from pathlib import Path
        from src.config.settings import DATA_ROOT

        db_path = Path(DATA_ROOT) / "vector_db" / doc_name
        return str(db_path)

    def _create_vector_db_client(self, doc_name: str):
        """
        åˆ›å»º VectorDBClient å®ä¾‹

        Args:
            doc_name: æ–‡æ¡£åç§°

        Returns:
            VectorDBClient: å‘é‡æ•°æ®åº“å®¢æˆ·ç«¯å®ä¾‹
        """
        from src.core.vector_db.vector_db_client import VectorDBClient

        db_path = self._get_db_path_from_doc_name(doc_name)

        # ä½¿ç”¨ä¾èµ–æ³¨å…¥ï¼Œä¼ å…¥ embedding_model
        client = VectorDBClient(
            db_path=db_path,
            embedding_model=self.embedding_model
        )

        logger.info(f"âœ… [VectorDB] å·²åˆ›å»ºå‘é‡æ•°æ®åº“å®¢æˆ·ç«¯: {doc_name}")
        return client

    def _build_retrieval_tools(self) -> Dict[str, Dict]:
        """
        ä»é…ç½®æ–‡ä»¶æ„å»ºæ£€ç´¢å·¥å…·å­—å…¸

        å·¥å…·é…ç½®æ¥æºï¼šsrc/config/tools/retrieval_tools.py

        Returns:
            å·¥å…·å­—å…¸ï¼Œkeyä¸ºå·¥å…·åç§°ï¼ŒvalueåŒ…å«å·¥å…·è¯¦ç»†ä¿¡æ¯
        """
        from src.config.tools.retrieval_tools import get_enabled_tools

        tools = {}
        enabled_tools = get_enabled_tools()

        for tool_config in enabled_tools:
            tool_name = tool_config["name"]
            method_name = tool_config["method_name"]

            # è·å–å¯¹åº”çš„æ–¹æ³•
            if hasattr(self, method_name):
                tool_method = getattr(self, method_name)

                tools[tool_name] = {
                    "name": tool_name,
                    "description": tool_config["description"],
                    "parameters": tool_config["parameters"],
                    "function": tool_method,
                    "priority": tool_config.get("priority", 999),
                }

                logger.debug(f"å·²åŠ è½½å·¥å…·: {tool_name} (æ–¹æ³•: {method_name})")
            else:
                logger.warning(f"å·¥å…· '{tool_name}' é…ç½®çš„æ–¹æ³• '{method_name}' æœªæ‰¾åˆ°")

        logger.info(f"æˆåŠŸåŠ è½½ {len(tools)} ä¸ªæ£€ç´¢å·¥å…·")
        return tools

    def _get_agenda_dict_from_vector_db(self) -> Dict[str, Any]:
        """
        ä»å‘é‡æ•°æ®åº“è·å– agenda_dictï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        ä» type="structure" æ–‡æ¡£ä¸­æå– agenda_dict å…ƒæ•°æ®ã€‚

        Returns:
            agenda_dict å­—å…¸ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›ç©ºå­—å…¸
        """
        if not self.vector_db_client:
            logger.warning("âš ï¸ [_get_agenda_dict_from_vector_db] VectorDBClient æœªåˆå§‹åŒ–")
            return {}

        try:
            doc_res = self.vector_db_client.search_with_metadata_filter(
                query="",
                k=1,
                field_name="type",
                field_value="structure",
                enable_dedup=False
            )

            if doc_res and len(doc_res) > 0:
                document = doc_res[0][0] if isinstance(doc_res[0], tuple) else doc_res[0]
                agenda_dict = document.metadata.get("agenda_dict", {})
                logger.debug(f"âœ… [_get_agenda_dict_from_vector_db] è·å–åˆ° agenda_dictï¼Œå…± {len(agenda_dict)} ä¸ªç« èŠ‚")
                return agenda_dict
            else:
                logger.warning("âš ï¸ [_get_agenda_dict_from_vector_db] æœªæ‰¾åˆ°æ–‡æ¡£ç»“æ„ä¿¡æ¯")
                return {}

        except Exception as e:
            logger.error(f"âŒ [_get_agenda_dict_from_vector_db] è·å– agenda_dict å¤±è´¥: {e}")
            return {}

    # ==================== å·¥å…·æ–¹æ³•å®ç° ====================

    async def search_by_context(self, query: str) -> List[str]:
        """
        åŸºäºä¸Šä¸‹æ–‡çš„è¯­ä¹‰æ£€ç´¢æ–¹æ³•

        é€šè¿‡å‘é‡ç›¸ä¼¼åº¦æœç´¢åœ¨æ–‡æ¡£ä¸­æŸ¥æ‰¾ä¸æŸ¥è¯¢è¯­ä¹‰ç›¸å…³çš„å†…å®¹æ®µè½ã€‚
        è¿™ä¸ªæ–¹æ³•ä½¿ç”¨å‘é‡æ•°æ®åº“çš„è¯­ä¹‰æœç´¢åŠŸèƒ½ï¼Œèƒ½å¤Ÿç†è§£æŸ¥è¯¢çš„è¯­ä¹‰å«ä¹‰ï¼Œ
        å¹¶æ‰¾åˆ°åœ¨è¯­ä¹‰ä¸Šç›¸å…³çš„æ–‡æ¡£å†…å®¹ï¼Œå³ä½¿å…³é”®è¯ä¸å®Œå…¨åŒ¹é…ã€‚

        Args:
            query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œåº”æè¿°è¦æŸ¥æ‰¾çš„å†…å®¹è¯­ä¹‰

        Returns:
            æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£å†…å®¹åˆ—è¡¨
        """
        if not query or not query.strip():
            logger.warning("âŒ [Tool:search_by_context] æŸ¥è¯¢å­—ç¬¦ä¸²ä¸ºç©º")
            return []

        if not self.vector_db_client:
            logger.error("âŒ [Tool:search_by_context] å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
            return []

        try:
            # ä½¿ç”¨ type='context' è¿‡æ»¤å™¨è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œå¯ç”¨å»é‡
            doc_res = self.vector_db_client.search_with_metadata_filter(
                query=query,
                k=3,  # ä¸æ—§å®ç°ä¿æŒä¸€è‡´
                field_name="type",
                field_value="context",
                enable_dedup=True
            )

            context_data = []
            chapter_info_list = []  # å­˜å‚¨ç« èŠ‚ä¿¡æ¯ç”¨äºæ±‡æ€»

            if doc_res and len(doc_res) > 0:
                for idx, doc_item in enumerate(doc_res):
                    try:
                        # è§£ææ–‡æ¡£ç»“æ„
                        document = doc_item[0] if isinstance(doc_item, tuple) else doc_item
                        metadata = document.metadata

                        refactor_data = metadata.get("refactor", "")
                        raw_data = metadata.get("raw_data", {})
                        page_number = list(raw_data.keys()) if isinstance(raw_data, dict) else []

                        # æå–ç« èŠ‚æ ‡é¢˜ä¿¡æ¯
                        chapter_title = metadata.get("title", "æœªçŸ¥ç« èŠ‚")

                        # æ•´ç†å¹¶è¿”å›æ£€ç´¢åˆ°çš„æ•°æ®ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
                        if refactor_data and refactor_data.strip():
                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå†…å®¹ï¼ˆå»é‡ï¼‰
                            existing_contents = [item["content"] for item in context_data]
                            if refactor_data not in existing_contents:
                                # è¿”å›ç»“æ„åŒ–æ•°æ®ï¼šåŒ…å«å†…å®¹å’Œå…ƒæ•°æ®
                                context_data.append({
                                    "content": refactor_data,
                                    "title": chapter_title,
                                    "pages": sorted(page_number, key=lambda x: int(x) if str(x).isdigit() else 0) if page_number else []
                                })

                                # è®°å½•ç« èŠ‚ä¿¡æ¯ç”¨äºæ—¥å¿—æ±‡æ€»
                                chapter_info_list.append({
                                    "title": chapter_title,
                                    "pages": sorted(page_number, key=lambda x: int(x) if str(x).isdigit() else 0) if page_number else []
                                })

                    except Exception as e:
                        logger.error(f"âŒ [Tool:search_by_context] å¤„ç†ç¬¬ {idx+1} ä¸ªæ–‡æ¡£æ—¶å‡ºé”™: {e}")
                        continue

                # ========== æ±‡æ€»æ—¥å¿— ==========
                logger.info("")
                logger.info("=" * 60)
                logger.info("âœ… [CONTEXT RETRIEVAL] ä¸Šä¸‹æ–‡æ£€ç´¢ç»“æœ")
                logger.info("=" * 60)
                logger.info(f"ğŸ“Š è¿”å› {len(context_data)} æ¡å†…å®¹ç‰‡æ®µ")

                # æ˜¾ç¤ºæœ¬æ¬¡è¿”å›å†…å®¹å¯¹åº”çš„ç« èŠ‚å’Œé¡µç 
                if chapter_info_list:
                    logger.info("ğŸ“š æ£€ç´¢åˆ°çš„ç« èŠ‚:")
                    for idx, chapter in enumerate(chapter_info_list, 1):
                        pages_str = f"é¡µç : {', '.join(map(str, chapter['pages']))}" if chapter['pages'] else "æ— é¡µç "
                        logger.info(f"   {idx}. {chapter['title']} ({pages_str})")
                else:
                    logger.info("ğŸ“š æœªæ£€ç´¢åˆ°ä»»ä½•ç« èŠ‚")

                logger.info("=" * 60)
                logger.info("")
            else:
                logger.warning("âš ï¸ [Tool:search_by_context] åœ¨å‘é‡æ•°æ®åº“ä¸­æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ç›¸å…³çš„å†…å®¹")

            return context_data

        except Exception as e:
            logger.error(f"âŒ [Tool:search_by_context] é€šè¿‡ä¸Šä¸‹æ–‡æ£€ç´¢æ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)
            return []

    async def extract_titles_from_structure(self, query: str) -> List[str]:
        """
        ä»æ–‡æ¡£ç»“æ„ä¸­æå–ç›¸å…³æ ‡é¢˜åˆ—è¡¨

        æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ï¼Œä» type="structure" æ–‡æ¡£ä¸­è·å– agenda_dictï¼Œ
        ç„¶åä½¿ç”¨ LLM æ™ºèƒ½æå–ä¸æŸ¥è¯¢ç›¸å…³çš„ç« èŠ‚æ ‡é¢˜ã€‚

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢å­—ç¬¦ä¸²

        Returns:
            æå–åˆ°çš„æ ‡é¢˜åˆ—è¡¨
        """
        logger.info(f"ğŸ“‹ [Tool:extract_titles_from_structure] ä»ç»“æ„ä¸­æå–æ ‡é¢˜: {query[:50]}...")

        if not query or not query.strip():
            logger.warning("âŒ [Tool:extract_titles_from_structure] æŸ¥è¯¢å­—ç¬¦ä¸²ä¸ºç©º")
            return []

        if not self.vector_db_client:
            logger.error("âŒ [Tool:extract_titles_from_structure] VectorDBClient æœªåˆå§‹åŒ–")
            return []

        try:
            # æ­¥éª¤1: ä»å‘é‡æ•°æ®åº“è·å– agenda_dict
            agenda_dict = self._get_agenda_dict_from_vector_db()

            if not agenda_dict:
                logger.warning("âš ï¸ [Tool:extract_titles_from_structure] æœªæ‰¾åˆ°æ–‡æ¡£ç»“æ„ä¿¡æ¯")
                return []

            # æ­¥éª¤2: ä½¿ç”¨ LLM æå–æ ‡é¢˜åˆ—è¡¨
            response = self.llm.call_llm_chain(
                ReaderRole.CHAPTER_MATCHER,
                query,
                "chapter_matcher",
                system_format_dict={
                    "agenda_dict": agenda_dict
                }
            )

            response_data = extract_data_from_LLM_res(response)
            title_list = response_data.get("title", [])

            # éªŒè¯ç»“æœ
            if not isinstance(title_list, list):
                logger.warning("âš ï¸ [Tool:extract_titles_from_structure] æ ‡é¢˜åˆ—è¡¨æ ¼å¼æ— æ•ˆ")
                return []

            logger.info(f"âœ… [Tool:extract_titles_from_structure] æå–åˆ° {len(title_list)} ä¸ªæ ‡é¢˜: {title_list}")
            return title_list

        except Exception as e:
            logger.error(f"âŒ [Tool:extract_titles_from_structure] æå–æ ‡é¢˜å¤±è´¥: {e}", exc_info=True)
            return []

    async def search_by_title(self, title_list: str) -> List[str]:
        """
        åŸºäºæ ‡é¢˜åˆ—è¡¨çš„ç²¾ç¡®æ£€ç´¢å·¥å…·

        æ ¹æ®ç»™å®šçš„æ ‡é¢˜åˆ—è¡¨ï¼Œåœ¨å‘é‡æ•°æ®åº“ä¸­ç²¾ç¡®åŒ¹é…è¿™äº›æ ‡é¢˜æ¥æ£€ç´¢å¯¹åº”çš„æ–‡æ¡£å†…å®¹ã€‚

        Args:
            title_list: æ ‡é¢˜åˆ—è¡¨ï¼ˆJSONæ ¼å¼å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰

        Returns:
            æ£€ç´¢åˆ°çš„åŒ¹é…æ ‡é¢˜çš„æ–‡æ¡£å†…å®¹åˆ—è¡¨
        """
        logger.info(f"ğŸ“‘ [Tool:search_by_title] æ ‡é¢˜æ£€ç´¢: {title_list}")

        if not self.vector_db_client:
            logger.error("âŒ [Tool:search_by_title] VectorDBClient æœªåˆå§‹åŒ–")
            return []

        try:
            # è§£æ title_listï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            if isinstance(title_list, str):
                # å°è¯•è§£æä¸ºJSON
                try:
                    parsed_list = json.loads(title_list)
                    if isinstance(parsed_list, list):
                        title_list = parsed_list
                    else:
                        logger.warning("âš ï¸ [Tool:search_by_title] è§£æåçš„æ•°æ®ä¸æ˜¯åˆ—è¡¨")
                        return []
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯JSONï¼ŒæŒ‰é€—å·åˆ†å‰²
                    title_list = [t.strip() for t in title_list.split(',') if t.strip()]

            # è¾“å…¥éªŒè¯
            if not isinstance(title_list, list):
                logger.warning("âš ï¸ [Tool:search_by_title] æ ‡é¢˜åˆ—è¡¨æ ¼å¼æ— æ•ˆï¼ŒæœŸæœ›listç±»å‹")
                return []

            if len(title_list) == 0:
                logger.info("â„¹ï¸ [Tool:search_by_title] æ ‡é¢˜åˆ—è¡¨ä¸ºç©ºï¼Œè¿”å›ç©ºç»“æœ")
                return []

            logger.info(f"ğŸ“ [Tool:search_by_title] å¤„ç† {len(title_list)} ä¸ªæ ‡é¢˜: {title_list}")

        except Exception as e:
            logger.error(f"âŒ [Tool:search_by_title] è§£ææ ‡é¢˜åˆ—è¡¨å¤±è´¥: {e}")
            return []

        # éå†æ ‡é¢˜åˆ—è¡¨ï¼Œæ£€ç´¢å¯¹åº”å†…å®¹
        context_data = []
        successful_retrievals = 0
        cache_hits = 0
        returned_titles = []  # è¿½è¸ªå®é™…è¿”å›çš„æ ‡é¢˜

        for title in title_list:
            if not title or not isinstance(title, str):
                continue

            title = title.strip()
            if not title:
                continue

            try:
                refactor_data = ""
                page_number = []
                is_from_cache = False

                # æ£€æŸ¥ç¼“å­˜
                if title in self.retrieval_data_dict:
                    cached_data = self.retrieval_data_dict[title]
                    refactor_data = cached_data.get("data", "")
                    page_number = cached_data.get("page", [])
                    cache_hits += 1
                    is_from_cache = True
                else:
                    # ä»å‘é‡æ•°æ®åº“æ£€ç´¢ï¼ˆä»…æ£€ç´¢ type='title' çš„æ–‡æ¡£ï¼‰
                    try:
                        doc_res = self.vector_db_client.search_by_title(
                            title,
                            doc_type="title",
                            enable_dedup=True
                        )

                        if doc_res and len(doc_res) > 0:
                            # å¤„ç†è¿”å›çš„åˆ—è¡¨ä¸­çš„æ¯ä¸ªæ–‡æ¡£
                            all_refactor_data = []
                            all_page_numbers = []

                            for doc_item in doc_res:
                                document = doc_item[0] if isinstance(doc_item, tuple) else doc_item
                                metadata = document.metadata

                                item_refactor_data = metadata.get("refactor", "")
                                item_raw_data = metadata.get("raw_data", {})
                                item_page_numbers = list(item_raw_data.keys()) if isinstance(item_raw_data, dict) else []

                                if item_refactor_data and item_refactor_data.strip():
                                    all_refactor_data.append(item_refactor_data)

                                if item_page_numbers:
                                    all_page_numbers.extend(item_page_numbers)

                            # åˆå¹¶æ‰€æœ‰æ£€ç´¢åˆ°çš„æ•°æ®
                            refactor_data = "\n\n".join(all_refactor_data) if all_refactor_data else ""
                            page_number = list(set(all_page_numbers))  # å»é‡é¡µé¢ç¼–å·

                            # ç¼“å­˜æ£€ç´¢ç»“æœ
                            self.retrieval_data_dict[title] = {
                                "data": refactor_data,
                                "page": page_number
                            }

                            successful_retrievals += 1
                        else:
                            logger.warning(f"âš ï¸ [Tool:search_by_title] ç« èŠ‚ '{title}' åœ¨å‘é‡æ•°æ®åº“ä¸­æœªæ‰¾åˆ°")

                    except Exception as e:
                        logger.error(f"âŒ [Tool:search_by_title] æ£€ç´¢ç« èŠ‚ '{title}' æ—¶å‡ºé”™: {e}")
                        continue

                # æ·»åŠ åˆ°ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆå»é‡ï¼‰ï¼ŒåŒ…å«å…ƒæ•°æ®
                if refactor_data and refactor_data.strip():
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå†…å®¹
                    existing_contents = [item["content"] if isinstance(item, dict) else item for item in context_data]
                    if refactor_data not in existing_contents:
                        # è¿”å›ç»“æ„åŒ–æ•°æ®ï¼šåŒ…å«å†…å®¹å’Œå…ƒæ•°æ®
                        context_data.append({
                            "content": refactor_data,
                            "title": title,
                            "pages": sorted(page_number, key=lambda x: int(x) if str(x).isdigit() else 0) if page_number else []
                        })
                        # è®°å½•ç”¨äºæ—¥å¿—æ±‡æ€»
                        returned_titles.append({
                            "title": title,
                            "pages": page_number,
                            "from_cache": is_from_cache
                        })

            except Exception as e:
                logger.error(f"âŒ [Tool:search_by_title] å¤„ç†ç« èŠ‚ '{title}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue

        # ========== æ±‡æ€»æ—¥å¿— ==========
        logger.info("")
        logger.info("=" * 60)
        logger.info("âœ… [TITLE RETRIEVAL] æ ‡é¢˜æ£€ç´¢ç»“æœ")
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š è¿”å› {len(context_data)} æ¡å†…å®¹ç‰‡æ®µ (æ–°æ£€ç´¢: {successful_retrievals}, ç¼“å­˜: {cache_hits})")

        # æ˜¾ç¤ºæœ¬æ¬¡å®é™…è¿”å›çš„ç« èŠ‚å’Œé¡µç 
        if returned_titles:
            logger.info("ğŸ“š æœ¬æ¬¡è¿”å›çš„ç« èŠ‚:")
            for item in returned_titles:
                title = item["title"]
                pages = item["pages"]
                from_cache = item.get("from_cache", False)

                cache_tag = " [ç¼“å­˜]" if from_cache else " [æ–°æ£€ç´¢]"

                if pages:
                    sorted_pages = sorted(pages, key=lambda x: int(x) if str(x).isdigit() else 0)
                    pages_str = f"é¡µç : {', '.join(map(str, sorted_pages))}"
                else:
                    pages_str = "æ— é¡µç "
                logger.info(f"   âœ“ {title} ({pages_str}){cache_tag}")
        else:
            logger.info("ğŸ“š æœªæ£€ç´¢åˆ°ä»»ä½•å†…å®¹")

        logger.info("=" * 60)
        logger.info("")

        return context_data

    async def get_document_structure(self, query: str = "") -> List[str]:
        """
        è·å–æ–‡æ¡£çš„ç›®å½•ç»“æ„å·¥å…·

        ä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢ type="structure" çš„ç‰¹æ®Šæ–‡æ¡£ï¼Œè·å–æ–‡æ¡£ç»“æ„ä¿¡æ¯ã€‚

        Args:
            query: æŸ¥è¯¢å‚æ•°ï¼ˆæ­¤å·¥å…·ä¸éœ€è¦å…·ä½“æŸ¥è¯¢å†…å®¹ï¼Œä¿ç•™ç”¨äºæ¥å£å…¼å®¹ï¼‰

        Returns:
            æ–‡æ¡£ç›®å½•ç»“æ„åˆ—è¡¨
        """
        _ = query  # å‚æ•°ä¿ç•™ç”¨äºæ¥å£å…¼å®¹ï¼Œå®é™…ä¸ä½¿ç”¨
        logger.info(f"ğŸ“š [Tool:get_document_structure] ä»å‘é‡æ•°æ®åº“è·å–æ–‡æ¡£ç»“æ„")

        if not self.vector_db_client:
            logger.error("âŒ [Tool:get_document_structure] VectorDBClient æœªåˆå§‹åŒ–")
            return ["æ–‡æ¡£ç»“æ„ä¿¡æ¯ä¸å¯ç”¨ï¼ˆå‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–ï¼‰"]

        try:
            # è·å– agenda_dict
            agenda_dict = self._get_agenda_dict_from_vector_db()

            if not agenda_dict:
                logger.warning("âš ï¸ [Tool:get_document_structure] æ–‡æ¡£ç»“æ„ä¿¡æ¯ä¸ºç©º")
                return ["æ–‡æ¡£ç›®å½•ä¿¡æ¯ä¸å¯ç”¨"]

            # æ ¼å¼åŒ–ç›®å½•ç»“æ„
            structure_list = []
            structure_list.append("=" * 60)
            structure_list.append("ğŸ“‘ æ–‡æ¡£ç›®å½•ç»“æ„")
            structure_list.append("=" * 60)

            for title, page_info in agenda_dict.items():
                if isinstance(page_info, list):
                    if len(page_info) == 0:
                        page_str = "é¡µç æœªçŸ¥"
                    elif len(page_info) == 1:
                        page_str = f"é¡µç : {page_info[0]}"
                    else:
                        sorted_pages = sorted(page_info, key=lambda x: int(x) if str(x).isdigit() else 0)
                        page_str = f"é¡µç : {sorted_pages[0]}-{sorted_pages[-1]}"
                else:
                    page_str = f"é¡µç : {page_info}"

                structure_list.append(f"{title} ({page_str})")

            structure_list.append("=" * 60)

            logger.info(f"âœ… [Tool:get_document_structure] è·å–åˆ° {len(agenda_dict)} ä¸ªç« èŠ‚")
            return structure_list

        except Exception as e:
            logger.error(f"âŒ [Tool:get_document_structure] è·å–å¤±è´¥: {e}", exc_info=True)
            return ["æ–‡æ¡£ç»“æ„ä¿¡æ¯ä¸å¯ç”¨"]

    # ==================== WorkflowèŠ‚ç‚¹æ–¹æ³• ====================

    def build_graph(self) -> StateGraph:
        """æ„å»ºReAct workflow"""
        workflow = StateGraph(RetrievalState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("initialize", self.initialize)
        workflow.add_node("think", self.think)
        workflow.add_node("act", self.act)
        workflow.add_node("observe", self.observe)
        workflow.add_node("evaluate", self.evaluate)
        workflow.add_node("summary", self.summary)

        # æ·»åŠ è¾¹
        workflow.add_edge("initialize", "think")
        workflow.add_edge("think", "act")
        workflow.add_edge("act", "observe")
        workflow.add_edge("observe", "evaluate")

        # æ¡ä»¶è¾¹ï¼šæ ¹æ®è¯„ä¼°ç»“æœå†³å®šç»§ç»­æˆ–ç»“æŸ
        workflow.add_conditional_edges(
            "evaluate",
            self.should_continue,
            {
                "continue": "think",  # ç»§ç»­å¾ªç¯
                "finish": "summary"  # å…ˆåˆ° summary èŠ‚ç‚¹æ€»ç»“
            }
        )

        # summary èŠ‚ç‚¹å®Œæˆååˆ° END
        workflow.add_edge("summary", END)

        # è®¾ç½®å…¥å£
        workflow.set_entry_point("initialize")

        return workflow.compile()

    def _validate_state(self, state: RetrievalState) -> None:
        """
        éªŒè¯stateçš„å®Œæ•´æ€§

        Args:
            state: RetrievalStateå¯¹è±¡

        Raises:
            ValueError: ç¼ºå°‘å¿…éœ€å­—æ®µæ—¶æŠ›å‡ºå¼‚å¸¸
        """
        required_fields = ['query', 'max_iterations']

        for field in required_fields:
            if field not in state:
                raise ValueError(f"âŒ [Validate] Stateç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")

        # éªŒè¯å­—æ®µç±»å‹å’Œå€¼
        if not isinstance(state.get('query', ''), str) or not state.get('query', '').strip():
            raise ValueError("âŒ [Validate] queryå­—æ®µå¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")

        max_iterations = state.get('max_iterations', 0)
        if not isinstance(max_iterations, int) or max_iterations <= 0:
            raise ValueError("âŒ [Validate] max_iterationså¿…é¡»æ˜¯æ­£æ•´æ•°")

        logger.debug(f"âœ… [Validate] StateéªŒè¯é€šè¿‡")

    async def initialize(self, state: RetrievalState) -> Dict:
        """
        åˆå§‹åŒ–èŠ‚ç‚¹ï¼šè®¾ç½®Agentçš„ä¸Šä¸‹æ–‡ç¯å¢ƒ

        åœ¨workflowå¼€å§‹æ—¶æ‰§è¡Œä¸€æ¬¡ï¼ŒåŒ…æ‹¬ï¼š
        1. éªŒè¯stateå®Œæ•´æ€§
        2. è®¾ç½®æ–‡æ¡£ä¸Šä¸‹æ–‡
        3. åˆ›å»ºæˆ–æ›´æ–° VectorDBClient
        4. åˆå§‹åŒ–å¿…è¦çš„stateå­—æ®µ
        """
        try:
            # éªŒè¯state
            self._validate_state(state)

            # ä»stateä¸­è¯»å–å¹¶è®¾ç½®æ–‡æ¡£ä¸Šä¸‹æ–‡
            doc_name_from_state = state.get('doc_name')
            self.current_doc = doc_name_from_state or self.current_doc
            self.current_tags = state.get('tags')

            logger.info(f"ğŸ”§ [Initialize] æ–‡æ¡£ä¸Šä¸‹æ–‡: {self.current_doc}, æ ‡ç­¾: {self.current_tags}")
            logger.info(f"ğŸ”§ [Initialize] æŸ¥è¯¢: {state['query'][:50]}...")
            logger.info(f"ğŸ”§ [Initialize] æœ€å¤§è¿­ä»£æ¬¡æ•°: {state['max_iterations']}")

            # åˆ›å»ºæˆ–æ›´æ–° VectorDBClientï¼ˆå¦‚æœæ–‡æ¡£åç§°å˜åŒ–ï¼‰
            if self.current_doc:
                if self.vector_db_client is None:
                    # é¦–æ¬¡åˆ›å»º
                    self.vector_db_client = self._create_vector_db_client(self.current_doc)
                    logger.info(f"âœ… [Initialize] VectorDBClient å·²åˆ›å»ºå¹¶åŠ è½½")

                elif doc_name_from_state and doc_name_from_state != self.current_doc:
                    # æ–‡æ¡£åç§°å˜åŒ–ï¼Œé‡æ–°åˆ›å»º
                    logger.info(f"ğŸ”„ [Initialize] æ–‡æ¡£åç§°å˜åŒ–ï¼Œé‡æ–°åˆ›å»ºVectorDBClient")
                    self.vector_db_client = self._create_vector_db_client(doc_name_from_state)
                    self.current_doc = doc_name_from_state
            else:
                logger.warning(f"âš ï¸ [Initialize] æœªæŒ‡å®šæ–‡æ¡£åç§°ï¼ŒæŸäº›æ£€ç´¢åŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨")

            # åˆå§‹åŒ–å¿…è¦çš„stateå­—æ®µ
            if 'retrieved_content' not in state:
                state['retrieved_content'] = {}

            if 'thoughts' not in state:
                state['thoughts'] = []

            if 'actions' not in state:
                state['actions'] = []

            if 'observations' not in state:
                state['observations'] = []

            if 'current_iteration' not in state:
                state['current_iteration'] = 0

            logger.info(f"âœ… [Initialize] åˆå§‹åŒ–å®Œæˆ")
            return state

        except ValueError as e:
            logger.error(f"âŒ [Initialize] çŠ¶æ€éªŒè¯å¤±è´¥: {e}")
            raise
        except Exception as e:
            logger.error(f"âŒ [Initialize] åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            raise

    async def think(self, state: RetrievalState) -> Dict:
        """
        æ­¥éª¤1ï¼šæ€è€ƒä¸‹ä¸€æ­¥ä½¿ç”¨å“ªä¸ªå·¥å…·

        åŸºäºå½“å‰æŸ¥è¯¢å’Œå·²æ£€ç´¢å†…å®¹ï¼Œå†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œ
        """
        current_iteration = state.get("current_iteration", 0)

        logger.info(
            f"ğŸ¤” [Think] è¿­ä»£ {current_iteration + 1}/{state['max_iterations']}"
        )

        try:
            # è·å–å·¥å…·æè¿°ï¼ˆä»é…ç½®æ–‡ä»¶ï¼‰
            from src.config.tools.retrieval_tools import format_all_tools_for_llm
            tools_description = format_all_tools_for_llm()

            # æ„å»ºpromptï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ£€ç´¢åŠ©æ‰‹ã€‚å½“å‰ä»»åŠ¡æ˜¯ä¸ºç”¨æˆ·æŸ¥è¯¢æ£€ç´¢ç›¸å…³å†…å®¹ã€‚

ç”¨æˆ·æŸ¥è¯¢ï¼š{state['query']}
å½“å‰å·²æ£€ç´¢åˆ° {len(state.get('retrieved_content', {{}}))} ä¸ªå†…å®¹ç‰‡æ®µã€‚

å·²æ‰§è¡Œçš„åŠ¨ä½œï¼š
{state.get('actions', [])}

å¯ç”¨å·¥å…·ï¼š
{tools_description}

è¯·é€‰æ‹©ä¸‹ä¸€æ­¥ä½¿ç”¨å“ªä¸ªå·¥å…·ï¼Œå¹¶æä¾›æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚

è¿”å›JSONæ ¼å¼ï¼š
{{
    "thought": "ä½ çš„æ€è€ƒè¿‡ç¨‹",
    "action": "å·¥å…·åç§°",
    "action_input": "æŸ¥è¯¢å­—ç¬¦ä¸²"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

            # ä½¿ç”¨ async_call_llm_chain
            session_id = f"retrieval_{state.get('doc_name', 'default')}"
            response = await self.llm.async_call_llm_chain(
                role=ReaderRole.RETRIEVAL,
                input_prompt=prompt,
                session_id=session_id,
                system_format_dict={"tool_info_dict": tools_description}
            )

            # è§£æJSON - æ›´å¥å£®çš„è§£ææ–¹æ³•
            decision = None
            try:
                # æ–¹æ³•1: å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                decision = json.loads(response.strip())
            except json.JSONDecodeError:
                try:
                    # æ–¹æ³•2: ä½¿ç”¨æ­£åˆ™æå–JSONå¯¹è±¡ï¼ˆéè´ªå©ªåŒ¹é…ï¼Œå¤„ç†åµŒå¥—ï¼‰
                    json_match = re.search(r'\{(?:[^{}]|(?:\{[^{}]*\}))*\}', response, re.DOTALL)
                    if json_match:
                        decision = json.loads(json_match.group())
                except (json.JSONDecodeError, AttributeError) as e:
                    logger.warning(f"âš ï¸ [Think] JSONè§£æå¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤ç­–ç•¥")

            # æå–å†³ç­–å­—æ®µ
            if decision and isinstance(decision, dict):
                thought = decision.get("thought", "")
                action = decision.get("action", "search_by_context")
                action_input = decision.get("action_input", state["query"])
            else:
                # é»˜è®¤ä½¿ç”¨è¯­ä¹‰æ£€ç´¢
                thought = "é»˜è®¤ç­–ç•¥ï¼šJSONè§£æå¤±è´¥"
                action = "search_by_context"
                action_input = state["query"]

            logger.info(f"ğŸ’¡ [Think] é€‰æ‹©å·¥å…·: {action}")
            logger.debug(f"æ€è€ƒè¿‡ç¨‹: {thought}")

            # æ›´æ–°çŠ¶æ€
            state["thoughts"] = state.get("thoughts", []) + [thought]
            state["current_tool"] = action
            state["current_params"] = {"query": action_input}
            state["current_iteration"] = current_iteration + 1

            return state

        except Exception as e:
            logger.error(f"âŒ [Think] æ€è€ƒå¤±è´¥: {e}")

            # å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤ç­–ç•¥
            state["current_tool"] = "search_by_context"
            state["current_params"] = {"query": state["query"]}
            state["thoughts"] = state.get("thoughts", []) + ["æ€è€ƒå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥"]
            state["current_iteration"] = current_iteration + 1

            return state

    async def act(self, state: RetrievalState) -> Dict:
        """
        æ­¥éª¤2ï¼šæ‰§è¡Œå·¥å…·è°ƒç”¨

        æ”¯æŒå¤šç§å‚æ•°ä¼ é€’æ–¹å¼ï¼š
        - å•å‚æ•°å·¥å…·ï¼šparams = {"query": "..."}
        - å¤šå‚æ•°å·¥å…·ï¼šparams = {"query": "...", "k": 5, "doc_type": "title"}
        """
        tool_name = state["current_tool"]
        params = state.get("current_params", {})

        logger.info(f"ğŸ”§ [Act] æ‰§è¡Œå·¥å…·: {tool_name}")
        logger.debug(f"å‚æ•°: {params}")

        try:
            # æ„å»ºå¯ç”¨å·¥å…·å­—å…¸
            available_tools = self._build_retrieval_tools()

            # æ‰§è¡Œå·¥å…·
            if tool_name in available_tools:
                tool_func = available_tools[tool_name]["function"]

                # æ™ºèƒ½å‚æ•°ä¼ é€’ï¼šæ£€æŸ¥å‡½æ•°ç­¾å
                import inspect
                sig = inspect.signature(tool_func)
                func_params = list(sig.parameters.keys())

                # å¦‚æœå‡½æ•°åªæ¥å—ä¸€ä¸ªå‚æ•°ï¼ˆé™¤äº†selfï¼‰ï¼Œç›´æ¥ä¼ query
                if len(func_params) == 1 and 'query' in params:
                    result = await tool_func(params['query'])
                # å¦åˆ™å°è¯•è§£åŒ…æ‰€æœ‰å‚æ•°
                else:
                    # è¿‡æ»¤å‡ºå‡½æ•°å®é™…éœ€è¦çš„å‚æ•°
                    filtered_params = {k: v for k, v in params.items() if k in func_params}
                    result = await tool_func(**filtered_params)

            else:
                logger.warning(f"âš ï¸ [Act] æœªçŸ¥å·¥å…·: {tool_name}ï¼Œä½¿ç”¨é»˜è®¤æ£€ç´¢")
                query = params.get("query", state.get("query", ""))
                result = await self.search_by_context(query)

            logger.info(f"âœ… [Act] å·¥å…·æ‰§è¡Œå®Œæˆï¼Œè¿”å› {len(result) if isinstance(result, list) else 'dict'} ä¸ªç»“æœ")

            # è®°å½•åŠ¨ä½œ
            state["actions"] = state.get("actions", []) + [{
                "tool": tool_name,
                "params": params
            }]
            state["last_result"] = result

            return state

        except Exception as e:
            logger.error(f"âŒ [Act] å·¥å…·æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)

            # è¿”å›ç©ºç»“æœï¼Œä½†ä¿ç•™åŠ¨ä½œè®°å½•
            state["actions"] = state.get("actions", []) + [{
                "tool": tool_name,
                "params": params,
                "error": str(e)
            }]
            state["last_result"] = []

            return state

    async def observe(self, state: RetrievalState) -> Dict:
        """
        æ­¥éª¤3ï¼šè§‚å¯Ÿç»“æœï¼Œæ›´æ–°æ£€ç´¢å†…å®¹
        """
        logger.info(f"ğŸ‘€ [Observe] è§‚å¯Ÿç»“æœ")

        try:
            last_result = state.get("last_result", [])
            retrieved_content = state.get("retrieved_content", {})
            tool_name = state.get("current_tool", "")

            # å¤„ç†å·¥å…·è¿”å›çš„ç»“æœ
            if isinstance(last_result, list):
                doc_name = state.get('doc_name', 'doc')

                # æ ¹æ®å·¥å…·ç±»å‹åŒºåˆ†å¤„ç†
                if tool_name == "get_document_structure":
                    # æ–‡æ¡£ç»“æ„ä¿¡æ¯ä½œä¸ºç‰¹æ®Šæ¡ç›®ï¼ˆList[str]ï¼‰
                    retrieved_content["_structure"] = "\n".join(last_result)
                    logger.info(f"âœ… [Observe] å·²ä¿å­˜æ–‡æ¡£ç»“æ„ä¿¡æ¯")
                else:
                    # æ£€ç´¢ç»“æœå†…å®¹ï¼Œå¤„ç†æ–°çš„ç»“æ„åŒ–æ ¼å¼ List[Dict] æˆ–æ—§çš„ List[str]
                    for idx, item in enumerate(last_result):
                        if isinstance(item, dict):
                            # æ–°æ ¼å¼ï¼šåŒ…å« contentã€titleã€pages çš„å­—å…¸
                            content = item.get("content", "")
                            title = item.get("title", "æœªçŸ¥ç« èŠ‚")
                            pages = item.get("pages", [])

                            if content and content.strip():
                                # ä½¿ç”¨å·¥å…·åå’Œç´¢å¼•æ„å»ºå”¯ä¸€key
                                key = f"{doc_name}_{tool_name}_{idx}"
                                retrieved_content[key] = {
                                    "content": content,
                                    "title": title,
                                    "pages": pages
                                }
                        elif isinstance(item, str):
                            # å…¼å®¹æ—§æ ¼å¼ï¼šçº¯å­—ç¬¦ä¸²
                            if item and item.strip():
                                key = f"{doc_name}_{tool_name}_{idx}"
                                retrieved_content[key] = {
                                    "content": item,
                                    "title": "æœªçŸ¥ç« èŠ‚",
                                    "pages": []
                                }

                    logger.info(f"âœ… [Observe] æ–°å¢ {len(last_result)} ä¸ªæ£€ç´¢ç»“æœ")

            elif isinstance(last_result, dict):
                # å…¼å®¹Dictæ ¼å¼ï¼ˆæœªæ¥å¯èƒ½çš„æ‰©å±•ï¼‰
                if "results" in last_result:
                    for item in last_result.get("results", []):
                        source = item.get("metadata", {}).get("page", "unknown")
                        content = item.get("content", "")
                        if content:
                            key = f"{state.get('doc_name', 'doc')}_{source}"
                            retrieved_content[key] = content
                elif "chapters" in last_result:
                    chapters_info = last_result.get("chapters", [])
                    retrieved_content["_structure"] = chapters_info

            # è®°å½•è§‚å¯Ÿï¼ˆç®€åŒ–çš„ç»“æœæ‘˜è¦ï¼‰
            result_summary = f"Tool: {tool_name}, Results: {len(last_result) if isinstance(last_result, list) else 'dict'}"
            state["observations"] = state.get("observations", []) + [result_summary]
            state["retrieved_content"] = retrieved_content

            logger.info(f"âœ… [Observe] å·²æ£€ç´¢å†…å®¹æ€»æ•°: {len([k for k in retrieved_content.keys() if not k.startswith('_')])}")

            return state

        except Exception as e:
            logger.error(f"âŒ [Observe] è§‚å¯Ÿå¤±è´¥: {e}", exc_info=True)

            # å¤±è´¥æ—¶ä¿æŒåŸæœ‰çŠ¶æ€
            return state

    async def evaluate(self, state: RetrievalState) -> Dict:
        """
        æ­¥éª¤4ï¼šè¯„ä¼°æ˜¯å¦å·²è·å–è¶³å¤Ÿä¿¡æ¯
        """
        logger.info(f"âš–ï¸ [Evaluate] è¯„ä¼°æ£€ç´¢ç»“æœ")

        try:
            # ä½¿ç”¨Agentçº§åˆ«çš„LLMå®ä¾‹
            llm = self.llm

            # æ•´ç†å·²æ£€ç´¢å†…å®¹
            retrieved_content = state.get("retrieved_content", {})
            content_items = []
            for key, value in retrieved_content.items():
                if key.startswith("_"):
                    continue

                if isinstance(value, dict):
                    # æ–°æ ¼å¼ï¼šåŒ…å« contentã€titleã€pages
                    content = value.get("content", "")
                    title = value.get("title", "æœªçŸ¥ç« èŠ‚")
                    preview = content[:100] + "..." if len(content) > 100 else content
                    content_items.append(f"- {title}: {preview}")
                else:
                    # æ—§æ ¼å¼ï¼šå­—ç¬¦ä¸²
                    preview = value[:100] + "..." if len(value) > 100 else value
                    content_items.append(f"- {key}: {preview}")

            content_summary = "\n".join(content_items)

            prompt = f"""
è¯„ä¼°æ£€ç´¢ç»“æœæ˜¯å¦è¶³ä»¥å›ç­”ç”¨æˆ·æŸ¥è¯¢ã€‚

ç”¨æˆ·æŸ¥è¯¢ï¼š{state['query']}
å·²æ£€ç´¢å†…å®¹æ‘˜è¦ï¼š
{content_summary}

å·²æ£€ç´¢æ¡æ•°ï¼š{len([k for k in retrieved_content.keys() if not k.startswith('_')])}

åˆ¤æ–­æ˜¯å¦å·²è·å–è¶³å¤Ÿä¿¡æ¯æ¥å›ç­”æŸ¥è¯¢ã€‚

è¿”å›JSONæ ¼å¼ï¼š
{{
    "is_complete": true/false,
    "reason": "è¯„ä¼°åŸå› ",
    "confidence": 0.0-1.0
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

            # ä½¿ç”¨ async_call_llm_chain
            session_id = f"retrieval_{state.get('doc_name', 'default')}"
            response = await llm.async_call_llm_chain(
                role=ReaderRole.RETRIEVAL_EVALUATOR,
                input_prompt=prompt,
                session_id=session_id
            )

            # è§£æJSON - æ›´å¥å£®çš„è§£ææ–¹æ³•
            evaluation = None
            try:
                # æ–¹æ³•1: å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                evaluation = json.loads(response.strip())
            except json.JSONDecodeError:
                try:
                    # æ–¹æ³•2: ä½¿ç”¨æ­£åˆ™æå–JSONå¯¹è±¡
                    json_match = re.search(r'\{(?:[^{}]|(?:\{[^{}]*\}))*\}', response, re.DOTALL)
                    if json_match:
                        evaluation = json.loads(json_match.group())
                except (json.JSONDecodeError, AttributeError) as e:
                    logger.warning(f"âš ï¸ [Evaluate] JSONè§£æå¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤è¯„ä¼°")

            # æå–è¯„ä¼°ç»“æœ
            if evaluation and isinstance(evaluation, dict):
                is_complete = evaluation.get("is_complete", False)
                reason = evaluation.get("reason", "")
            else:
                # é»˜è®¤ï¼šå¦‚æœæœ‰å†…å®¹å°±è®¤ä¸ºå®Œæˆ
                is_complete = len(retrieved_content) > 0
                reason = "é»˜è®¤è¯„ä¼°ï¼šJSONè§£æå¤±è´¥"

            logger.info(f"âœ… [Evaluate] è¯„ä¼°ç»“æœ: {'å®Œæˆ' if is_complete else 'ç»§ç»­'} - {reason}")

            state["is_complete"] = is_complete
            return state

        except Exception as e:
            logger.error(f"âŒ [Evaluate] è¯„ä¼°å¤±è´¥: {e}")

            # å¤±è´¥æ—¶æ ¹æ®è¿­ä»£æ¬¡æ•°åˆ¤æ–­
            current_iteration = state.get("current_iteration", 0)
            is_complete = current_iteration >= state["max_iterations"]

            state["is_complete"] = is_complete
            return state

    async def summary(self, state: RetrievalState) -> Dict:
        """
        æ­¥éª¤5ï¼šæ€»ç»“æ£€ç´¢ç»“æœ

        ä½¿ç”¨ LLM å°†æ£€ç´¢åˆ°çš„å†…å®¹æ ¼å¼åŒ–ï¼ŒåŒ…æ‹¬ï¼š
        - å†…å®¹æ¥æºï¼ˆtitleã€pagesï¼‰
        - å†…å®¹æ‘˜è¦
        """
        logger.info(f"ğŸ“ [Summary] å¼€å§‹æ€»ç»“æ£€ç´¢ç»“æœ")

        try:
            retrieved_content = state.get("retrieved_content", {})

            # è¿‡æ»¤å‡ºå®é™…æ£€ç´¢çš„å†…å®¹ï¼ˆæ’é™¤ç‰¹æ®Šæ¡ç›®ï¼‰
            content_items = []
            for key, value in retrieved_content.items():
                if key.startswith("_"):
                    continue  # è·³è¿‡ç‰¹æ®Šæ¡ç›®ï¼ˆå¦‚ _structureï¼‰

                if isinstance(value, dict):
                    # æ–°æ ¼å¼ï¼šåŒ…å« contentã€titleã€pages
                    content_items.append({
                        "content": value.get("content", ""),
                        "title": value.get("title", "æœªçŸ¥ç« èŠ‚"),
                        "pages": value.get("pages", [])
                    })
                elif isinstance(value, str):
                    # æ—§æ ¼å¼å…¼å®¹ï¼šçº¯å­—ç¬¦ä¸²
                    content_items.append({
                        "content": value,
                        "title": "æœªçŸ¥ç« èŠ‚",
                        "pages": []
                    })

            if not content_items:
                logger.warning("âš ï¸ [Summary] æ²¡æœ‰æ£€ç´¢åˆ°ä»»ä½•å†…å®¹")
                state["final_summary"] = "æœªæ£€ç´¢åˆ°ç›¸å…³å†…å®¹ã€‚"
                return state

            # æ„å»º LLM æç¤º
            items_text = ""
            for idx, item in enumerate(content_items, 1):
                pages_str = ", ".join(map(str, item["pages"])) if item["pages"] else "æœªçŸ¥"
                items_text += f"\n\nã€æ¡ç›® {idx}ã€‘\n"
                items_text += f"æ¥æºç« èŠ‚: {item['title']}\n"
                items_text += f"é¡µç : {pages_str}\n"
                items_text += f"å†…å®¹:\n{item['content'][:500]}{'...' if len(item['content']) > 500 else ''}\n"

            prompt = f"""
è¯·å¯¹ä»¥ä¸‹æ£€ç´¢ç»“æœè¿›è¡Œæ ¼å¼åŒ–æ€»ç»“ã€‚

ç”¨æˆ·æŸ¥è¯¢ï¼š{state.get('query', '')}

æ£€ç´¢åˆ° {len(content_items)} æ¡å†…å®¹ï¼š
{items_text}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ€»ç»“ï¼š

## ğŸ“š æ£€ç´¢ç»“æœæ€»ç»“

### ğŸ“‘ æ¥æºä¿¡æ¯
- æ¶‰åŠç« èŠ‚ï¼š[åˆ—å‡ºæ‰€æœ‰ç›¸å…³ç« èŠ‚æ ‡é¢˜]
- æ¶‰åŠé¡µç ï¼š[åˆ—å‡ºæ‰€æœ‰é¡µç èŒƒå›´]

### ğŸ“ å†…å®¹æ‘˜è¦
[å¯¹æ£€ç´¢åˆ°çš„å†…å®¹è¿›è¡Œå½’çº³æ€»ç»“ï¼Œçªå‡ºä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³çš„å…³é”®ä¿¡æ¯]

### ğŸ“„ è¯¦ç»†å†…å®¹
[æŒ‰ç« èŠ‚ç»„ç»‡ï¼Œå±•ç¤ºæ¯ä¸ªç« èŠ‚çš„å…·ä½“å†…å®¹]

è¯·ç”¨æ¸…æ™°ã€ä¸“ä¸šçš„è¯­è¨€è¿›è¡Œæ€»ç»“ã€‚
"""

            # ä½¿ç”¨ async_call_llm_chain
            session_id = f"retrieval_{state.get('doc_name', 'default')}"
            summary_result = await self.llm.async_call_llm_chain(
                role=ReaderRole.CONTEXT_SUMMARIZER,
                input_prompt=prompt,
                session_id=session_id
            )

            logger.info(f"âœ… [Summary] æ€»ç»“å®Œæˆï¼Œé•¿åº¦: {len(summary_result)} å­—ç¬¦")

            state["final_summary"] = summary_result
            return state

        except Exception as e:
            logger.error(f"âŒ [Summary] æ€»ç»“å¤±è´¥: {e}", exc_info=True)

            # å¤±è´¥æ—¶è¿”å›ç®€å•çš„æç¤ºä¿¡æ¯
            retrieved_content = state.get("retrieved_content", {})
            content_count = len([k for k in retrieved_content.keys() if not k.startswith("_")])

            fallback_summary = f"æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼Œä½†å·²æ£€ç´¢åˆ° {content_count} æ¡ç›¸å…³å†…å®¹ã€‚"

            state["final_summary"] = fallback_summary
            return state

    def should_continue(self, state: RetrievalState) -> str:
        """
        åˆ¤æ–­æ˜¯å¦ç»§ç»­æ£€ç´¢

        Returns:
            "continue" æˆ– "finish"
        """
        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if state.get("is_complete", False):
            return "finish"

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°
        current_iteration = state.get("current_iteration", 0)
        max_iterations = state.get("max_iterations", 5)

        if current_iteration >= max_iterations:
            logger.warning(f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
            return "finish"

        return "continue"

