"""
Retrieval Agent - æ™ºèƒ½æ£€ç´¢Agent

ä½¿ç”¨ReActï¼ˆReasoning + Actingï¼‰æ¨¡å¼è¿›è¡Œæ™ºèƒ½æ£€ç´¢
"""

from langgraph.graph import StateGraph, END
from langgraph.types import Command
from typing import Dict, List, Any
import logging
import json
import re

from ..base import AgentBase
from .state import RetrievalState
from src.config.prompts.retrieval_prompts import RetrievalRole
from src.config.prompts.common_prompts import CommonRole
from src.utils.helpers import extract_data_from_LLM_res

logger = logging.getLogger(__name__)


class RetrievalAgent(AgentBase):
    """
    æ£€ç´¢Agentï¼ˆReActæ¨¡å¼ï¼‰

    å·¥ä½œæµç¨‹ï¼ˆå¾ªç¯ï¼‰ï¼š
    1. think - æ€è€ƒä¸‹ä¸€æ­¥ä½¿ç”¨å“ªä¸ªå·¥å…·
    2. act - æ‰§è¡Œå·¥å…·è°ƒç”¨
    3. observe - è§‚å¯Ÿç»“æœ
    4. evaluate - è¯„ä¼°æ˜¯å¦å®Œæˆ

    å·¥å…·æ–¹æ³•ï¼ˆç›´æ¥åœ¨ç±»ä¸­å®ç°ï¼‰ï¼š
    - search_by_context - è¯­ä¹‰ç›¸ä¼¼æ£€ç´¢
    - search_by_title - æŒ‰æ ‡é¢˜æ£€ç´¢
    - get_document_structure - è·å–æ–‡æ¡£ç»“æ„

    æ”¯æŒï¼š
    - å•æ–‡æ¡£æ£€ç´¢ï¼šæŒ‡å®šdoc_name
    - å¤šæ–‡æ¡£æ£€ç´¢ï¼šdoc_name=None
    """

    def __init__(self, doc_name: str = None):
        super().__init__(name="RetrievalAgent")

        # å½“å‰æ–‡æ¡£ä¸Šä¸‹æ–‡
        self.current_doc = doc_name

        # åˆå§‹åŒ– VectorDBClientï¼ˆå¤ç”¨å®ä¾‹ï¼Œé¿å…é‡å¤åŠ è½½ï¼‰
        self.vector_db_client = None
        if doc_name:
            self.vector_db_client = self._create_vector_db_client(doc_name)

        # æ£€ç´¢ç¼“å­˜å­—å…¸ï¼ˆæå‡æ€§èƒ½ï¼Œé¿å…é‡å¤æ£€ç´¢ï¼‰
        self.retrieval_data_dict: Dict[str, Any] = {}

        self.graph = self.build_graph()

    def _get_db_path_from_doc_name(self, doc_name: str) -> str:
        """
        å°†æ–‡æ¡£åç§°è½¬æ¢ä¸ºå‘é‡æ•°æ®åº“è·¯å¾„

        Args:
            doc_name: æ–‡æ¡£åç§°

        Returns:
            str: å‘é‡æ•°æ®åº“çš„å®Œæ•´è·¯å¾„
        """
        from pathlib import Path
        from src.config.settings import DATA_ROOT

        # æ³¨æ„ï¼šå¿…é¡»ä¸ IndexingAgent çš„è·¯å¾„æ ¼å¼ä¿æŒä¸€è‡´
        db_path = Path(DATA_ROOT) / "vector_db" / f"{doc_name}_data_index"
        return str(db_path)

    def _create_vector_db_client(self, doc_name: str):
        """
        åˆ›å»º VectorDBClient å®ä¾‹

        Args:
            doc_name: æ–‡æ¡£åç§°

        Returns:
            VectorDBClient: å‘é‡æ•°æ®åº“å®¢æˆ·ç«¯å®ä¾‹
        """
        from src.core.vector_db.vector_db_client import VectorDBClient

        db_path = self._get_db_path_from_doc_name(doc_name)

        # ä½¿ç”¨ä¾èµ–æ³¨å…¥ï¼Œä¼ å…¥ embedding_model
        client = VectorDBClient(
            db_path=db_path,
            embedding_model=self.embedding_model
        )

        logger.info(f"âœ… [VectorDB] å·²åˆ›å»ºå‘é‡æ•°æ®åº“å®¢æˆ·ç«¯: {doc_name}")
        return client

    def _build_retrieval_tools(self) -> Dict[str, Dict]:
        """
        ä»é…ç½®æ–‡ä»¶æ„å»ºæ£€ç´¢å·¥å…·å­—å…¸

        å·¥å…·é…ç½®æ¥æºï¼šsrc/config/tools/retrieval_tools.py

        Returns:
            å·¥å…·å­—å…¸ï¼Œkeyä¸ºå·¥å…·åç§°ï¼ŒvalueåŒ…å«å·¥å…·è¯¦ç»†ä¿¡æ¯
        """
        from src.config.tools.retrieval_tools import get_enabled_tools

        tools = {}
        enabled_tools = get_enabled_tools()

        for tool_config in enabled_tools:
            tool_name = tool_config["name"]
            method_name = tool_config["method_name"]

            # è·å–å¯¹åº”çš„æ–¹æ³•
            if hasattr(self, method_name):
                tool_method = getattr(self, method_name)

                tools[tool_name] = {
                    "name": tool_name,
                    "description": tool_config["description"],
                    "parameters": tool_config["parameters"],
                    "function": tool_method,
                    "priority": tool_config.get("priority", 999),
                }

                logger.debug(f"å·²åŠ è½½å·¥å…·: {tool_name} (æ–¹æ³•: {method_name})")
            else:
                logger.warning(f"å·¥å…· '{tool_name}' é…ç½®çš„æ–¹æ³• '{method_name}' æœªæ‰¾åˆ°")

        logger.info(f"æˆåŠŸåŠ è½½ {len(tools)} ä¸ªæ£€ç´¢å·¥å…·")
        return tools

    def _get_agenda_dict_from_vector_db(self) -> Dict[str, Any]:
        """
        ä»å‘é‡æ•°æ®åº“è·å– agenda_dictï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        ä» type="structure" æ–‡æ¡£ä¸­æå– agenda_dict å…ƒæ•°æ®ã€‚

        Returns:
            agenda_dict å­—å…¸ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›ç©ºå­—å…¸
        """
        if not self.vector_db_client:
            logger.warning("âš ï¸ [_get_agenda_dict_from_vector_db] VectorDBClient æœªåˆå§‹åŒ–")
            return {}

        try:
            doc_res = self.vector_db_client.search_with_metadata_filter(
                query="",
                k=1,
                field_name="type",
                field_value="structure",
                enable_dedup=False
            )

            if doc_res and len(doc_res) > 0:
                document = doc_res[0][0] if isinstance(doc_res[0], tuple) else doc_res[0]
                agenda_dict = document.metadata.get("agenda_dict", {})
                logger.debug(f"âœ… [_get_agenda_dict_from_vector_db] è·å–åˆ° agenda_dictï¼Œå…± {len(agenda_dict)} ä¸ªç« èŠ‚")
                return agenda_dict
            else:
                logger.warning("âš ï¸ [_get_agenda_dict_from_vector_db] æœªæ‰¾åˆ°æ–‡æ¡£ç»“æ„ä¿¡æ¯")
                return {}

        except Exception as e:
            logger.error(f"âŒ [_get_agenda_dict_from_vector_db] è·å– agenda_dict å¤±è´¥: {e}")
            return {}

    # ==================== å·¥å…·æ–¹æ³•å®ç° ====================

    async def search_by_context(self, query: str) -> List[str]:
        """
        åŸºäºä¸Šä¸‹æ–‡çš„è¯­ä¹‰æ£€ç´¢æ–¹æ³•

        é€šè¿‡å‘é‡ç›¸ä¼¼åº¦æœç´¢åœ¨æ–‡æ¡£ä¸­æŸ¥æ‰¾ä¸æŸ¥è¯¢è¯­ä¹‰ç›¸å…³çš„å†…å®¹æ®µè½ã€‚
        è¿™ä¸ªæ–¹æ³•ä½¿ç”¨å‘é‡æ•°æ®åº“çš„è¯­ä¹‰æœç´¢åŠŸèƒ½ï¼Œèƒ½å¤Ÿç†è§£æŸ¥è¯¢çš„è¯­ä¹‰å«ä¹‰ï¼Œ
        å¹¶æ‰¾åˆ°åœ¨è¯­ä¹‰ä¸Šç›¸å…³çš„æ–‡æ¡£å†…å®¹ï¼Œå³ä½¿å…³é”®è¯ä¸å®Œå…¨åŒ¹é…ã€‚

        Args:
            query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œåº”æè¿°è¦æŸ¥æ‰¾çš„å†…å®¹è¯­ä¹‰

        Returns:
            æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£å†…å®¹åˆ—è¡¨
        """
        logger.info(f"ğŸ” [Tool:search_by_context] ---------- è¯­ä¹‰æ£€ç´¢ ----------")
        logger.info(f"ğŸ” [Tool:search_by_context] æŸ¥è¯¢å†…å®¹: {query}")

        if not query or not query.strip():
            logger.warning("ğŸ” [Tool:search_by_context] âŒ æŸ¥è¯¢å­—ç¬¦ä¸²ä¸ºç©º")
            return []

        if not self.vector_db_client:
            logger.error("ğŸ” [Tool:search_by_context] âŒ å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
            return []

        try:
            logger.info(f"ğŸ” [Tool:search_by_context] æ‰§è¡Œå‘é‡æ£€ç´¢ (k=3, type=context)")
            # ä½¿ç”¨ type='context' è¿‡æ»¤å™¨è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œå¯ç”¨å»é‡
            doc_res = self.vector_db_client.search_with_metadata_filter(
                query=query,
                k=3,  # ä¸æ—§å®ç°ä¿æŒä¸€è‡´
                field_name="type",
                field_value="context",
                enable_dedup=True
            )
            logger.info(f"ğŸ” [Tool:search_by_context] å‘é‡æ£€ç´¢è¿”å›: {len(doc_res) if doc_res else 0} ä¸ªç»“æœ")

            context_data = []
            chapter_info_list = []  # å­˜å‚¨ç« èŠ‚ä¿¡æ¯ç”¨äºæ±‡æ€»

            if doc_res and len(doc_res) > 0:
                for idx, doc_item in enumerate(doc_res):
                    try:
                        # è§£ææ–‡æ¡£ç»“æ„
                        document = doc_item[0] if isinstance(doc_item, tuple) else doc_item
                        metadata = document.metadata

                        refactor_data = metadata.get("refactor", "")
                        raw_data = metadata.get("raw_data", {})
                        page_number = list(raw_data.keys()) if isinstance(raw_data, dict) else []

                        # æå–ç« èŠ‚æ ‡é¢˜ä¿¡æ¯
                        chapter_title = metadata.get("title", "æœªçŸ¥ç« èŠ‚")

                        # æ•´ç†å¹¶è¿”å›æ£€ç´¢åˆ°çš„æ•°æ®ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
                        if refactor_data and refactor_data.strip():
                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå†…å®¹ï¼ˆå»é‡ï¼‰
                            existing_contents = [item["content"] for item in context_data]
                            if refactor_data not in existing_contents:
                                # è¿”å›ç»“æ„åŒ–æ•°æ®ï¼šåŒ…å«å†…å®¹å’Œå…ƒæ•°æ®
                                context_data.append({
                                    "content": refactor_data,
                                    "title": chapter_title,
                                    "pages": sorted(page_number, key=lambda x: int(x) if str(x).isdigit() else 0) if page_number else []
                                })

                                # è®°å½•ç« èŠ‚ä¿¡æ¯ç”¨äºæ—¥å¿—æ±‡æ€»
                                chapter_info_list.append({
                                    "title": chapter_title,
                                    "pages": sorted(page_number, key=lambda x: int(x) if str(x).isdigit() else 0) if page_number else []
                                })

                    except Exception as e:
                        logger.error(f"âŒ [Tool:search_by_context] å¤„ç†ç¬¬ {idx+1} ä¸ªæ–‡æ¡£æ—¶å‡ºé”™: {e}")
                        continue

                # ========== æ±‡æ€»æ—¥å¿— ==========
                logger.info("")
                logger.info("=" * 60)
                logger.info("âœ… [CONTEXT RETRIEVAL] ä¸Šä¸‹æ–‡æ£€ç´¢ç»“æœ")
                logger.info("=" * 60)
                logger.info(f"ğŸ“Š è¿”å› {len(context_data)} æ¡å†…å®¹ç‰‡æ®µ")

                # æ˜¾ç¤ºæœ¬æ¬¡è¿”å›å†…å®¹å¯¹åº”çš„ç« èŠ‚å’Œé¡µç 
                if chapter_info_list:
                    logger.info("ğŸ“š æ£€ç´¢åˆ°çš„ç« èŠ‚:")
                    for idx, chapter in enumerate(chapter_info_list, 1):
                        pages_str = f"é¡µç : {', '.join(map(str, chapter['pages']))}" if chapter['pages'] else "æ— é¡µç "
                        logger.info(f"   {idx}. {chapter['title']} ({pages_str})")
                else:
                    logger.info("ğŸ“š æœªæ£€ç´¢åˆ°ä»»ä½•ç« èŠ‚")

                logger.info("=" * 60)
                logger.info("")
            else:
                logger.warning("âš ï¸ [Tool:search_by_context] åœ¨å‘é‡æ•°æ®åº“ä¸­æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ç›¸å…³çš„å†…å®¹")

            return context_data

        except Exception as e:
            logger.error(f"âŒ [Tool:search_by_context] é€šè¿‡ä¸Šä¸‹æ–‡æ£€ç´¢æ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)
            return []

    async def extract_titles_from_structure(self, query: str) -> List[str]:
        """
        ä»æ–‡æ¡£ç»“æ„ä¸­æå–ç›¸å…³æ ‡é¢˜åˆ—è¡¨

        æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ï¼Œä» type="structure" æ–‡æ¡£ä¸­è·å– agenda_dictï¼Œ
        ç„¶åä½¿ç”¨ LLM æ™ºèƒ½æå–ä¸æŸ¥è¯¢ç›¸å…³çš„ç« èŠ‚æ ‡é¢˜ã€‚

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢å­—ç¬¦ä¸²

        Returns:
            æå–åˆ°çš„æ ‡é¢˜åˆ—è¡¨
        """
        logger.info(f"ğŸ“‹ [Tool:extract_titles_from_structure] ä»ç»“æ„ä¸­æå–æ ‡é¢˜: {query[:50]}...")

        if not query or not query.strip():
            logger.warning("âŒ [Tool:extract_titles_from_structure] æŸ¥è¯¢å­—ç¬¦ä¸²ä¸ºç©º")
            return []

        if not self.vector_db_client:
            logger.error("âŒ [Tool:extract_titles_from_structure] VectorDBClient æœªåˆå§‹åŒ–")
            return []

        try:
            # æ­¥éª¤1: ä»å‘é‡æ•°æ®åº“è·å– agenda_dict
            agenda_dict = self._get_agenda_dict_from_vector_db()

            if not agenda_dict:
                logger.warning("âš ï¸ [Tool:extract_titles_from_structure] æœªæ‰¾åˆ°æ–‡æ¡£ç»“æ„ä¿¡æ¯")
                return []

            # æ­¥éª¤2: ä½¿ç”¨ LLM æå–æ ‡é¢˜åˆ—è¡¨
            response = self.llm.call_llm_chain(
                CommonRole.CHAPTER_MATCHER,
                query,
                "chapter_matcher",
                system_format_dict={
                    "agenda_dict": agenda_dict
                }
            )

            response_data = extract_data_from_LLM_res(response)
            title_list = response_data.get("title", [])

            # éªŒè¯ç»“æœ
            if not isinstance(title_list, list):
                logger.warning("âš ï¸ [Tool:extract_titles_from_structure] æ ‡é¢˜åˆ—è¡¨æ ¼å¼æ— æ•ˆ")
                return []

            logger.info(f"âœ… [Tool:extract_titles_from_structure] æå–åˆ° {len(title_list)} ä¸ªæ ‡é¢˜: {title_list}")
            return title_list

        except Exception as e:
            logger.error(f"âŒ [Tool:extract_titles_from_structure] æå–æ ‡é¢˜å¤±è´¥: {e}", exc_info=True)
            return []

    async def search_by_title(self, title_list: str) -> List[str]:
        """
        åŸºäºæ ‡é¢˜åˆ—è¡¨çš„ç²¾ç¡®æ£€ç´¢å·¥å…·

        æ ¹æ®ç»™å®šçš„æ ‡é¢˜åˆ—è¡¨ï¼Œåœ¨å‘é‡æ•°æ®åº“ä¸­ç²¾ç¡®åŒ¹é…è¿™äº›æ ‡é¢˜æ¥æ£€ç´¢å¯¹åº”çš„æ–‡æ¡£å†…å®¹ã€‚

        Args:
            title_list: æ ‡é¢˜åˆ—è¡¨ï¼ˆJSONæ ¼å¼å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰

        Returns:
            æ£€ç´¢åˆ°çš„åŒ¹é…æ ‡é¢˜çš„æ–‡æ¡£å†…å®¹åˆ—è¡¨
        """
        logger.info(f"ğŸ“‘ [Tool:search_by_title] ---------- æ ‡é¢˜æ£€ç´¢ ----------")
        logger.info(f"ğŸ“‘ [Tool:search_by_title] è¾“å…¥æ ‡é¢˜: {title_list}")

        if not self.vector_db_client:
            logger.error("ğŸ“‘ [Tool:search_by_title] âŒ VectorDBClient æœªåˆå§‹åŒ–")
            return []

        try:
            # è§£æ title_listï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            if isinstance(title_list, str):
                # å°è¯•è§£æä¸ºJSON
                try:
                    parsed_list = json.loads(title_list)
                    if isinstance(parsed_list, list):
                        title_list = parsed_list
                    else:
                        logger.warning("âš ï¸ [Tool:search_by_title] è§£æåçš„æ•°æ®ä¸æ˜¯åˆ—è¡¨")
                        return []
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯JSONï¼ŒæŒ‰é€—å·åˆ†å‰²
                    title_list = [t.strip() for t in title_list.split(',') if t.strip()]

            # è¾“å…¥éªŒè¯
            if not isinstance(title_list, list):
                logger.warning("âš ï¸ [Tool:search_by_title] æ ‡é¢˜åˆ—è¡¨æ ¼å¼æ— æ•ˆï¼ŒæœŸæœ›listç±»å‹")
                return []

            if len(title_list) == 0:
                logger.info("â„¹ï¸ [Tool:search_by_title] æ ‡é¢˜åˆ—è¡¨ä¸ºç©ºï¼Œè¿”å›ç©ºç»“æœ")
                return []

            logger.info(f"ğŸ“ [Tool:search_by_title] å¤„ç† {len(title_list)} ä¸ªæ ‡é¢˜: {title_list}")

        except Exception as e:
            logger.error(f"âŒ [Tool:search_by_title] è§£ææ ‡é¢˜åˆ—è¡¨å¤±è´¥: {e}")
            return []

        # éå†æ ‡é¢˜åˆ—è¡¨ï¼Œæ£€ç´¢å¯¹åº”å†…å®¹
        context_data = []
        successful_retrievals = 0
        cache_hits = 0
        returned_titles = []  # è¿½è¸ªå®é™…è¿”å›çš„æ ‡é¢˜

        for title in title_list:
            if not title or not isinstance(title, str):
                continue

            title = title.strip()
            if not title:
                continue

            try:
                refactor_data = ""
                page_number = []
                is_from_cache = False

                # æ£€æŸ¥ç¼“å­˜
                if title in self.retrieval_data_dict:
                    cached_data = self.retrieval_data_dict[title]
                    refactor_data = cached_data.get("data", "")
                    page_number = cached_data.get("page", [])
                    cache_hits += 1
                    is_from_cache = True
                else:
                    # ä»å‘é‡æ•°æ®åº“æ£€ç´¢ï¼ˆä»…æ£€ç´¢ type='title' çš„æ–‡æ¡£ï¼‰
                    try:
                        doc_res = self.vector_db_client.search_by_title(
                            title,
                            doc_type="title",
                            enable_dedup=True
                        )

                        if doc_res and len(doc_res) > 0:
                            # å¤„ç†è¿”å›çš„åˆ—è¡¨ä¸­çš„æ¯ä¸ªæ–‡æ¡£
                            all_refactor_data = []
                            all_page_numbers = []

                            for doc_item in doc_res:
                                document = doc_item[0] if isinstance(doc_item, tuple) else doc_item
                                metadata = document.metadata

                                item_refactor_data = metadata.get("refactor", "")
                                item_raw_data = metadata.get("raw_data", {})
                                item_page_numbers = list(item_raw_data.keys()) if isinstance(item_raw_data, dict) else []

                                if item_refactor_data and item_refactor_data.strip():
                                    all_refactor_data.append(item_refactor_data)

                                if item_page_numbers:
                                    all_page_numbers.extend(item_page_numbers)

                            # åˆå¹¶æ‰€æœ‰æ£€ç´¢åˆ°çš„æ•°æ®
                            refactor_data = "\n\n".join(all_refactor_data) if all_refactor_data else ""
                            page_number = list(set(all_page_numbers))  # å»é‡é¡µé¢ç¼–å·

                            # ç¼“å­˜æ£€ç´¢ç»“æœ
                            self.retrieval_data_dict[title] = {
                                "data": refactor_data,
                                "page": page_number
                            }

                            successful_retrievals += 1
                        else:
                            logger.warning(f"âš ï¸ [Tool:search_by_title] ç« èŠ‚ '{title}' åœ¨å‘é‡æ•°æ®åº“ä¸­æœªæ‰¾åˆ°")

                    except Exception as e:
                        logger.error(f"âŒ [Tool:search_by_title] æ£€ç´¢ç« èŠ‚ '{title}' æ—¶å‡ºé”™: {e}")
                        continue

                # æ·»åŠ åˆ°ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆå»é‡ï¼‰ï¼ŒåŒ…å«å…ƒæ•°æ®
                if refactor_data and refactor_data.strip():
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå†…å®¹
                    existing_contents = [item["content"] if isinstance(item, dict) else item for item in context_data]
                    if refactor_data not in existing_contents:
                        # è¿”å›ç»“æ„åŒ–æ•°æ®ï¼šåŒ…å«å†…å®¹å’Œå…ƒæ•°æ®
                        context_data.append({
                            "content": refactor_data,
                            "title": title,
                            "pages": sorted(page_number, key=lambda x: int(x) if str(x).isdigit() else 0) if page_number else []
                        })
                        # è®°å½•ç”¨äºæ—¥å¿—æ±‡æ€»
                        returned_titles.append({
                            "title": title,
                            "pages": page_number,
                            "from_cache": is_from_cache
                        })

            except Exception as e:
                logger.error(f"âŒ [Tool:search_by_title] å¤„ç†ç« èŠ‚ '{title}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue

        # ========== æ±‡æ€»æ—¥å¿— ==========
        logger.info("")
        logger.info("=" * 60)
        logger.info("âœ… [TITLE RETRIEVAL] æ ‡é¢˜æ£€ç´¢ç»“æœ")
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š è¿”å› {len(context_data)} æ¡å†…å®¹ç‰‡æ®µ (æ–°æ£€ç´¢: {successful_retrievals}, ç¼“å­˜: {cache_hits})")

        # æ˜¾ç¤ºæœ¬æ¬¡å®é™…è¿”å›çš„ç« èŠ‚å’Œé¡µç 
        if returned_titles:
            logger.info("ğŸ“š æœ¬æ¬¡è¿”å›çš„ç« èŠ‚:")
            for item in returned_titles:
                title = item["title"]
                pages = item["pages"]
                from_cache = item.get("from_cache", False)

                cache_tag = " [ç¼“å­˜]" if from_cache else " [æ–°æ£€ç´¢]"

                if pages:
                    sorted_pages = sorted(pages, key=lambda x: int(x) if str(x).isdigit() else 0)
                    pages_str = f"é¡µç : {', '.join(map(str, sorted_pages))}"
                else:
                    pages_str = "æ— é¡µç "
                logger.info(f"   âœ“ {title} ({pages_str}){cache_tag}")
        else:
            logger.info("ğŸ“š æœªæ£€ç´¢åˆ°ä»»ä½•å†…å®¹")

        logger.info("=" * 60)
        logger.info("")

        return context_data

    async def get_document_structure(self, query: str = "") -> List[str]:
        """
        è·å–æ–‡æ¡£çš„ç›®å½•ç»“æ„å·¥å…·

        ä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢ type="structure" çš„ç‰¹æ®Šæ–‡æ¡£ï¼Œè·å–æ–‡æ¡£ç»“æ„ä¿¡æ¯ã€‚

        Args:
            query: æŸ¥è¯¢å‚æ•°ï¼ˆæ­¤å·¥å…·ä¸éœ€è¦å…·ä½“æŸ¥è¯¢å†…å®¹ï¼Œä¿ç•™ç”¨äºæ¥å£å…¼å®¹ï¼‰

        Returns:
            æ–‡æ¡£ç›®å½•ç»“æ„åˆ—è¡¨
        """
        _ = query  # å‚æ•°ä¿ç•™ç”¨äºæ¥å£å…¼å®¹ï¼Œå®é™…ä¸ä½¿ç”¨
        logger.info(f"ğŸ“š [Tool:get_document_structure] ---------- è·å–æ–‡æ¡£ç»“æ„ ----------")

        if not self.vector_db_client:
            logger.error("ğŸ“š [Tool:get_document_structure] âŒ VectorDBClient æœªåˆå§‹åŒ–")
            return ["æ–‡æ¡£ç»“æ„ä¿¡æ¯ä¸å¯ç”¨ï¼ˆå‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–ï¼‰"]

        try:
            # è·å– agenda_dict
            agenda_dict = self._get_agenda_dict_from_vector_db()

            if not agenda_dict:
                logger.warning("âš ï¸ [Tool:get_document_structure] æ–‡æ¡£ç»“æ„ä¿¡æ¯ä¸ºç©º")
                return ["æ–‡æ¡£ç›®å½•ä¿¡æ¯ä¸å¯ç”¨"]

            # æ ¼å¼åŒ–ç›®å½•ç»“æ„
            structure_list = []
            structure_list.append("=" * 60)
            structure_list.append("ğŸ“‘ æ–‡æ¡£ç›®å½•ç»“æ„")
            structure_list.append("=" * 60)

            for title, page_info in agenda_dict.items():
                if isinstance(page_info, list):
                    if len(page_info) == 0:
                        page_str = "é¡µç æœªçŸ¥"
                    elif len(page_info) == 1:
                        page_str = f"é¡µç : {page_info[0]}"
                    else:
                        sorted_pages = sorted(page_info, key=lambda x: int(x) if str(x).isdigit() else 0)
                        page_str = f"é¡µç : {sorted_pages[0]}-{sorted_pages[-1]}"
                else:
                    page_str = f"é¡µç : {page_info}"

                structure_list.append(f"{title} ({page_str})")

            structure_list.append("=" * 60)

            logger.info(f"âœ… [Tool:get_document_structure] è·å–åˆ° {len(agenda_dict)} ä¸ªç« èŠ‚")
            return structure_list

        except Exception as e:
            logger.error(f"âŒ [Tool:get_document_structure] è·å–å¤±è´¥: {e}", exc_info=True)
            return ["æ–‡æ¡£ç»“æ„ä¿¡æ¯ä¸å¯ç”¨"]

    # ==================== WorkflowèŠ‚ç‚¹æ–¹æ³• ====================

    def build_graph(self) -> StateGraph:
        """æ„å»ºReAct workflow"""
        workflow = StateGraph(RetrievalState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("initialize", self.initialize)
        workflow.add_node("rewrite", self.rewrite)
        workflow.add_node("think", self.think)
        workflow.add_node("act", self.act)
        workflow.add_node("summary", self.summary)
        workflow.add_node("evaluate", self.evaluate)
        workflow.add_node("format", self.format)

        # æ·»åŠ è¾¹
        workflow.add_edge("initialize", "rewrite")  # å…ˆ rewrite
        workflow.add_edge("rewrite", "think")       # å† think
        workflow.add_edge("think", "act")

        # æ¡ä»¶è¾¹ï¼šæ ¹æ®å·¥å…·é…ç½®å†³å®šæ˜¯å¦éœ€è¦ summary
        workflow.add_conditional_edges(
            "act",
            self.should_summarize,
            {
                "summary": "summary",    # éœ€è¦æ€»ç»“
                "evaluate": "evaluate"   # è·³è¿‡æ€»ç»“ï¼Œç›´æ¥è¯„ä¼°
            }
        )

        workflow.add_edge("summary", "evaluate")

        # æ¡ä»¶è¾¹ï¼šæ ¹æ®è¯„ä¼°ç»“æœå†³å®šç»§ç»­æˆ–ç»“æŸ
        workflow.add_conditional_edges(
            "evaluate",
            self.should_continue,
            {
                "continue": "rewrite",  # ç»§ç»­å¾ªç¯ï¼ˆå›åˆ° rewriteï¼‰
                "finish": "format"      # åˆ° format èŠ‚ç‚¹è¿›è¡Œç²¾å‡†æ€»ç»“
            }
        )

        # format èŠ‚ç‚¹å®Œæˆååˆ° END
        workflow.add_edge("format", END)

        # è®¾ç½®å…¥å£
        workflow.set_entry_point("initialize")

        return workflow.compile()

    def _validate_state(self, state: RetrievalState) -> None:
        """
        éªŒè¯stateçš„å®Œæ•´æ€§

        Args:
            state: RetrievalStateå¯¹è±¡

        Raises:
            ValueError: ç¼ºå°‘å¿…éœ€å­—æ®µæ—¶æŠ›å‡ºå¼‚å¸¸
        """
        required_fields = ['query', 'max_iterations']

        for field in required_fields:
            if field not in state:
                raise ValueError(f"âŒ [Validate] Stateç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")

        # éªŒè¯å­—æ®µç±»å‹å’Œå€¼
        if not isinstance(state.get('query', ''), str) or not state.get('query', '').strip():
            raise ValueError("âŒ [Validate] queryå­—æ®µå¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")

        max_iterations = state.get('max_iterations', 0)
        if not isinstance(max_iterations, int) or max_iterations <= 0:
            raise ValueError("âŒ [Validate] max_iterationså¿…é¡»æ˜¯æ­£æ•´æ•°")

        logger.debug(f"âœ… [Validate] StateéªŒè¯é€šè¿‡")

    async def initialize(self, state: RetrievalState) -> Dict:
        """
        åˆå§‹åŒ–èŠ‚ç‚¹ï¼šè®¾ç½®Agentçš„ä¸Šä¸‹æ–‡ç¯å¢ƒ

        åœ¨workflowå¼€å§‹æ—¶æ‰§è¡Œä¸€æ¬¡ï¼ŒåŒ…æ‹¬ï¼š
        1. éªŒè¯stateå®Œæ•´æ€§
        2. è®¾ç½®æ–‡æ¡£ä¸Šä¸‹æ–‡
        3. åˆ›å»ºæˆ–æ›´æ–° VectorDBClient
        4. åˆå§‹åŒ–å¿…è¦çš„stateå­—æ®µ
        """
        logger.info(f"ğŸ”§ [Initialize] ========== RetrievalAgent åˆå§‹åŒ– ==========")

        try:
            # éªŒè¯state
            self._validate_state(state)

            # ä»stateä¸­è¯»å–å¹¶è®¾ç½®æ–‡æ¡£ä¸Šä¸‹æ–‡
            doc_name_from_state = state.get('doc_name')
            self.current_doc = doc_name_from_state or self.current_doc

            logger.info(f"ğŸ”§ [Initialize] é…ç½®ä¿¡æ¯:")
            logger.info(f"ğŸ”§ [Initialize]   - æ–‡æ¡£åç§°: {self.current_doc or 'å¤šæ–‡æ¡£æ¨¡å¼'}")
            logger.info(f"ğŸ”§ [Initialize]   - æŸ¥è¯¢å†…å®¹: {state['query']}")
            logger.info(f"ğŸ”§ [Initialize]   - æœ€å¤§è¿­ä»£: {state['max_iterations']}")
            logger.info(f"ğŸ”§ [Initialize]   - å½“å‰è¿­ä»£: {state.get('current_iteration', 0)}")

            # åˆ›å»ºæˆ–æ›´æ–° VectorDBClientï¼ˆå¦‚æœæ–‡æ¡£åç§°å˜åŒ–ï¼‰
            if self.current_doc:
                if self.vector_db_client is None:
                    # é¦–æ¬¡åˆ›å»º
                    self.vector_db_client = self._create_vector_db_client(self.current_doc)
                    logger.info(f"âœ… [Initialize] VectorDBClient å·²åˆ›å»ºå¹¶åŠ è½½")

                elif doc_name_from_state and doc_name_from_state != self.current_doc:
                    # æ–‡æ¡£åç§°å˜åŒ–ï¼Œé‡æ–°åˆ›å»º
                    logger.info(f"ğŸ”„ [Initialize] æ–‡æ¡£åç§°å˜åŒ–ï¼Œé‡æ–°åˆ›å»ºVectorDBClient")
                    self.vector_db_client = self._create_vector_db_client(doc_name_from_state)
                    self.current_doc = doc_name_from_state
            else:
                logger.warning(f"âš ï¸ [Initialize] æœªæŒ‡å®šæ–‡æ¡£åç§°ï¼ŒæŸäº›æ£€ç´¢åŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨")

            # åˆå§‹åŒ–å¿…è¦çš„stateå­—æ®µ
            if 'retrieved_content' not in state:
                state['retrieved_content'] = []  # æ”¹ä¸º list

            if 'formatted_data' not in state:
                state['formatted_data'] = []

            if 'thoughts' not in state:
                state['thoughts'] = []

            if 'actions' not in state:
                state['actions'] = []

            if 'observations' not in state:
                state['observations'] = []

            if 'current_iteration' not in state:
                state['current_iteration'] = 0

            logger.info(f"âœ… [Initialize] åˆå§‹åŒ–å®Œæˆ")
            return state

        except ValueError as e:
            logger.error(f"âŒ [Initialize] çŠ¶æ€éªŒè¯å¤±è´¥: {e}")
            raise
        except Exception as e:
            logger.error(f"âŒ [Initialize] åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            raise

    async def rewrite(self, state: RetrievalState) -> Dict:
        """
        æŸ¥è¯¢é‡å†™èŠ‚ç‚¹ï¼šåŸºäºå†å²æ£€ç´¢å†…å®¹ä¼˜åŒ–æŸ¥è¯¢

        ç­–ç•¥ï¼š
        - ç¬¬ä¸€è½®æˆ–æ— å†å²å†…å®¹ â†’ è·³è¿‡é‡å†™ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢
        - æœ‰å†å²å†…å®¹ â†’ åŸºäº intermediate_summary ä¼˜åŒ–æŸ¥è¯¢

        è¿”å›ï¼š
        - rewritten_query: ä¼˜åŒ–åçš„æŸ¥è¯¢ï¼ˆä¿å­˜åˆ° stateï¼‰
        """
        current_iteration = state.get("current_iteration", 0)
        intermediate_summary = state.get("intermediate_summary", "")
        original_query = state["query"]

        logger.info(f"ğŸ”„ [Rewrite] æŸ¥è¯¢é‡å†™ - è¿­ä»£ {current_iteration + 1}")

        try:
            # ç¬¬ä¸€è½®æˆ–æ— å†å²å†…å®¹ â†’ è·³è¿‡é‡å†™
            if current_iteration == 0 or not intermediate_summary:
                logger.info(f"â­ï¸ [Rewrite] é¦–è½®æˆ–æ— å†å²å†…å®¹ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢")
                state["rewritten_query"] = original_query
                return state

            # æœ‰å†å²å†…å®¹ â†’ æ‰§è¡Œé‡å†™
            logger.info(f"ğŸ“ [Rewrite] åŸºäºå†å²å†…å®¹ä¼˜åŒ–æŸ¥è¯¢")

            # è·å–ä¸Šä¸€è½® evaluate çš„è¯„ä¼°ç»“æœ
            last_reason = state.get("reason", "")

            # è·å–å·²æ£€ç´¢çš„ç« èŠ‚é¡µç ä¿¡æ¯
            formatted_data = state.get("formatted_data", [])
            retrieved_info = ""
            if formatted_data:
                chapters = []
                for item in formatted_data:
                    title = item.get("title", "")
                    pages = item.get("pages", [])
                    if pages:
                        pages_str = ", ".join(map(str, pages))
                        chapters.append(f"- {title} (é¡µç : {pages_str})")
                if chapters:
                    retrieved_info = "\n".join(chapters)

            # æ„å»º rewrite promptï¼ˆç®€æ´ç‰ˆï¼Œè¯¦ç»†ç­–ç•¥åœ¨ system promptï¼‰
            prompt = f"""
åŸå§‹æŸ¥è¯¢: {original_query}

ä¸Šä¸€è½®è¯„ä¼°åé¦ˆ:
{last_reason if last_reason else "æš‚æ— è¯„ä¼°"}

å·²æ£€ç´¢ç« èŠ‚:
{retrieved_info if retrieved_info else "æš‚æ— "}

æ£€ç´¢å†…å®¹æ€»ç»“:
{intermediate_summary[:800]}...

è¯·ä¼˜åŒ–æŸ¥è¯¢ï¼Œåªè¿”å›ä¼˜åŒ–åçš„æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚
"""

            # ä½¿ç”¨ async_call_llm_chain
            session_id = f"rewrite_{state.get('doc_name', 'default')}"
            rewritten = await self.llm.async_call_llm_chain(
                role=RetrievalRole.QUERY_REWRITE,
                input_prompt=prompt,
                session_id=session_id
            )

            # æ¸…ç†è¿”å›ç»“æœï¼ˆå»é™¤å¤šä½™çš„å¼•å·ã€æ¢è¡Œç­‰ï¼‰
            rewritten = rewritten.strip().strip('"').strip("'").strip()

            logger.info(f"âœ… [Rewrite] æŸ¥è¯¢ä¼˜åŒ–å®Œæˆ")
            logger.info(f"   åŸå§‹: {original_query}")
            logger.info(f"   ä¼˜åŒ–: {rewritten}")

            state["rewritten_query"] = rewritten
            return state

        except Exception as e:
            logger.error(f"âŒ [Rewrite] æŸ¥è¯¢é‡å†™å¤±è´¥: {e}", exc_info=True)
            # å¤±è´¥æ—¶ä½¿ç”¨åŸå§‹æŸ¥è¯¢
            state["rewritten_query"] = original_query
            return state

    async def think(self, state: RetrievalState) -> Dict:
        """
        æ­¥éª¤1ï¼šæ€è€ƒä¸‹ä¸€æ­¥ä½¿ç”¨å“ªä¸ªå·¥å…·

        åŸºäºå½“å‰æŸ¥è¯¢å’Œå·²æ£€ç´¢å†…å®¹ï¼Œå†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œ
        """
        current_iteration = state.get("current_iteration", 0)

        logger.info(f"ğŸ¤” [Think] ========== æ­¥éª¤1: æ€è€ƒå·¥å…·é€‰æ‹© ==========")
        logger.info(f"ğŸ¤” [Think] è¿­ä»£è¿›åº¦: {current_iteration + 1}/{state['max_iterations']}")
        logger.info(f"ğŸ¤” [Think] å·²ç´¯ç§¯å†…å®¹: {len(state.get('retrieved_content', []))} æ¡")

        # æ˜¾ç¤ºæŸ¥è¯¢ä¿¡æ¯
        current_query = state.get("rewritten_query", state["query"])
        if current_query != state["query"]:
            logger.info(f"ğŸ¤” [Think] åŸå§‹æŸ¥è¯¢: {state['query']}")
            logger.info(f"ğŸ¤” [Think] ä¼˜åŒ–æŸ¥è¯¢: {current_query}")
        else:
            logger.info(f"ğŸ¤” [Think] å½“å‰æŸ¥è¯¢: {current_query}")

        try:
            # è·å–å·¥å…·æè¿°ï¼ˆä»é…ç½®æ–‡ä»¶ï¼‰
            from src.config.tools.retrieval_tools import format_all_tools_for_llm
            tools_description = format_all_tools_for_llm()

            # è·å–ä¸­é—´æ€»ç»“ï¼ˆå¦‚æœæœ‰ï¼‰
            intermediate_summary = state.get("intermediate_summary", "")

            # è·å–ä¸Šä¸€è½®å·¥å…·è°ƒç”¨ç»“æœ
            last_action = state.get("actions", [])[-1] if state.get("actions", []) else None
            last_result_info = ""
            if last_action:
                tool_name = last_action.get("tool", "æœªçŸ¥")
                result_count = len(state.get("last_result", []))
                last_result_info = f"\nä¸Šä¸€è½®è°ƒç”¨: {tool_name}ï¼Œè¿”å› {result_count} æ¡ç»“æœ"
                if intermediate_summary:
                    last_result_info += f"\nå½“å‰æ€»ç»“:\n{intermediate_summary}"  # é™åˆ¶é•¿åº¦

            # ä½¿ç”¨ rewritten_query æˆ–åŸå§‹ query
            current_query = state.get("rewritten_query", state["query"])

            # å¦‚æœ query è¢«é‡å†™ï¼Œæ˜¾ç¤ºå¯¹æ¯”
            query_info = f"å½“å‰æŸ¥è¯¢: {current_query}"
            if current_query != state["query"]:
                query_info = f"åŸå§‹æŸ¥è¯¢: {state['query']}\nä¼˜åŒ–æŸ¥è¯¢: {current_query}"

            # æ„å»º promptï¼ˆåªåŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè§’è‰²å’Œå·¥å…·ä¿¡æ¯åœ¨ system promptï¼‰
            prompt = f"""
# å½“å‰æ£€ç´¢çŠ¶æ€

{query_info}
å½“å‰è¿­ä»£: {current_iteration + 1}/{state['max_iterations']}
å·²ç´¯ç§¯å†…å®¹: {len(state.get('retrieved_content', []))} æ¡
{last_result_info}

# å†å²åŠ¨ä½œè®°å½•

{state.get('actions', [])}

# ä»»åŠ¡è¦æ±‚

è¯·åˆ†æå½“å‰æ£€ç´¢çŠ¶æ€ï¼Œå†³å®šä¸‹ä¸€æ­¥ä½¿ç”¨å“ªä¸ªå·¥å…·ä»¥åŠå¦‚ä½•è°ƒç”¨ã€‚

è¿”å›JSONæ ¼å¼ï¼š
{{
    "thought": "åˆ†æå½“å‰çŠ¶æ€ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªå·¥å…·",
    "action": "å·¥å…·åç§°",
    "action_input": "ä¼ é€’ç»™å·¥å…·çš„å‚æ•°ï¼ˆæŸ¥è¯¢å­—ç¬¦ä¸²æˆ–æ ‡é¢˜åˆ—è¡¨ï¼‰"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

            # ä½¿ç”¨ async_call_llm_chain
            session_id = f"think_{state.get('doc_name', 'default')}"
            response = await self.llm.async_call_llm_chain(
                role=RetrievalRole.RETRIEVAL,
                input_prompt=prompt,
                session_id=session_id,
                system_format_dict={"tool_info_dict": tools_description}
            )

            # è§£æJSON - æ›´å¥å£®çš„è§£ææ–¹æ³•
            decision = None
            try:
                # æ–¹æ³•1: å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                decision = json.loads(response.strip())
            except json.JSONDecodeError:
                try:
                    # æ–¹æ³•2: ä½¿ç”¨æ­£åˆ™æå–JSONå¯¹è±¡ï¼ˆéè´ªå©ªåŒ¹é…ï¼Œå¤„ç†åµŒå¥—ï¼‰
                    json_match = re.search(r'\{(?:[^{}]|(?:\{[^{}]*\}))*\}', response, re.DOTALL)
                    if json_match:
                        decision = json.loads(json_match.group())
                except (json.JSONDecodeError, AttributeError) as e:
                    logger.warning(f"âš ï¸ [Think] JSONè§£æå¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤ç­–ç•¥")

            # æå–å†³ç­–å­—æ®µ
            if decision and isinstance(decision, dict):
                thought = decision.get("thought", "")
                action = decision.get("action", "search_by_context")
                action_input = decision.get("action_input", current_query)
            else:
                # é»˜è®¤ä½¿ç”¨è¯­ä¹‰æ£€ç´¢
                thought = "é»˜è®¤ç­–ç•¥ï¼šJSONè§£æå¤±è´¥"
                action = "search_by_context"
                action_input = current_query  # ä½¿ç”¨ current_query è€Œä¸æ˜¯é‡æ–°è·å–

            logger.info(f"ğŸ’¡ [Think] é€‰æ‹©å·¥å…·: {action}")
            logger.info(f"ğŸ’¡ [Think] åŸå§‹è¾“å…¥: {state['query']}")
            logger.debug(f"æ€è€ƒè¿‡ç¨‹: {thought}")

            # æ›´æ–°çŠ¶æ€ï¼ˆå‚æ•°è§£æäº¤ç»™ act èŠ‚ç‚¹å¤„ç†ï¼‰
            state["thoughts"] = state.get("thoughts", []) + [thought]
            state["current_tool"] = action
            state["action_input"] = action_input  # å­˜å‚¨åŸå§‹è¾“å…¥ï¼Œç”± act è§£æ
            state["current_iteration"] = current_iteration + 1

            return state

        except Exception as e:
            logger.error(f"âŒ [Think] æ€è€ƒå¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())

            # å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤ç­–ç•¥
            state["current_tool"] = "search_by_context"
            state["action_input"] = ""  # ç©ºå­—ç¬¦ä¸²ï¼Œact ä¼šä½¿ç”¨ current_query
            state["thoughts"] = state.get("thoughts", []) + ["æ€è€ƒå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥"]
            state["current_iteration"] = current_iteration + 1

            return state

    async def act(self, state: RetrievalState) -> Dict:
        """
        æ­¥éª¤2ï¼šæ‰§è¡Œå·¥å…·è°ƒç”¨

        ä» state è¯»å–ï¼š
        - current_tool: å·¥å…·åç§°
        - action_input: åŸå§‹è¾“å…¥ï¼ˆå­—ç¬¦ä¸²ï¼‰
        - rewritten_query/query: ä¼˜åŒ–åçš„æŸ¥è¯¢

        æ ¹æ®å·¥å…·é…ç½®æ„å»ºæ­£ç¡®çš„å‚æ•°å¹¶æ‰§è¡Œã€‚
        """
        tool_name = state["current_tool"]
        action_input = state.get("action_input", "")
        current_query = state.get("rewritten_query", state["query"])

        logger.info(f"ğŸ”§ [Act] ========== æ­¥éª¤2: æ‰§è¡Œå·¥å…·è°ƒç”¨ ==========")
        logger.info(f"ğŸ”§ [Act] å·¥å…·åç§°: {tool_name}")
        logger.info(f"ğŸ”§ [Act] åŸå§‹è¾“å…¥: {state['query']}")
        logger.info(f"ğŸ”§ [Act] å½“å‰æŸ¥è¯¢: {current_query}")

        try:
            # æ ¹æ®å·¥å…·é…ç½®æ„å»ºå‚æ•°
            from src.config.tools.retrieval_tools import get_tool_by_name
            tool_config = get_tool_by_name(tool_name)

            if tool_config:
                # è·å–å·¥å…·éœ€è¦çš„å‚æ•°
                required_params = tool_config.get("parameters", {})
                params = {}

                # æ ¹æ®å‚æ•°ç±»å‹æ„å»ºå‚æ•°å­—å…¸
                if "query" in required_params:
                    # å·¥å…·éœ€è¦ query å‚æ•°ï¼Œç›´æ¥ä½¿ç”¨ current_queryï¼ˆä¼˜åŒ–åçš„æŸ¥è¯¢ï¼‰
                    params["query"] = current_query
                    logger.debug(f"ä½¿ç”¨ current_query ä½œä¸º query å‚æ•°")

                elif "title_list" in required_params:
                    # search_by_title éœ€è¦ title_list å‚æ•°
                    # action_input åº”è¯¥æ˜¯ JSON æ ¼å¼çš„æ ‡é¢˜åˆ—è¡¨
                    try:
                        # å°è¯•è§£æä¸º JSON åˆ—è¡¨
                        if isinstance(action_input, str):
                            import json
                            title_list = json.loads(action_input)
                        elif isinstance(action_input, list):
                            title_list = action_input
                        else:
                            # å¦‚æœä¸æ˜¯åˆ—è¡¨æ ¼å¼ï¼ŒåŒ…è£…æˆå•å…ƒç´ åˆ—è¡¨
                            title_list = [str(action_input)]

                        params["title_list"] = title_list
                        logger.debug(f"è§£ææ ‡é¢˜åˆ—è¡¨: {title_list}")
                    except (json.JSONDecodeError, ValueError) as e:
                        logger.warning(f"âš ï¸ [Act] æ ‡é¢˜åˆ—è¡¨è§£æå¤±è´¥: {e}, å°è¯•å…¶ä»–æ ¼å¼")
                        # å¤±è´¥æ—¶å°è¯•æŒ‰è¡Œåˆ†å‰²æˆ–é€—å·åˆ†å‰²
                        if isinstance(action_input, str):
                            if '\n' in action_input:
                                title_list = [t.strip() for t in action_input.split('\n') if t.strip()]
                            elif ',' in action_input:
                                title_list = [t.strip() for t in action_input.split(',') if t.strip()]
                            else:
                                title_list = [action_input] if action_input else []
                        else:
                            title_list = [str(action_input)] if action_input else []
                        params["title_list"] = title_list
                        logger.debug(f"ä½¿ç”¨åˆ†å‰²æ–¹å¼è§£æ: {title_list}")

                else:
                    # æœªçŸ¥å‚æ•°ç±»å‹ï¼Œä½¿ç”¨ action_input æˆ– current_query
                    logger.warning(f"âš ï¸ [Act] å·¥å…· {tool_name} çš„å‚æ•°ç±»å‹æœªçŸ¥ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†")
                    first_param_name = list(required_params.keys())[0] if required_params else "query"
                    params[first_param_name] = action_input if action_input else current_query

            else:
                # å·¥å…·é…ç½®æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
                logger.warning(f"âš ï¸ [Act] å·¥å…·é…ç½®æœªæ‰¾åˆ°: {tool_name}, ä½¿ç”¨é»˜è®¤å‚æ•°")
                params = {"query": current_query}

            logger.info(f"ğŸ”§ [Act] æ„å»ºçš„å‚æ•°: {params}")

            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            # æ„å»ºå¯ç”¨å·¥å…·å­—å…¸
            available_tools = self._build_retrieval_tools()

            # æ‰§è¡Œå·¥å…·
            if tool_name in available_tools:
                tool_func = available_tools[tool_name]["function"]

                # æ™ºèƒ½å‚æ•°ä¼ é€’ï¼šæ£€æŸ¥å‡½æ•°ç­¾å
                import inspect
                sig = inspect.signature(tool_func)
                func_params = list(sig.parameters.keys())

                # å¦‚æœå‡½æ•°åªæ¥å—ä¸€ä¸ªå‚æ•°ï¼ˆé™¤äº†selfï¼‰
                if len(func_params) == 1:
                    param_name = func_params[0]
                    # ä½¿ç”¨å‡½æ•°ç­¾åä¸­çš„å‚æ•°å
                    if param_name in params:
                        result = await tool_func(params[param_name])
                    else:
                        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„å‚æ•°åï¼Œå°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨å‚æ•°
                        logger.warning(f"âš ï¸ [Act] å‚æ•°åä¸åŒ¹é…ï¼ŒæœŸæœ› {param_name}ï¼Œå®é™…æœ‰ {list(params.keys())}")
                        first_value = next(iter(params.values())) if params else None
                        result = await tool_func(first_value)
                # å¦åˆ™å°è¯•è§£åŒ…æ‰€æœ‰å‚æ•°
                else:
                    # è¿‡æ»¤å‡ºå‡½æ•°å®é™…éœ€è¦çš„å‚æ•°
                    filtered_params = {k: v for k, v in params.items() if k in func_params}
                    result = await tool_func(**filtered_params)

            else:
                logger.warning(f"âš ï¸ [Act] æœªçŸ¥å·¥å…·: {tool_name}ï¼Œä½¿ç”¨é»˜è®¤æ£€ç´¢")
                query = params.get("query", state.get("query", ""))
                result = await self.search_by_context(query)

            result_count = len(result) if isinstance(result, list) else 'dict'
            logger.info(f"ğŸ”§ [Act] âœ… å·¥å…·æ‰§è¡Œå®Œæˆ")
            logger.info(f"ğŸ”§ [Act]   - è¿”å›ç»“æœ: {result_count} ä¸ª")

            # è·å–å·¥å…·é…ç½®ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ summary
            from src.config.tools.retrieval_tools import get_tool_by_name
            tool_config = get_tool_by_name(tool_name)
            requires_summary = tool_config.get("requires_summary", True) if tool_config else True

            logger.info(f"ğŸ” [Act] å·¥å…· {tool_name} requires_summary={requires_summary}")

            # è®°å½•åŠ¨ä½œå’Œå‚æ•°
            state["current_params"] = params  # è®°å½•æ„å»ºçš„å‚æ•°
            state["actions"] = state.get("actions", []) + [{
                "tool": tool_name,
                "params": params
            }]
            state["last_result"] = result
            state["requires_summary"] = requires_summary

            # å¦‚æœä¸éœ€è¦ summaryï¼Œç›´æ¥å°†ç»“æœæ·»åŠ åˆ° intermediate_summary
            if not requires_summary and result:
                current_summary = state.get("intermediate_summary", "")
                summary_block = (
                    "\n\n"
                    "=== å·¥å…·ä¿¡æ¯ ===\n"
                    f"{tool_name}\n"
                    "=== Tool Result ===\n"
                    f"{str(result)}\n"
                )

                state["intermediate_summary"] = current_summary + summary_block
                logger.info(f"âœ… [Act] å·²å°†å·¥å…·ä¿¡æ¯å’Œç»“æœæ·»åŠ åˆ°æ€»ç»“ä¸­")

            return state

        except Exception as e:
            logger.error(f"âŒ [Act] å·¥å…·æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)

            # è·å–å·¥å…·é…ç½®ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè¦è®¾ç½®ï¼‰
            from src.config.tools.retrieval_tools import get_tool_by_name
            tool_config = get_tool_by_name(tool_name)
            requires_summary = tool_config.get("requires_summary", True) if tool_config else True

            # å¦‚æœ params æœªå®šä¹‰ï¼ˆå¯èƒ½åœ¨å‚æ•°æ„å»ºæ—¶å°±å¤±è´¥äº†ï¼‰ï¼Œä½¿ç”¨ç©ºå­—å…¸
            error_params = params if 'params' in locals() else {"query": current_query}

            # è¿”å›ç©ºç»“æœï¼Œä½†ä¿ç•™åŠ¨ä½œè®°å½•
            state["current_params"] = error_params
            state["actions"] = state.get("actions", []) + [{
                "tool": tool_name,
                "params": error_params,
                "error": str(e)
            }]
            state["last_result"] = []
            state["requires_summary"] = requires_summary

            return state

    async def evaluate(self, state: RetrievalState) -> Dict:
        """
        æ­¥éª¤4ï¼šè¯„ä¼°ä¸­é—´æ€»ç»“æ˜¯å¦è¶³ä»¥å›ç­”ç”¨æˆ·æŸ¥è¯¢

        å¦‚æœä¸Šä¸€æ­¥è·³è¿‡äº† summaryï¼ˆå·¥å…·ä¸éœ€è¦æ€»ç»“ï¼‰ï¼Œåˆ™è‡ªåŠ¨åˆ¤æ–­ä¸ºéœ€è¦ç»§ç»­æ£€ç´¢
        """
        logger.info(f"âš–ï¸ [Evaluate] ========== æ­¥éª¤3: è¯„ä¼°æ£€ç´¢ç»“æœ ==========")

        try:
            # ä½¿ç”¨Agentçº§åˆ«çš„LLMå®ä¾‹
            llm = self.llm

            # è·å–ä¸­é—´æ€»ç»“
            intermediate_summary = state.get("intermediate_summary", "")
            retrieved_content = state.get("retrieved_content", [])

            logger.info(f"âš–ï¸ [Evaluate] å·²æ£€ç´¢å†…å®¹: {len(retrieved_content)} æ¡")
            logger.info(f"âš–ï¸ [Evaluate] ä¸­é—´æ€»ç»“é•¿åº¦: {len(intermediate_summary)} å­—ç¬¦")

            # å¦‚æœä¸­é—´æ€»ç»“ä¸ºç©ºï¼ˆå¯èƒ½æ˜¯è·³è¿‡äº† summary èŠ‚ç‚¹ï¼‰
            if not intermediate_summary:
                logger.info("âš ï¸ [Evaluate] ä¸­é—´æ€»ç»“ä¸ºç©ºï¼ˆå·¥å…·ä¸éœ€è¦æ€»ç»“ï¼‰ï¼Œè‡ªåŠ¨ç»§ç»­æ£€ç´¢")
                state["is_complete"] = False
                state["reason"] = "ä¸Šä¸€æ­¥å·¥å…·ä¸éœ€è¦æ€»ç»“ï¼Œç»§ç»­æ£€ç´¢"
                return state

            # è·å–å½“å‰è¿­ä»£ä¿¡æ¯
            current_iteration = state.get("current_iteration", 0)
            max_iterations = state.get("max_iterations", 5)
            formatted_data = state.get("formatted_data", [])

            # æ„å»ºé¡µç ä¿¡æ¯ä¾› LLM å‚è€ƒ
            pages_info = ""
            if formatted_data and isinstance(formatted_data, list):
                pages_list = []
                for item in formatted_data:
                    title = item.get("title", "æœªçŸ¥ç« èŠ‚")
                    pages = item.get("pages", [])
                    if pages:
                        pages_str = ", ".join(map(str, pages))
                        pages_list.append(f"- {title}: é¡µç  {pages_str}")
                if pages_list:
                    pages_info = "\n".join(pages_list)

            prompt = f"""
ç”¨æˆ·æŸ¥è¯¢: {state['query']}

å½“å‰è¿›åº¦: ç¬¬ {current_iteration}/{max_iterations} è½®æ£€ç´¢
å·²æ£€ç´¢å†…å®¹æ•°: {len(retrieved_content) if isinstance(retrieved_content, list) else 0} æ¡

# æ£€ç´¢æ€»ç»“

{intermediate_summary}

# æ¶‰åŠé¡µç 

{pages_info if pages_info else "æš‚æ— é¡µç ä¿¡æ¯"}

# ä»»åŠ¡

è¯·è¯„ä¼°å½“å‰æ£€ç´¢ç»“æœæ˜¯å¦è¶³ä»¥å›ç­”ç”¨æˆ·æŸ¥è¯¢ã€‚

**æ³¨æ„**ï¼š
- å¦‚æœå·²è¾¾åˆ°ç¬¬ {max_iterations} è½®ä¸”æœ‰ç›¸å…³å†…å®¹ï¼Œå»ºè®®å®Œæˆè¯„ä¼°
- reason å¿…é¡»å…·ä½“ï¼šis_complete=true æ—¶è¯´æ˜æ¶‰åŠçš„å…³é”®é¡µç ï¼Œis_complete=false æ—¶ç»™å‡ºæ£€ç´¢å»ºè®®

è¿”å›JSONæ ¼å¼ï¼š
{{
    "is_complete": true/false,
    "reason": "è¯¦ç»†è¯„ä¼°åŸå› ï¼ˆå‚è€ƒç³»ç»Ÿæç¤ºçš„æ ¼å¼è¦æ±‚ï¼‰",
    "confidence": 0.0-1.0
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

            # ä½¿ç”¨ async_call_llm_chain
            session_id = f"evaluate_{state.get('doc_name', 'default')}"
            response = await llm.async_call_llm_chain(
                role=RetrievalRole.RETRIEVAL_EVALUATOR,
                input_prompt=prompt,
                session_id=session_id
            )

            # è§£æJSON - æ›´å¥å£®çš„è§£ææ–¹æ³•
            evaluation = None
            try:
                # æ–¹æ³•1: å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
                evaluation = json.loads(response.strip())
            except json.JSONDecodeError:
                try:
                    # æ–¹æ³•2: ä½¿ç”¨æ­£åˆ™æå–JSONå¯¹è±¡
                    json_match = re.search(r'\{(?:[^{}]|(?:\{[^{}]*\}))*\}', response, re.DOTALL)
                    if json_match:
                        evaluation = json.loads(json_match.group())
                except (json.JSONDecodeError, AttributeError) as e:
                    logger.warning(f"âš ï¸ [Evaluate] JSONè§£æå¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤è¯„ä¼°")

            # æå–è¯„ä¼°ç»“æœ
            if evaluation and isinstance(evaluation, dict):
                is_complete = evaluation.get("is_complete", False)
                reason = evaluation.get("reason", "")
            else:
                # é»˜è®¤ï¼šå¦‚æœæœ‰å†…å®¹å°±è®¤ä¸ºå®Œæˆ
                is_complete = len(retrieved_content) > 0
                reason = "é»˜è®¤è¯„ä¼°ï¼šJSONè§£æå¤±è´¥"

            logger.info(f"âš–ï¸ [Evaluate] ========================================")
            logger.info(f"âš–ï¸ [Evaluate] è¯„ä¼°ç»“æœ: {'âœ… æ£€ç´¢å®Œæˆ' if is_complete else 'ğŸ”„ ç»§ç»­æ£€ç´¢'}")
            logger.info(f"âš–ï¸ [Evaluate] è¯„ä¼°åŸå› : {reason}")
            logger.info(f"âš–ï¸ [Evaluate] ========================================")

            state["is_complete"] = is_complete
            state["reason"] = reason  # ä¿å­˜è¯„ä¼°åŸå› ï¼Œä¾› format èŠ‚ç‚¹ä½¿ç”¨
            return state

        except Exception as e:
            logger.error(f"âŒ [Evaluate] è¯„ä¼°å¤±è´¥: {e}")

            # å¤±è´¥æ—¶æ ¹æ®è¿­ä»£æ¬¡æ•°åˆ¤æ–­
            current_iteration = state.get("current_iteration", 0)
            is_complete = current_iteration >= state["max_iterations"]
            reason = f"è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {state['max_iterations']}"

            state["is_complete"] = is_complete
            state["reason"] = reason
            return state

    async def summary(self, state: RetrievalState) -> Dict:
        """
        æ­¥éª¤3ï¼šç´¯ç§¯æ£€ç´¢æ•°æ®å¹¶å¯¹å½“å‰æ‰€æœ‰ç»“æœè¿›è¡Œä¸­é—´æ€»ç»“ï¼ˆå¾ªç¯å†…ï¼‰

        æ¯æ¬¡æ£€ç´¢åï¼š
        1. ç´¯ç§¯ last_result åˆ° retrieved_content
        2. å¯¹æ‰€æœ‰ç´¯ç§¯æ•°æ®è¿›è¡Œæ€»ç»“
        è¿”å›ï¼š
        - intermediate_summary: ä¸­é—´æ€»ç»“ï¼ˆä¾› evaluate è¯„ä¼°ï¼‰
        - formatted_data: æ ¼å¼åŒ–çš„åŸå§‹æ•°æ®ï¼ˆä¾›æœ€ç»ˆ format ä½¿ç”¨ï¼‰
        """
        logger.info(f"ğŸ“ [Summary] ========== æ­¥éª¤2.5: ç´¯ç§¯å¹¶æ€»ç»“æ•°æ® ==========")

        try:
            # æ­¥éª¤1ï¼šç´¯ç§¯æœ¬æ¬¡æ£€ç´¢ç»“æœåˆ° retrieved_content
            last_result = state.get("last_result", [])
            retrieved_content = state.get("retrieved_content", [])

            logger.info(f"ğŸ“ [Summary] æœ¬æ¬¡ç»“æœ: {len(last_result)} æ¡")
            logger.info(f"ğŸ“ [Summary] å·²ç´¯ç§¯: {len(retrieved_content)} æ¡")

            # ç¡®ä¿æ˜¯ list ç±»å‹
            if not isinstance(retrieved_content, list):
                retrieved_content = []

            # ç´¯ç§¯æ–°ç»“æœ
            if isinstance(last_result, list) and last_result:
                for item in last_result:
                    if isinstance(item, dict):
                        # æ–°æ ¼å¼ï¼šåŒ…å« contentã€titleã€pages
                        retrieved_content.append(item)
                    elif isinstance(item, str) and item.strip():
                        # å…¼å®¹æ—§æ ¼å¼ï¼šçº¯å­—ç¬¦ä¸²
                        retrieved_content.append({
                            "content": item,
                            "title": "æœªçŸ¥ç« èŠ‚",
                            "pages": []
                        })

                logger.info(f"âœ… [Summary] ç´¯ç§¯ {len(last_result)} æ¡æ–°ç»“æœï¼Œæ€»è®¡ {len(retrieved_content)} æ¡")

            # æ›´æ–° state
            state["retrieved_content"] = retrieved_content

            # æ­¥éª¤2ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
            if not retrieved_content:
                logger.warning("âš ï¸ [Summary] æ²¡æœ‰æ£€ç´¢åˆ°ä»»ä½•å†…å®¹")
                state["intermediate_summary"] = "æœªæ£€ç´¢åˆ°ç›¸å…³å†…å®¹ã€‚"
                state["formatted_data"] = []
                return state

            # æ­¥éª¤3ï¼šæ„å»ºæ ¼å¼åŒ–çš„åŸå§‹æ•°æ®
            formatted_data = []
            items_text = ""

            for idx, item in enumerate(retrieved_content, 1):
                if isinstance(item, dict):
                    content = item.get("content", "")
                    title = item.get("title", "æœªçŸ¥ç« èŠ‚")
                    pages = item.get("pages", [])
                elif isinstance(item, str):
                    content = item
                    title = "æœªçŸ¥ç« èŠ‚"
                    pages = []
                else:
                    continue

                # æ ¼å¼åŒ–å•æ¡æ•°æ®
                pages_str = ", ".join(map(str, pages)) if pages else "æœªçŸ¥"
                formatted_item = {
                    "index": idx,
                    "title": title,
                    "pages": pages,
                    "content": content
                }
                formatted_data.append(formatted_item)

                # æ„å»º LLM æç¤ºæ–‡æœ¬ï¼ˆé™åˆ¶é•¿åº¦é¿å…è¿‡é•¿ï¼‰
                content_preview = content
                items_text += f"\n\nã€æ¡ç›® {idx}ã€‘\n"
                items_text += f"æ¥æºç« èŠ‚: {title}\n"
                items_text += f"é¡µç : {pages_str}\n"
                items_text += f"å†…å®¹:\n{content_preview}\n"

            # æ­¥éª¤4ï¼šä½¿ç”¨ LLM ç”Ÿæˆä¸­é—´æ€»ç»“
            prompt = f"""
å½“å‰ç´¯ç§¯æ£€ç´¢ç»“æœï¼ˆå…± {len(formatted_data)} æ¡ï¼‰ï¼š

{items_text}

# ä»»åŠ¡

å¯¹ä»¥ä¸Šæ£€ç´¢å†…å®¹è¿›è¡Œå®¢è§‚æ€»ç»“ï¼Œæå–å…³é”®ä¿¡æ¯å¹¶å‹ç¼©å†—ä½™å†…å®¹ã€‚

æ€»ç»“åº”åŒ…å«ï¼š
1. æ¶µç›–çš„ç« èŠ‚å’Œé¡µç èŒƒå›´
2. æ¯ä¸ªç« èŠ‚çš„æ ¸å¿ƒå†…å®¹ï¼ˆäº‹å®ã€æ•°æ®ã€ç»“è®ºã€æ¦‚å¿µç­‰ï¼‰
3. é‡è¦çš„æ•°å€¼ã€å›¾è¡¨ã€å…¬å¼æè¿°
4. æ¸…æ™°çš„ç»“æ„ç»„ç»‡ï¼ˆæŒ‰ç« èŠ‚æˆ–ä¸»é¢˜ï¼‰

è¯·ä¿æŒå®¢è§‚ä¸­ç«‹ï¼Œå¿ å®åŸæ–‡ï¼Œä½¿ç”¨ Markdown æ ¼å¼å‘ˆç°ã€‚
"""

            # ä½¿ç”¨ async_call_llm_chain
            session_id = f"summary_{state.get('doc_name', 'default')}"
            summary_result = await self.llm.async_call_llm_chain(
                role=RetrievalRole.CONTEXT_SUMMARIZER,
                input_prompt=prompt,
                session_id=session_id
            )

            logger.info(f"âœ… [Summary] ä¸­é—´æ€»ç»“å®Œæˆï¼Œé•¿åº¦: {len(summary_result)} å­—ç¬¦")
            logger.info(f"âœ… [Summary] æ ¼å¼åŒ–æ•°æ®æ¡æ•°: {len(formatted_data)}")

            # ä¿å­˜ä¸­é—´æ€»ç»“å’Œæ ¼å¼åŒ–åŸå§‹æ•°æ®
            state["intermediate_summary"] = summary_result
            state["formatted_data"] = formatted_data

            return state

        except Exception as e:
            logger.error(f"âŒ [Summary] ä¸­é—´æ€»ç»“å¤±è´¥: {e}", exc_info=True)

            # å¤±è´¥æ—¶è¿”å›ç®€å•çš„æç¤ºä¿¡æ¯
            retrieved_content = state.get("retrieved_content", [])
            content_count = len(retrieved_content) if isinstance(retrieved_content, list) else 0

            fallback_summary = f"ä¸­é—´æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼Œä½†å·²æ£€ç´¢åˆ° {content_count} æ¡ç›¸å…³å†…å®¹ã€‚"

            state["intermediate_summary"] = fallback_summary
            state["formatted_data"] = []
            return state

    def should_summarize(self, state: RetrievalState) -> str:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œ summary

        æ ¹æ®ä¸Šä¸€ä¸ªå·¥å…·çš„ requires_summary é…ç½®å†³å®š

        Returns:
            "summary" - éœ€è¦æ€»ç»“
            "evaluate" - ç›´æ¥è¯„ä¼°ï¼ˆè·³è¿‡æ€»ç»“ï¼‰
        """
        requires_summary = state.get("requires_summary", True)

        if requires_summary:
            logger.info(f"ğŸ“ [Route] å·¥å…·éœ€è¦æ€»ç»“ï¼Œè¿›å…¥ summary èŠ‚ç‚¹")
            return "summary"
        else:
            logger.info(f"â­ï¸ [Route] å·¥å…·ä¸éœ€è¦æ€»ç»“ï¼Œç›´æ¥è¿›å…¥ evaluate èŠ‚ç‚¹")
            return "evaluate"

    def should_continue(self, state: RetrievalState) -> str:
        """
        åˆ¤æ–­æ˜¯å¦ç»§ç»­æ£€ç´¢

        Returns:
            "continue" æˆ– "finish"
        """
        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if state.get("is_complete", False):
            return "finish"

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°
        current_iteration = state.get("current_iteration", 0)
        max_iterations = state.get("max_iterations", 5)

        if current_iteration >= max_iterations:
            logger.warning(f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
            return "finish"

        return "continue"

    async def format(self, state: RetrievalState) -> Dict:
        """
        æ­¥éª¤5ï¼šæœ€ç»ˆç²¾å‡†æ€»ç»“ï¼ˆæ ¹æ®é¡µç æå–åŸæ–‡å¹¶ç”Ÿæˆç²¾å‡†ç­”æ¡ˆï¼‰

        æ ¹æ®ï¼š
        1. evaluate çš„ reasonï¼ˆç¼ºå°‘ä»€ä¹ˆä¿¡æ¯æˆ–ä¸ºä»€ä¹ˆè¶³å¤Ÿï¼‰
        2. intermediate_summaryï¼ˆä¸­é—´æ€»ç»“ï¼‰
        3. ç”¨æˆ·çš„ query

        ä½¿ç”¨ LLMï¼š
        1. åˆ¤æ–­ç²¾å‡†å›ç­”é—®é¢˜éœ€è¦å“ªäº›é¡µç 
        2. ä» formatted_data ä¸­æå–è¿™äº›é¡µç çš„åŸæ–‡
        3. ç”Ÿæˆæœ€ç»ˆæ€»ç»“ï¼Œå°½å¯èƒ½ä¿ç•™åŸæ–‡ä¿¡æ¯ã€æ•°æ®ã€å›¾ç‰‡å†…å®¹

        è¿”å›ï¼š
        - final_summary: æœ€ç»ˆç²¾å‡†æ€»ç»“
        - selected_pages: é€‰æ‹©çš„é¡µç åˆ—è¡¨
        """
        logger.info(f"ğŸ¯ [Format] ========== æ­¥éª¤4: ç”Ÿæˆæœ€ç»ˆæ€»ç»“ ==========")

        try:
            logger.info(f"ğŸ¯ [Format] å¼€å§‹ç”Ÿæˆç²¾å‡†ç­”æ¡ˆ...")
            # è·å–å¿…è¦æ•°æ®
            query = state.get("query", "")
            intermediate_summary = state.get("intermediate_summary", "")
            formatted_data = state.get("formatted_data", [])
            reason = state.get("reason", "")  # evaluate çš„è¯„ä¼°åŸå› 
            if not formatted_data:
                logger.warning("âš ï¸ [Format] æ²¡æœ‰æ ¼å¼åŒ–æ•°æ®ï¼Œä½¿ç”¨ä¸­é—´æ€»ç»“ä½œä¸ºæœ€ç»ˆæ€»ç»“")
                state["final_summary"] = intermediate_summary
                state["selected_pages"] = []
                return state

            # æ­¥éª¤1ï¼šä½¿ç”¨ LLM åˆ¤æ–­éœ€è¦å“ªäº›é¡µç 
            # æ„å»ºé¡µç ä¿¡æ¯åˆ—è¡¨
            pages_info = []
            for item in formatted_data:
                pages = item.get("pages", [])
                title = item.get("title", "æœªçŸ¥ç« èŠ‚")
                if pages:
                    pages_str = ", ".join(map(str, pages))
                    pages_info.append(f"- {title}: é¡µç  {pages_str}")

            pages_info_text = "\n".join(pages_info)

            page_selection_prompt = f"""
# é¡µç é€‰æ‹©ä»»åŠ¡

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

è¯„ä¼°ç»“è®ºï¼š{reason}

æ£€ç´¢æ€»ç»“ï¼š
{intermediate_summary}

# å¯ç”¨é¡µç æ¸…å•

{pages_info_text}

# é€‰æ‹©è¦æ±‚

ä»ä»¥ä¸Šé¡µç ä¸­é€‰æ‹©æœ€èƒ½ç²¾å‡†å›ç­”ç”¨æˆ·é—®é¢˜çš„å…³é”®é¡µç ã€‚

é€‰æ‹©åŸåˆ™ï¼š
- ä¼˜å…ˆé€‰æ‹©ç›´æ¥å›ç­”é—®é¢˜çš„é¡µç 
- åŒ…å«é‡è¦æ•°æ®ã€å›¾è¡¨ã€ç»“è®ºçš„é¡µç 
- å¦‚æœå¤šä¸ªç« èŠ‚éƒ½åŒ…å«æ ¸å¿ƒä¿¡æ¯ï¼Œå¯é€‰æ‹©å¤šä¸ª
- é¿å…é€‰æ‹©æ¬¡è¦æˆ–é‡å¤çš„é¡µç 

è¿”å›JSONæ ¼å¼ï¼š
{{
    "selected_pages": [1, 2, 3, ...],
    "selection_reason": "é€‰æ‹©ç†ç”±"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

            # ä½¿ç”¨ LLM é€‰æ‹©é¡µç 
            session_id = f"format_{state.get('doc_name', 'default')}"
            page_selection_response = await self.llm.async_call_llm_chain(
                role=RetrievalRole.PAGE_SELECTOR,
                input_prompt=page_selection_prompt,
                session_id=session_id
            )

            # è§£æé¡µç é€‰æ‹©ç»“æœ
            selected_pages = []
            try:
                selection_result = json.loads(page_selection_response.strip())
                selected_pages = selection_result.get("selected_pages", [])
                logger.info(f"âœ… [Format] LLM é€‰æ‹©é¡µç : {selected_pages}")
            except json.JSONDecodeError:
                logger.warning("âš ï¸ [Format] é¡µç é€‰æ‹©JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨æ‰€æœ‰é¡µç ")
                # æ”¶é›†æ‰€æœ‰é¡µç 
                all_pages = set()
                for item in formatted_data:
                    pages = item.get("pages", [])
                    all_pages.update(pages)
                selected_pages = sorted(list(all_pages))

            # æ­¥éª¤2ï¼šæ ¹æ®é€‰æ‹©çš„é¡µç æå–åŸæ–‡
            selected_pages_set = {str(p) for p in selected_pages}
            selected_content = []
            for item in formatted_data:
                item_pages = item.get("pages", [])
                # æ£€æŸ¥æ˜¯å¦æœ‰äº¤é›†ï¼ˆç»Ÿä¸€ä¸ºå­—ç¬¦ä¸²æ¯”è¾ƒï¼‰
                if any(str(page) in selected_pages_set for page in item_pages):
                    selected_content.append({
                        "title": item.get("title", ""),
                        "pages": item_pages,
                        "content": item.get("content", "")
                    })

            if not selected_content:
                # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œä½¿ç”¨æ‰€æœ‰å†…å®¹
                logger.warning("âš ï¸ [Format] æ²¡æœ‰åŒ¹é…çš„é¡µç ï¼Œä½¿ç”¨æ‰€æœ‰å†…å®¹")
                selected_content = formatted_data

            # æ­¥éª¤3ï¼šæ„å»ºæœ€ç»ˆæ€»ç»“æç¤º
            selected_items_text = ""
            for idx, item in enumerate(selected_content, 1):
                pages_str = ", ".join(map(str, item.get("pages", []))) if item.get("pages") else "æœªçŸ¥"
                selected_items_text += f"\n\nã€åŸæ–‡ {idx}ã€‘\n"
                selected_items_text += f"æ¥æºç« èŠ‚: {item.get('title', 'æœªçŸ¥')}\n"
                selected_items_text += f"é¡µç : {pages_str}\n"
                selected_items_text += f"å†…å®¹:\n{item.get('content', '')}\n"

            final_summary_prompt = f"""
# ç²¾å‡†å›ç­”ç”Ÿæˆä»»åŠ¡

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

å·²é€‰å®šçš„åŸæ–‡å†…å®¹ï¼ˆ{len(selected_content)} æ¡ï¼‰ï¼š
{selected_items_text}

# ç”Ÿæˆè¦æ±‚

åŸºäºä»¥ä¸ŠåŸæ–‡ï¼Œç”Ÿæˆç²¾å‡†çš„æœ€ç»ˆå›ç­”ï¼š

1. **ç›´æ¥å›ç­”**ï¼šé¦–å…ˆç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
2. **å¼•ç”¨åŸæ–‡**ï¼šä¿ç•™åŸæ–‡ä¸­çš„å…³é”®ä¿¡æ¯ã€æ•°æ®ã€å›¾è¡¨æè¿°ã€å…¬å¼ç­‰
3. **æ ‡æ³¨æ¥æº**ï¼šæ˜ç¡®æ ‡æ³¨ä¿¡æ¯æ¥è‡ªå“ªäº›ç« èŠ‚å’Œé¡µç 
4. **ä¿ç•™ç»†èŠ‚**ï¼šé‡è¦çš„æ•°æ®ã€æ­¥éª¤ã€ç»“è®ºä¸è¦çœç•¥æˆ–æ”¹å†™
5. **ä¿ç•™å’Œé—®é¢˜ç›¸å…³çš„ä¿¡æ¯**ï¼šç¡®ä¿ç­”æ¡ˆä¸­åŒ…å«ä¸ç”¨æˆ·é—®é¢˜ç›´æ¥ç›¸å…³çš„æ‰€æœ‰ä¿¡æ¯ï¼Œé¿å…é—æ¼å…³é”®å†…å®¹ã€‚å…¶ä»–ä¸ç›¸å…³çš„ä¿¡æ¯å¯ä»¥çœç•¥ã€‚

# æ¨èæ ¼å¼

## æ ¸å¿ƒå›ç­”

[ç®€æ˜æ‰¼è¦åœ°å›ç­”ç”¨æˆ·é—®é¢˜]

## è¯¦ç»†è¯´æ˜

### ç« èŠ‚åç§°ï¼ˆé¡µç èŒƒå›´ï¼‰

[è¯¥éƒ¨åˆ†çš„è¯¦ç»†å†…å®¹ï¼Œä¿ç•™åŸæ–‡å…³é”®ä¿¡æ¯]

### ç« èŠ‚åç§°ï¼ˆé¡µç èŒƒå›´ï¼‰

[è¯¥éƒ¨åˆ†çš„è¯¦ç»†å†…å®¹ï¼Œä¿ç•™åŸæ–‡å…³é”®ä¿¡æ¯]

è¯·ä½¿ç”¨ä¸“ä¸šã€å‡†ç¡®çš„è¯­è¨€ï¼Œç¡®ä¿ç­”æ¡ˆçš„å®Œæ•´æ€§å’Œå¯é æ€§ã€‚
"""

            # ä½¿ç”¨ LLM ç”Ÿæˆæœ€ç»ˆæ€»ç»“
            final_summary = await self.llm.async_call_llm_chain(
                role=RetrievalRole.CONTEXT_SUMMARIZER,
                input_prompt=final_summary_prompt,
                session_id=session_id,
                #session_id="final_summary_" + state.get('doc_name', 'default')
            )

            logger.info(f"âœ… [Format] æœ€ç»ˆæ€»ç»“å®Œæˆï¼Œé•¿åº¦: {len(final_summary)} å­—ç¬¦")
            logger.info(f"âœ… [Format] é€‰æ‹©é¡µç : {selected_pages}")

            # ä¿å­˜ç»“æœ
            state["final_summary"] = final_summary
            state["selected_pages"] = selected_pages

            return state

        except Exception as e:
            logger.error(f"âŒ [Format] æœ€ç»ˆæ€»ç»“å¤±è´¥: {e}", exc_info=True)

            # å¤±è´¥æ—¶ä½¿ç”¨ä¸­é—´æ€»ç»“ä½œä¸ºæœ€ç»ˆæ€»ç»“
            intermediate_summary = state.get("intermediate_summary", "")
            fallback_summary = f"## æ£€ç´¢ç»“æœ\n\n{intermediate_summary}\n\n---\n\næ³¨ï¼šæœ€ç»ˆæ ¼å¼åŒ–å¤±è´¥ï¼Œä»¥ä¸Šä¸ºä¸­é—´æ€»ç»“ç»“æœã€‚"

            state["final_summary"] = fallback_summary
            state["selected_pages"] = []

            return state

