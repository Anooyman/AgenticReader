"""
RetrievalAgent WorkflowèŠ‚ç‚¹æ–¹æ³•

æ‰€æœ‰workflowèŠ‚ç‚¹çš„å®ç°
"""

from __future__ import annotations
from typing import Dict, TYPE_CHECKING
import logging
import json
import re

from .state import RetrievalState
from .prompts import RetrievalRole
from .tools_config import format_all_tools_for_llm, get_tool_by_name
from src.config.constants import ProcessingLimits

if TYPE_CHECKING:
    from .agent import RetrievalAgent

logger = logging.getLogger(__name__)


class RetrievalNodes:
    """RetrievalAgent WorkflowèŠ‚ç‚¹æ–¹æ³•é›†åˆ"""

    def __init__(self, agent: 'RetrievalAgent'):
        """
        Args:
            agent: RetrievalAgentå®ä¾‹ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
        """
        self.agent = agent

    def _doc_tag(self) -> str:
        """
        è·å–æ–‡æ¡£æ ‡è¯†ï¼ˆç”¨äºæ—¥å¿—å‰ç¼€ï¼Œä¾¿äºå¹¶è¡Œåœºæ™¯ä¸‹åŒºåˆ†ï¼‰

        Returns:
            æ–‡æ¡£åæ ‡ç­¾ï¼Œå¦‚ "doc.pdf" æˆ– "MultiDoc"
        """
        return self.agent.current_doc or "MultiDoc"

    def _save_persistent_state(self, state: RetrievalState):
        """
        ä¿å­˜çŠ¶æ€ä¾›ä¸‹ä¸€è½®æ£€ç´¢ä½¿ç”¨ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        ä¿å­˜çš„å­—æ®µï¼š
        - thoughts: æ€è€ƒè¿‡ç¨‹ï¼ˆç´¯ç§¯ï¼‰
        - actions: åŠ¨ä½œå†å²ï¼ˆç´¯ç§¯ï¼‰
        - observations: è§‚å¯Ÿç»“æœï¼ˆç´¯ç§¯ï¼‰
        - retrieved_content: æ£€ç´¢å†…å®¹ï¼ˆç´¯ç§¯ï¼‰
        - formatted_data: æ ¼å¼åŒ–æ•°æ®ï¼ˆç´¯ç§¯ï¼‰
        - intermediate_summary: ä¸­é—´æ€»ç»“ï¼ˆç”¨äº query rewriteï¼‰
        """
        self.agent.persistent_state = {}

        # ä¿å­˜ ReAct å†å²ï¼ˆç´¯ç§¯ï¼‰
        if "thoughts" in state and state["thoughts"]:
            self.agent.persistent_state["thoughts"] = state["thoughts"].copy()
            logger.info(f"ğŸ’¾ [{self._doc_tag()}] ä¿å­˜ thoughts: {len(state['thoughts'])} æ¡")

        if "actions" in state and state["actions"]:
            self.agent.persistent_state["actions"] = state["actions"].copy()
            logger.info(f"ğŸ’¾ [{self._doc_tag()}] ä¿å­˜ actions: {len(state['actions'])} ä¸ª")

        if "observations" in state and state["observations"]:
            self.agent.persistent_state["observations"] = state["observations"].copy()
            logger.info(f"ğŸ’¾ [{self._doc_tag()}] ä¿å­˜ observations: {len(state['observations'])} æ¡")

        # ä¿å­˜æ£€ç´¢å†…å®¹ï¼ˆç´¯ç§¯ï¼‰
        if "retrieved_content" in state and state["retrieved_content"]:
            self.agent.persistent_state["retrieved_content"] = state["retrieved_content"].copy()
            logger.info(f"ğŸ’¾ [{self._doc_tag()}] ä¿å­˜ retrieved_content: {len(state['retrieved_content'])} ä¸ª")

        if "formatted_data" in state and state["formatted_data"]:
            self.agent.persistent_state["formatted_data"] = state["formatted_data"].copy()
            logger.info(f"ğŸ’¾ [{self._doc_tag()}] ä¿å­˜ formatted_data: {len(state['formatted_data'])} ä¸ª")

        # ä¿å­˜ä¸­é—´æ€»ç»“ï¼ˆç”¨äº query rewriteï¼‰
        if "intermediate_summary" in state and state["intermediate_summary"]:
            self.agent.persistent_state["intermediate_summary"] = state["intermediate_summary"]
            logger.info(f"ğŸ’¾ [{self._doc_tag()}] ä¿å­˜ intermediate_summary: {len(state['intermediate_summary'])} å­—ç¬¦")

    async def initialize(self, state: RetrievalState) -> Dict:
        """åˆå§‹åŒ–èŠ‚ç‚¹ï¼šè®¾ç½®Agentçš„ä¸Šä¸‹æ–‡ç¯å¢ƒ"""
        logger.info(f"ğŸ”§ [Initialize|{self._doc_tag()}] ========== RetrievalAgent åˆå§‹åŒ– ==========")

        try:
            # éªŒè¯state
            self.agent.utils.validate_state(state)

            # ä»stateä¸­è¯»å–å¹¶è®¾ç½®æ–‡æ¡£ä¸Šä¸‹æ–‡
            doc_name_from_state = state.get('doc_name')
            self.agent.current_doc = doc_name_from_state or self.agent.current_doc

            logger.info(f"ğŸ”§ [Initialize|{self._doc_tag()}] é…ç½®ä¿¡æ¯:")
            logger.info(f"ğŸ”§ [Initialize|{self._doc_tag()}]   - æ–‡æ¡£åç§°: {self.agent.current_doc or 'å¤šæ–‡æ¡£æ¨¡å¼'}")
            logger.info(f"ğŸ”§ [Initialize|{self._doc_tag()}]   - æŸ¥è¯¢å†…å®¹: {state['query']}")
            logger.info(f"ğŸ”§ [Initialize|{self._doc_tag()}]   - æœ€å¤§è¿­ä»£: {state['max_iterations']}")

            # åˆ›å»ºæˆ–æ›´æ–° VectorDBClient
            if self.agent.current_doc:
                if self.agent.vector_db_client is None:
                    self.agent.vector_db_client = self.agent.utils.create_vector_db_client(self.agent.current_doc)
                    logger.info(f"âœ… [Initialize|{self._doc_tag()}] VectorDBClient å·²åˆ›å»ºå¹¶åŠ è½½")
                elif doc_name_from_state and doc_name_from_state != self.agent.current_doc:
                    logger.info(f"ğŸ”„ [Initialize|{self._doc_tag()}] æ–‡æ¡£åç§°å˜åŒ–ï¼Œé‡æ–°åˆ›å»ºVectorDBClient")
                    self.agent.vector_db_client = self.agent.utils.create_vector_db_client(doc_name_from_state)
                    self.agent.current_doc = doc_name_from_state

            # ============ çŠ¶æ€æŒä¹…åŒ–ï¼šæ¢å¤ä¹‹å‰çš„æ£€ç´¢å†å² ============
            if self.agent.persistent_state:
                logger.info(f"ğŸ”„ [Initialize|{self._doc_tag()}] æ£€æµ‹åˆ°æŒä¹…åŒ–çŠ¶æ€ï¼Œæ¢å¤å†å²ä¿¡æ¯:")

                # è·å–å†å²é•¿åº¦é™åˆ¶ï¼ˆé¿å…ä¸Šä¸‹æ–‡æ— é™å¢é•¿ï¼‰
                max_history = ProcessingLimits.MAX_PERSISTENT_HISTORY_LENGTH

                # æ¢å¤ ReAct å†å²ï¼ˆåªä¿ç•™æœ€è¿‘çš„ N æ¡ï¼‰
                if "thoughts" in self.agent.persistent_state:
                    full_thoughts = self.agent.persistent_state["thoughts"]
                    state["thoughts"] = full_thoughts[-max_history:].copy() if len(full_thoughts) > max_history else full_thoughts.copy()
                    if len(full_thoughts) > max_history:
                        logger.info(f"   - thoughts: {len(full_thoughts)} æ¡ â†’ è£å‰ªè‡³æœ€è¿‘ {len(state['thoughts'])} æ¡")
                    else:
                        logger.info(f"   - thoughts: {len(state['thoughts'])} æ¡")

                if "actions" in self.agent.persistent_state:
                    full_actions = self.agent.persistent_state["actions"]
                    state["actions"] = full_actions[-max_history:].copy() if len(full_actions) > max_history else full_actions.copy()
                    if len(full_actions) > max_history:
                        logger.info(f"   - actions: {len(full_actions)} ä¸ª â†’ è£å‰ªè‡³æœ€è¿‘ {len(state['actions'])} ä¸ª")
                    else:
                        logger.info(f"   - actions: {len(state['actions'])} ä¸ª")

                if "observations" in self.agent.persistent_state:
                    full_observations = self.agent.persistent_state["observations"]
                    state["observations"] = full_observations[-max_history:].copy() if len(full_observations) > max_history else full_observations.copy()
                    if len(full_observations) > max_history:
                        logger.info(f"   - observations: {len(full_observations)} æ¡ â†’ è£å‰ªè‡³æœ€è¿‘ {len(state['observations'])} æ¡")
                    else:
                        logger.info(f"   - observations: {len(state['observations'])} æ¡")

                # æ¢å¤æ£€ç´¢å†…å®¹ï¼ˆåªä¿ç•™æœ€è¿‘çš„ N ä¸ªï¼‰
                if "retrieved_content" in self.agent.persistent_state:
                    full_content = self.agent.persistent_state["retrieved_content"]
                    state["retrieved_content"] = full_content[-max_history:].copy() if len(full_content) > max_history else full_content.copy()
                    if len(full_content) > max_history:
                        logger.info(f"   - retrieved_content: {len(full_content)} ä¸ª â†’ è£å‰ªè‡³æœ€è¿‘ {len(state['retrieved_content'])} ä¸ª")
                    else:
                        logger.info(f"   - retrieved_content: {len(state['retrieved_content'])} ä¸ª")

                if "formatted_data" in self.agent.persistent_state:
                    full_data = self.agent.persistent_state["formatted_data"]
                    state["formatted_data"] = full_data[-max_history:].copy() if len(full_data) > max_history else full_data.copy()
                    if len(full_data) > max_history:
                        logger.info(f"   - formatted_data: {len(full_data)} ä¸ª â†’ è£å‰ªè‡³æœ€è¿‘ {len(state['formatted_data'])} ä¸ª")
                    else:
                        logger.info(f"   - formatted_data: {len(state['formatted_data'])} ä¸ª")

                # æ¢å¤ä¸­é—´æ€»ç»“ï¼ˆç”¨äº query rewriteï¼‰
                if "intermediate_summary" in self.agent.persistent_state:
                    state["intermediate_summary"] = self.agent.persistent_state["intermediate_summary"]
                    logger.info(f"   - intermediate_summary: {len(state.get('intermediate_summary', ''))} å­—ç¬¦")

            # åˆå§‹åŒ–stateå­—æ®µï¼ˆå¦‚æœæ²¡æœ‰æŒä¹…åŒ–çŠ¶æ€ï¼‰
            for field in ['retrieved_content', 'formatted_data', 'thoughts', 'actions', 'observations']:
                if field not in state:
                    state[field] = []
            if 'current_iteration' not in state:
                state['current_iteration'] = 0

            logger.info(f"âœ… [Initialize|{self._doc_tag()}] åˆå§‹åŒ–å®Œæˆ")
            return state

        except Exception as e:
            logger.error(f"âŒ [Initialize|{self._doc_tag()}] åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            raise

    async def rewrite(self, state: RetrievalState) -> Dict:
        """æŸ¥è¯¢é‡å†™èŠ‚ç‚¹"""

        conversation_turn = state.get("conversation_turn", 0)
        current_iteration = state.get("current_iteration", 0)
        intermediate_summary = state.get("intermediate_summary", "")
        original_query = state["query"]

        logger.info(f"ğŸ”„ [Rewrite|{self._doc_tag()}] ========== æ­¥éª¤0: æŸ¥è¯¢é‡å†™ ==========")
        logger.info(f"ğŸ”„ [Rewrite|{self._doc_tag()}] å¯¹è¯è½®æ¬¡: {conversation_turn}")
        logger.info(f"ğŸ”„ [Rewrite|{self._doc_tag()}] å†…éƒ¨è¿­ä»£: {current_iteration}")
        logger.info(f"ğŸ”„ [Rewrite|{self._doc_tag()}] åŸå§‹æŸ¥è¯¢: {original_query}")

        try:
            # åªæœ‰å¤–éƒ¨å¯¹è¯è½®æ¬¡å’Œå†…éƒ¨è¿­ä»£æ¬¡æ•°éƒ½ä¸º0æ—¶ï¼Œæ‰è·³è¿‡é‡å†™
            # å…¶ä»–æƒ…å†µï¼ˆå¤–éƒ¨éé¦–è½® æˆ– å†…éƒ¨éé¦–æ¬¡ï¼‰éƒ½éœ€è¦é‡å†™
            if conversation_turn == 0 and current_iteration == 0:
                logger.info(f"ğŸ”„ [Rewrite|{self._doc_tag()}] åˆ¤æ–­: å¤–éƒ¨é¦–è½®å¯¹è¯ä¸”å†…éƒ¨é¦–æ¬¡è¿­ä»£ï¼Œè·³è¿‡æŸ¥è¯¢é‡å†™")
                state["rewritten_query"] = original_query
                logger.info(f"âœ… [Rewrite|{self._doc_tag()}] è¾“å‡ºæŸ¥è¯¢: {original_query}")
                return state

            logger.info(f"ğŸ”„ [Rewrite|{self._doc_tag()}] åˆ¤æ–­: å¤–éƒ¨éé¦–è½®({conversation_turn}) æˆ– å†…éƒ¨éé¦–æ¬¡({current_iteration})ï¼Œè¿›è¡ŒæŸ¥è¯¢ä¼˜åŒ–")

            # è·å–ä¸Šä¸€è½® evaluate èŠ‚ç‚¹çš„è¯„ä¼°ï¼ˆåŒ…å«å»ºè®®ï¼‰
            last_reason = state.get("reason", "")
            
            # æ„å»ºprompt
            if last_reason and current_iteration > 0:
                # å¦‚æœæœ‰ä¸Šä¸€è½®çš„è¯„ä¼°ï¼ŒåŸºäºè¯„ä¼°é‡å†™æŸ¥è¯¢
                logger.info(f"ğŸ”„ [Rewrite|{self._doc_tag()}] ä½¿ç”¨ä¸Šä¸€è½®è¯„ä¼°: {last_reason[:100]}...")
                input_prompt = f"""åŸå§‹æŸ¥è¯¢: {original_query}

ä¸Šä¸€è½®æ£€ç´¢è¯„ä¼°: {last_reason}

ä»»åŠ¡: åŸºäºè¯„ä¼°ä¸­çš„å»ºè®®ï¼Œä¼˜åŒ–æŸ¥è¯¢ä»¥ä¾¿è¿›è¡Œä¸‹ä¸€è½®æ£€ç´¢ã€‚
- å¦‚æœè¯„ä¼°å»ºè®®æ£€ç´¢ç‰¹å®šç« èŠ‚ï¼Œä¿æŒåŸæŸ¥è¯¢ä¸å˜ï¼ˆå·¥å…·é€‰æ‹©ä¼šå¤„ç†ï¼‰
- å¦‚æœè¯„ä¼°å»ºè®®æ›´æ¢å…³é”®è¯ï¼Œæå–å»ºè®®çš„å…³é”®è¯
- å¦‚æœè¯„ä¼°å»ºè®®åˆ‡æ¢ç­–ç•¥ï¼Œè°ƒæ•´æŸ¥è¯¢ä»¥é€‚åº”æ–°ç­–ç•¥

åªè¿”å›ä¼˜åŒ–åçš„æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œä¸è¦è§£é‡Šã€‚"""
            else:
                # æ²¡æœ‰è¯„ä¼°æˆ–é¦–æ¬¡æ£€ç´¢ï¼Œä½¿ç”¨é€šç”¨ä¼˜åŒ–
                input_prompt = f"åŸå§‹æŸ¥è¯¢: {original_query}\nä¼˜åŒ–è¯¥æŸ¥è¯¢"
            
            #session_id = f"rewrite_{state.get('doc_name', 'default')}"
            rewritten = await self.agent.llm.async_call_llm_chain(
                role=RetrievalRole.QUERY_REWRITE,
                input_prompt=input_prompt,
                session_id="rewrite_query"
            )

            rewritten_clean = rewritten.strip().strip('"').strip("'").strip()
            state["rewritten_query"] = rewritten_clean
            logger.info(f"âœ… [Rewrite|{self._doc_tag()}] é‡å†™åæŸ¥è¯¢: {rewritten_clean}")
            return state

        except Exception as e:
            logger.error(f"âŒ [Rewrite|{self._doc_tag()}] å¤±è´¥: {e}", exc_info=True)
            state["rewritten_query"] = original_query
            logger.info(f"âš ï¸  [Rewrite|{self._doc_tag()}] å›é€€åˆ°åŸå§‹æŸ¥è¯¢: {original_query}")
            return state

    async def think(self, state: RetrievalState) -> Dict:
        """æ€è€ƒèŠ‚ç‚¹ï¼šé€‰æ‹©å·¥å…·"""

        current_iteration = state.get("current_iteration", 0)
        logger.info(f"ğŸ¤” [Think|{self._doc_tag()}] ========== æ­¥éª¤1: æ€è€ƒå·¥å…·é€‰æ‹© ==========")
        logger.info(f"ğŸ¤” [Think|{self._doc_tag()}] è¿­ä»£è¿›åº¦: ç¬¬ {current_iteration + 1}/{state['max_iterations']} è½®")

        try:
            tools_description = format_all_tools_for_llm()
            current_query = state.get("rewritten_query", state["query"])
            original_query = state["query"]
            last_reason = state.get("reason", "")

            logger.info(f"ğŸ¤” [Think|{self._doc_tag()}] è¾“å…¥:")
            logger.info(f"ğŸ¤” [Think|{self._doc_tag()}]   - åŸå§‹æŸ¥è¯¢: {original_query}")
            logger.info(f"ğŸ¤” [Think|{self._doc_tag()}]   - å½“å‰æŸ¥è¯¢: {current_query}")

            # æ„å»ºå†å²æ‰§è¡Œä¿¡æ¯ï¼ˆä¸é’ˆå¯¹ä»»ä½•ç‰¹å®šå·¥å…·åšè§£æï¼‰
            actions_history = state.get("actions", [])
            observations = state.get("observations", [])
            retrieved_content = state.get("retrieved_content", [])

            executed_tools = [action.get("tool", "") for action in actions_history]

            logger.info(f"ğŸ¤” [Think|{self._doc_tag()}] ä¸Šä¸‹æ–‡:")
            logger.info(f"ğŸ¤” [Think|{self._doc_tag()}]   - å·²æ‰§è¡Œå·¥å…·æ•°: {len(actions_history)}")
            logger.info(f"ğŸ¤” [Think|{self._doc_tag()}]   - å·²æ£€ç´¢å†…å®¹æ•°: {len(retrieved_content)}")

            # ç»Ÿä¸€çš„å†å² JSONï¼ˆåŸºäº tool_response_format ä¸­çš„å­—æ®µï¼‰
            history_data = []
            for idx, (action, observation) in enumerate(zip(actions_history, observations), 1):
                history_data.append({
                    "round": idx,
                    "tool": action.get("tool", "unknown"),
                    "params": action.get("params", {}),
                    "observation": observation
                })

            history_json = json.dumps(history_data, ensure_ascii=False, indent=2)

            # ç»Ÿä¸€ç»Ÿè®¡ retrieved_content ä¸­å„ç±»å‹çš„æ•°é‡ï¼ˆç¬¦åˆ ToolResponse.typeï¼‰
            content_count = sum(1 for item in retrieved_content if isinstance(item, dict) and item.get("type") == "content")
            metadata_count = sum(1 for item in retrieved_content if isinstance(item, dict) and item.get("type") == "metadata")
            structure_count = sum(1 for item in retrieved_content if isinstance(item, dict) and item.get("type") == "structure")
            unknown_count = len(retrieved_content) - (content_count + metadata_count + structure_count)

            if actions_history:
                history_info = f"""## æ£€ç´¢å†å²ï¼ˆJSON æ ¼å¼ï¼‰

```json
{history_json}
```

## å½“å‰ç´¯ç§¯å†…å®¹ç»Ÿè®¡
- å†…å®¹(content): {content_count} æ¡
- å…ƒæ•°æ®(metadata): {metadata_count} æ¡
- ç»“æ„(structure): {structure_count} æ¡
- æœªçŸ¥ç±»å‹: {unknown_count} æ¡
- æ€»è®¡: {len(retrieved_content)} æ¡
"""
            else:
                history_info = "## é¦–æ¬¡æ£€ç´¢\næš‚æ— å†å²æ‰§è¡Œè®°å½•ã€‚"

            reason_info = f"\n## ä¸Šä¸€è½®è¯„ä¼°ç†ç”±\n{last_reason}\n" if last_reason else ""

            # æ„å»ºç®€æ´çš„ promptï¼ˆå®Œå…¨ä¾èµ–å·¥å…·æè¿°å’Œç»Ÿä¸€æ ¼å¼ï¼Œä¸åšå·¥å…·ç‰¹å®šå¤„ç†ï¼‰
            prompt = f"""# å½“å‰ä»»åŠ¡ä¿¡æ¯

**ç”¨æˆ·åŸå§‹æŸ¥è¯¢**: {original_query}
**å½“å‰ä¼˜åŒ–æŸ¥è¯¢**: {current_query}
**è¿­ä»£è¿›åº¦**: ç¬¬ {current_iteration + 1}/{state['max_iterations']} è½®

{history_info}
{reason_info}

# è¯·é€‰æ‹©ä¸‹ä¸€æ­¥å·¥å…·

è¯·åŸºäºæ£€ç´¢å†å²å’Œå½“å‰ç»Ÿè®¡ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ç»§ç»­æ£€ç´¢ã€‚ä¸¥æ ¼éµå¾ªå·¥å…·æè¿°ä¸­çš„å‚æ•°æ ¼å¼ã€‚
**é‡è¦æç¤º**:
- é¿å…é‡å¤å®Œå…¨ç›¸åŒçš„å·¥å…·+å‚æ•°ç»„åˆ
- å¦‚æœ observation æ˜¾ç¤ºæœªæ‰¾åˆ°æˆ–é‡å¤ï¼Œè€ƒè™‘æ›´æ¢ç­–ç•¥æˆ–å‚æ•°
- action_input å¿…é¡»ç¬¦åˆå·¥å…·çš„å‚æ•°è§„èŒƒï¼ˆä¾‹å¦‚éœ€è¦æ•°ç»„çš„å·¥å…·ä¼ æ•°ç»„ï¼‰

è¿”å›ä¸¥æ ¼çš„ JSON æ ¼å¼ï¼š
{{
  "thought": "ä½ çš„æ€è€ƒè¿‡ç¨‹",
  "action": "å·¥å…·åç§°",
  "action_input": "å·¥å…·å‚æ•°"
}}
"""

            logger.info(f"ğŸ¤” [Think|{self._doc_tag()}] è°ƒç”¨ LLM è¿›è¡Œå·¥å…·é€‰æ‹©...")
            session_id = f"think_{state.get('doc_name', 'default')}"
            response = await self.agent.llm.async_call_llm_chain(
                role=RetrievalRole.RETRIEVAL,
                input_prompt=prompt,
                session_id=session_id,
                system_format_dict={"tool_info_dict": tools_description}
            )

            # è§£æJSON
            logger.info(f"ğŸ¤” [Think|{self._doc_tag()}] LLM å“åº”: {response[:200]}...")
            decision = json.loads(response.strip()) if response.strip().startswith('{') else None
            if decision:
                thought = decision.get("thought", "")
                action = decision.get("action", "search_by_context")
                action_input = decision.get("action_input", current_query)

                logger.info(f"ğŸ¤” [Think|{self._doc_tag()}] å†³ç­–ç»“æœ:")
                logger.info(f"ğŸ¤” [Think|{self._doc_tag()}]   - æ€è€ƒ: {thought}")
                logger.info(f"ğŸ¤” [Think|{self._doc_tag()}]   - é€‰æ‹©å·¥å…·: {action}")
                logger.info(f"ğŸ¤” [Think|{self._doc_tag()}]   - å·¥å…·å‚æ•°: {action_input}")
            else:
                logger.warning(f"âš ï¸  [Think|{self._doc_tag()}] JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·")
                action = "search_by_context"
                action_input = current_query
                logger.info(f"ğŸ¤” [Think|{self._doc_tag()}]   - é»˜è®¤å·¥å…·: {action}")
                logger.info(f"ğŸ¤” [Think|{self._doc_tag()}]   - é»˜è®¤å‚æ•°: {action_input}")

            state["current_tool"] = action
            state["action_input"] = action_input

            # è®°å½•å‚æ•°ï¼ˆç»Ÿä¸€ä»å·¥å…·é…ç½®ä¸­æ¨æ–­é¦–ä¸ªå‚æ•°åï¼Œé¿å…é’ˆå¯¹å…·ä½“å·¥å…·çš„ç¡¬ç¼–ç ï¼‰
            tool_config = get_tool_by_name(action)
            if tool_config:
                params_spec = tool_config.get("parameters", {})
                if params_spec:
                    param_name = list(params_spec.keys())[0]
                    current_params = {param_name: action_input}
                else:
                    current_params = {}
            else:
                current_params = {"query": action_input}

            state["current_params"] = current_params
            logger.info(f"ğŸ¤” [Think|{self._doc_tag()}]   - è®°å½•å‚æ•°: {current_params}")

            state["current_iteration"] = current_iteration + 1

            # å®‰å…¨åœ°æ˜¾ç¤ºå‚æ•°ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            if isinstance(action_input, str):
                param_preview = action_input[:50] + "..." if len(action_input) > 50 else action_input
            elif isinstance(action_input, list):
                param_preview = str(action_input)[:100] + "..." if len(str(action_input)) > 100 else str(action_input)
            else:
                param_preview = str(action_input)

            logger.info(f"âœ… [Think|{self._doc_tag()}] è¾“å‡º: å·¥å…·={action}, å‚æ•°ç±»å‹={type(action_input).__name__}, å‚æ•°={param_preview}")
            return state

        except Exception as e:
            logger.error(f"âŒ [Think|{self._doc_tag()}] å¤±è´¥: {e}", exc_info=True)
            state["current_tool"] = "search_by_context"
            state["action_input"] = state.get("rewritten_query", state["query"])
            state["current_iteration"] = current_iteration + 1
            logger.info(f"âš ï¸  [Think|{self._doc_tag()}] é”™è¯¯å›é€€: ä½¿ç”¨ search_by_context")
            return state

    async def act(self, state: RetrievalState) -> Dict:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""

        tool_name = state["current_tool"]
        action_input = state.get("action_input", state.get("rewritten_query", state["query"]))

        logger.info(f"ğŸ”§ [Act|{self._doc_tag()}] ========== æ­¥éª¤2: æ‰§è¡Œå·¥å…· ==========")
        logger.info(f"ğŸ”§ [Act|{self._doc_tag()}] å·¥å…·åç§°: {tool_name}")
        logger.info(f"ğŸ”§ [Act|{self._doc_tag()}] å·¥å…·å‚æ•°: {action_input}")

        try:
            # æ„å»ºå¯ç”¨å·¥å…·
            available_tools = self.agent.utils.build_retrieval_tools()
            logger.info(f"ğŸ”§ [Act|{self._doc_tag()}] å¯ç”¨å·¥å…·åˆ—è¡¨: {list(available_tools.keys())}")

            if tool_name in available_tools:
                logger.info(f"ğŸ”§ [Act|{self._doc_tag()}] è°ƒç”¨å·¥å…·: {tool_name}")
                tool_func = available_tools[tool_name]["function"]

                # è°ƒç”¨å·¥å…·ï¼ˆä¼ å…¥action_inputï¼‰
                result = await tool_func(action_input)
            else:
                logger.warning(f"âš ï¸  [Act|{self._doc_tag()}] å·¥å…· '{tool_name}' ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·")
                result = await self.agent.tools.search_by_context(action_input)

            # ç»Ÿè®¡ç»“æœï¼ˆåŸºäºæ ‡å‡†æ ¼å¼ï¼‰
            if isinstance(result, dict) and "type" in result and "items" in result:
                # æ ‡å‡†æ ¼å¼å“åº”
                tool_type = result["type"]
                items = result["items"]
                metadata = result.get("metadata", {})
                result_count = len(items)

                logger.info(f"ğŸ”§ [Act|{self._doc_tag()}] å·¥å…·æ‰§è¡Œå®Œæˆï¼Œè¿”å› {result_count} é¡¹ (type={tool_type})")

                if tool_type == "content" and result_count > 0:
                    # å†…å®¹æ£€ç´¢å·¥å…·ï¼šæ˜¾ç¤ºç« èŠ‚ä¿¡æ¯
                    logger.info(f"ğŸ”§ [Act|{self._doc_tag()}]   æ£€ç´¢åˆ°çš„å†…å®¹:")
                    for idx, item in enumerate(items[:3], 1):
                        if isinstance(item, dict):
                            title = item.get("title", "æ— æ ‡é¢˜")
                            pages = item.get("pages", [])
                            content_preview = item.get("content", "")[:50] + "..." if item.get("content", "") else ""
                            logger.info(f"ğŸ”§ [Act|{self._doc_tag()}]     {idx}. ç« èŠ‚: {title} (é¡µç : {pages})")
                            logger.info(f"ğŸ”§ [Act|{self._doc_tag()}]        å†…å®¹é¢„è§ˆ: {content_preview}")
                    if len(items) > 3:
                        logger.info(f"ğŸ”§ [Act|{self._doc_tag()}]     ... (è¿˜æœ‰ {len(items) - 3} æ¡)")

                elif tool_type in ["metadata", "structure"] and result_count > 0:
                    # ç»“æ„åŒ–å·¥å…·ï¼šæ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                    preview_items = items[:5] if len(items) > 5 else items
                    logger.info(f"ğŸ”§ [Act|{self._doc_tag()}]   æ•°æ®é¢„è§ˆï¼ˆå‰{len(preview_items)}é¡¹ï¼‰:")
                    for idx, item in enumerate(preview_items, 1):
                        logger.info(f"ğŸ”§ [Act|{self._doc_tag()}]     {idx}. {item}")
                    if len(items) > 5:
                        logger.info(f"ğŸ”§ [Act|{self._doc_tag()}]     ... (è¿˜æœ‰ {len(items) - 5} é¡¹)")

                    # å¦‚æœæœ‰metadataï¼ˆå¦‚reasonï¼‰ï¼Œä¹Ÿæ‰“å°
                    if metadata:
                        logger.info(f"ğŸ”§ [Act|{self._doc_tag()}]   å…ƒæ•°æ®: {metadata}")
            else:
                # éæ ‡å‡†æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                result_count = 0
                logger.warning(f"âš ï¸  [Act|{self._doc_tag()}] å·¥å…·è¿”å›éæ ‡å‡†æ ¼å¼ï¼Œç±»å‹: {type(result)}")

            state["last_result"] = result

            # è®°å½•actionï¼ˆåŒ…å«toolå’Œparamsï¼‰
            current_params = state.get("current_params", {})
            state["actions"] = state.get("actions", []) + [{"tool": tool_name, "params": current_params}]

            logger.info(f"âœ… [Act|{self._doc_tag()}] è¾“å‡º: {result_count} æ¡ç»“æœ")
            return state

        except Exception as e:
            logger.error(f"âŒ [Act|{self._doc_tag()}] å¤±è´¥: {e}", exc_info=True)
            state["last_result"] = []
            logger.info(f"âš ï¸  [Act|{self._doc_tag()}] é”™è¯¯å›é€€: è¿”å›ç©ºç»“æœ")
            return state

    async def summary(self, state: RetrievalState) -> Dict:
        """ç´¯ç§¯å¹¶æ€»ç»“æ•°æ®ï¼ˆå§‹ç»ˆç´¯ç§¯ï¼ŒæŒ‰éœ€æ€»ç»“ï¼‰"""

        logger.info(f"ğŸ“ [Summary|{self._doc_tag()}] ========== æ­¥éª¤3: ç´¯ç§¯å¹¶æ€»ç»“æ•°æ® ==========")

        try:
            last_result = state.get("last_result", [])
            retrieved_content = state.get("retrieved_content", [])

            logger.info(f"ğŸ“ [Summary|{self._doc_tag()}] è¾“å…¥:")
            logger.info(f"ğŸ“ [Summary|{self._doc_tag()}]   - æœ¬è½®ç»“æœæ•°: {len(last_result) if isinstance(last_result, list) else 0}")
            logger.info(f"ğŸ“ [Summary|{self._doc_tag()}]   - ç´¯ç§¯ç»“æœæ•°: {len(retrieved_content)}")

            # ========== ç¬¬ä¸€æ­¥ï¼šå§‹ç»ˆç´¯ç§¯æ•°æ®ï¼ˆç»Ÿä¸€çš„æ ‡å‡†æ ¼å¼å¤„ç†ï¼‰==========
            new_items = 0
            current_tool = state.get("current_tool", "unknown")

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡å‡†æ ¼å¼ï¼ˆæ‰€æœ‰å·¥å…·ç°åœ¨éƒ½è¿”å›è¿™ä¸ªæ ¼å¼ï¼‰
            if isinstance(last_result, dict) and "type" in last_result and "tool" in last_result and "items" in last_result:
                # æ ‡å‡†æ ¼å¼ï¼š{"type": "...", "tool": "...", "items": [...], "metadata": {...}}
                tool_type = last_result["type"]
                tool_name = last_result["tool"]
                items = last_result["items"]
                metadata = last_result.get("metadata", {})

                logger.info(f"ğŸ“ [Summary|{self._doc_tag()}] å¤„ç†æ ‡å‡†æ ¼å¼å“åº”: type={tool_type}, tool={tool_name}")

                if tool_type == "content":
                    # å†…å®¹ç±»å‹ï¼šitems æ˜¯ List[Dict]ï¼Œæ¯ä¸ªDictåŒ…å« content, title, pages, raw_data
                    # æå–å·²æœ‰çš„å†…å®¹ï¼ˆç”¨äºè·¨è¿­ä»£å»é‡ï¼‰
                    existing_contents = [
                        item.get("content", "")
                        for item in retrieved_content
                        if isinstance(item, dict) and item.get("type") != "structured_info"
                    ]

                    for item in items:
                        if isinstance(item, dict):
                            item_content = item.get("content", "")
                            # æ£€æŸ¥æ˜¯å¦é‡å¤ï¼ˆè·¨è¿­ä»£å»é‡ï¼‰
                            if item_content and item_content not in existing_contents:
                                retrieved_content.append(item)
                                new_items += 1
                                existing_contents.append(item_content)  # æ›´æ–°å·²æœ‰å†…å®¹åˆ—è¡¨
                            # else: é‡å¤å†…å®¹ï¼Œä¸æ·»åŠ ï¼Œnew_items ä¸å¢åŠ 

                    logger.info(f"ğŸ“ [Summary|{self._doc_tag()}] å·¥å…·è¿”å› {len(items)} æ¡ï¼Œå»é‡åæ–°å¢ {new_items} æ¡")

                elif tool_type in ["metadata", "structure"]:
                    # å…ƒæ•°æ®/ç»“æ„ç±»å‹ï¼šitems æ˜¯ List[str]ï¼Œéœ€è¦åŒ…è£…æˆ structured_info
                    structured_info = {
                        "type": "structured_info",
                        "tool": tool_name,
                        "data": items
                    }
                    # å¦‚æœæœ‰metadataï¼Œæ·»åŠ åˆ°structured_infoä¸­
                    if metadata:
                        structured_info["metadata"] = metadata

                    retrieved_content.append(structured_info)
                    new_items = 1
                    logger.info(f"ğŸ“ [Summary|{self._doc_tag()}] ç´¯ç§¯ç»“æ„åŒ–ä¿¡æ¯: {tool_name}, {len(items)} é¡¹")
                    if metadata:
                        logger.info(f"ğŸ“ [Summary|{self._doc_tag()}]   - å…ƒæ•°æ®: {metadata}")

                else:
                    logger.warning(f"âš ï¸  [Summary|{self._doc_tag()}] æœªçŸ¥çš„typeç±»å‹: {tool_type}")

            else:
                # éæ ‡å‡†æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼Œç†è®ºä¸Šä¸åº”è¯¥å‡ºç°ï¼‰
                logger.warning(f"âš ï¸  [Summary|{self._doc_tag()}] å·¥å…·è¿”å›éæ ‡å‡†æ ¼å¼ï¼Œå°è¯•å…¼å®¹å¤„ç†")
                logger.warning(f"âš ï¸  [Summary|{self._doc_tag()}] last_resultç±»å‹: {type(last_result)}")

                # ç®€å•å¤„ç†ï¼šå¦‚æœæ˜¯dictå°±æ·»åŠ ï¼Œå¦‚æœæ˜¯listå°±é€ä¸ªæ·»åŠ 
                if isinstance(last_result, dict):
                    retrieved_content.append(last_result)
                    new_items = 1
                elif isinstance(last_result, list):
                    for item in last_result:
                        if isinstance(item, dict):
                            retrieved_content.append(item)
                            new_items += 1

            state["retrieved_content"] = retrieved_content
            logger.info(f"ğŸ“ [Summary|{self._doc_tag()}] æ–°å¢ {new_items} æ¡å†…å®¹ï¼Œæ€»è®¡ {len(retrieved_content)} æ¡")

            if not retrieved_content:
                logger.warning(f"âš ï¸  [Summary|{self._doc_tag()}] æ— æ£€ç´¢å†…å®¹ï¼Œè·³è¿‡æ€»ç»“")
                state["intermediate_summary"] = "æœªæ£€ç´¢åˆ°ç›¸å…³å†…å®¹"
                return state

            # æ„å»ºæ ¼å¼åŒ–æ•°æ®
            formatted_data = []
            for idx, item in enumerate(retrieved_content, 1):
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç»“æ„åŒ–ä¿¡æ¯
                if isinstance(item, dict) and item.get("type") == "structured_info":
                    # ç»“æ„åŒ–ä¿¡æ¯ï¼ˆæ–‡æ¡£ç»“æ„æˆ–æ ‡é¢˜åˆ—è¡¨ï¼‰
                    tool_name = item.get("tool", "unknown")
                    data = item.get("data", [])
                    metadata = item.get("metadata", {})

                    formatted_item = {
                        "index": idx,
                        "type": "structured_info",
                        "tool": tool_name,
                        "data": data,
                        "title": f"[{tool_name}]",
                        "pages": [],
                        "content": "\n".join(data) if isinstance(data, list) else str(data)
                    }

                    # å¦‚æœæœ‰å…ƒæ•°æ®ï¼ˆå¦‚reasonç­‰ï¼‰ï¼Œä¹ŸåŠ å…¥
                    if metadata:
                        formatted_item["metadata"] = metadata
                        # å‘åå…¼å®¹ï¼šå¦‚æœmetadataä¸­æœ‰reasonï¼Œä¹Ÿæå–åˆ°é¡¶å±‚
                        if "reason" in metadata:
                            formatted_item["reason"] = metadata["reason"]

                    formatted_data.append(formatted_item)
                else:
                    # å¸¸è§„å†…å®¹
                    formatted_data.append({
                        "index": idx,
                        "type": "content",
                        "title": item.get("title", ""),
                        "pages": item.get("pages", []),
                        "content": item.get("content", ""),
                        "raw_data": item.get("raw_data", {})  # ä¼ é€’åŸå§‹æ•°æ®
                    })

            state["formatted_data"] = formatted_data
            logger.info(f"ğŸ“ [Summary|{self._doc_tag()}] æ ¼å¼åŒ– {len(formatted_data)} æ¡æ•°æ®")

            # è®°å½•observationï¼ˆç»Ÿä¸€åŸºäºæ ‡å‡†æ ¼å¼ï¼Œæ— éœ€hardcodeå·¥å…·åï¼‰
            if isinstance(last_result, dict) and "type" in last_result:
                # æ ‡å‡†æ ¼å¼
                tool_type = last_result["type"]
                items = last_result.get("items", [])
                tool_name = last_result.get("tool", current_tool)

                if new_items > 0:
                    # æœ‰æ–°å†…å®¹è¢«æ·»åŠ 
                    if tool_type == "content":
                        # å†…å®¹ç±»å‹ï¼šæ˜¾ç¤ºæ–°å¢æ•°é‡
                        observation = f"æ–°å¢ {new_items} ä¸ªç»“æœ"
                    elif tool_type in ["metadata", "structure"]:
                        # å…ƒæ•°æ®/ç»“æ„ç±»å‹ï¼šæ˜¾ç¤ºè·å–çš„é¡¹æ•°
                        observation = f"è·å– {len(items)} é¡¹æ•°æ®"
                    else:
                        observation = f"å®Œæˆï¼ˆtype={tool_type}ï¼‰"
                else:
                    # æ²¡æœ‰æ–°å†…å®¹ï¼ˆå¯èƒ½æ˜¯é‡å¤æˆ–æœªæ‰¾åˆ°ï¼‰
                    if tool_type == "content" and len(items) > 0:
                        # å·¥å…·è¿”å›äº†ç»“æœï¼Œä½†éƒ½æ˜¯é‡å¤çš„
                        observation = f"è¿”å› {len(items)} ä¸ªç»“æœï¼Œä½†å‡ä¸ºé‡å¤å†…å®¹"
                    else:
                        # å®Œå…¨æœªæ‰¾åˆ°
                        observation = "æœªæ‰¾åˆ°æ–°å†…å®¹"
            else:
                # éæ ‡å‡†æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                if new_items > 0:
                    observation = f"æ–°å¢ {new_items} ä¸ªç»“æœ"
                else:
                    observation = "æœªæ‰¾åˆ°æ–°å†…å®¹"

            state["observations"] = state.get("observations", []) + [observation]
            logger.info(f"ğŸ“ [Summary|{self._doc_tag()}] è®°å½•observation: {observation}")

            return state

        except Exception as e:
            logger.error(f"âŒ [Summary|{self._doc_tag()}] å¤±è´¥: {e}", exc_info=True)
            state["intermediate_summary"] = "æ€»ç»“å¤±è´¥"
            return state

    async def evaluate(self, state: RetrievalState) -> Dict:
        """è¯„ä¼°æ£€ç´¢ç»“æœ"""

        logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}] ========== æ­¥éª¤4: è¯„ä¼°æ£€ç´¢ç»“æœ ==========")

        try:
            formatted_data = state.get("formatted_data", [])
            current_iteration = state.get("current_iteration", 0)
            max_iterations = state.get("max_iterations", ProcessingLimits.MAX_RETRIEVAL_ITERATIONS)
            original_query = state["query"]
            actions = state.get("actions", [])
            observations = state.get("observations", [])

            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}] è¾“å…¥:")
            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}]   - ç”¨æˆ·æŸ¥è¯¢: {original_query}")
            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}]   - æ ¼å¼åŒ–æ•°æ®æ•°: {len(formatted_data)}")
            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}]   - å½“å‰è¿­ä»£: {current_iteration}/{max_iterations}")
            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}]   - å†å²åŠ¨ä½œæ•°: {len(actions)}")

            if not formatted_data:
                logger.warning(f"âš ï¸  [Evaluate|{self._doc_tag()}] æ— æ£€ç´¢å†…å®¹ï¼Œåˆ¤æ–­ä¸ºä¸å®Œæ•´")
                state["is_complete"] = False
                state["reason"] = "æ— æ£€ç´¢å†…å®¹ï¼Œç»§ç»­æ£€ç´¢"
                logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}] è¾“å‡º: is_complete=False, reason='{state['reason']}'")
                return state

            # æ„å»ºæ£€ç´¢å†…å®¹æ‘˜è¦ï¼ˆç« èŠ‚æ ‡é¢˜ + é¡µç ï¼Œä¸åŒ…å«å®Œæ•´å†…å®¹ï¼‰
            content_summary_parts = []
            for idx, item in enumerate(formatted_data, 1):
                if item.get("type") == "structured_info":
                    # ç»“æ„åŒ–ä¿¡æ¯ï¼ˆé€šç”¨å¤„ç†ï¼‰
                    tool_name = item.get("tool", "unknown")
                    data = item.get("data", [])
                    metadata = item.get("metadata", {})

                    # å¦‚æœæœ‰reasonï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                    reason = metadata.get("reason", "") or item.get("reason", "")
                    if reason:
                        content_summary_parts.append(f"{idx}. {tool_name}: {data} ({reason})")
                    else:
                        content_summary_parts.append(f"{idx}. {tool_name}: {len(data)} é¡¹")
                else:
                    # å®é™…å†…å®¹
                    title = item.get("title", "æœªçŸ¥ç« èŠ‚")
                    pages = item.get("pages", [])
                    content_length = len(item.get("content", ""))
                    page_info = f"é¡µç : {pages}" if pages else "æ— é¡µç "
                    content_summary_parts.append(f"{idx}. {title} ({page_info}, {content_length} å­—ç¬¦)")

            content_summary = "\n".join(content_summary_parts)

            # æ„å»ºæ£€ç´¢è½¨è¿¹ï¼ˆåŒ…å«observationçš„å…³é”®ä¿¡æ¯ï¼šæ£€ç´¢æ•°é‡ã€é‡å¤æƒ…å†µç­‰ï¼‰
            def format_param_value(value, max_len=60):
                """é€šç”¨å‚æ•°æ ¼å¼åŒ–å‡½æ•°"""
                if isinstance(value, str):
                    # å­—ç¬¦ä¸²ï¼šé€‚å½“æˆªæ–­
                    return f"'{value[:max_len]}...'" if len(value) > max_len else f"'{value}'"
                elif isinstance(value, list):
                    # åˆ—è¡¨ï¼šå¯¹äºæ ‡é¢˜åˆ—è¡¨ç­‰å…³é”®å‚æ•°ï¼Œæ˜¾ç¤ºæ›´å¤šä¿¡æ¯
                    if not value:
                        return "[]"

                    # æ£€æŸ¥åˆ—è¡¨é¡¹çš„é•¿åº¦ï¼Œå¦‚æœéƒ½æ˜¯è¾ƒçŸ­çš„å­—ç¬¦ä¸²ï¼ˆå¦‚ç« èŠ‚æ ‡é¢˜ï¼‰ï¼Œå°è¯•æ˜¾ç¤ºæ‰€æœ‰é¡¹
                    if len(value) <= 5:
                        # å°‘äº5é¡¹ï¼Œæ˜¾ç¤ºæ‰€æœ‰é¡¹ï¼Œä½†æ¯é¡¹é™åˆ¶é•¿åº¦
                        items_preview = ", ".join([f"'{str(v)[:50]}'" if len(str(v)) > 50 else f"'{str(v)}'" for v in value])
                        return f"[{items_preview}]"
                    else:
                        # å¤šäº5é¡¹ï¼Œæ˜¾ç¤ºå‰3é¡¹
                        items_preview = ", ".join([f"'{str(v)[:50]}'" if len(str(v)) > 50 else f"'{str(v)}'" for v in value[:3]])
                        suffix = f", ...å…±{len(value)}é¡¹"
                        return f"[{items_preview}{suffix}]"
                elif isinstance(value, dict):
                    # å­—å…¸ï¼šæ˜¾ç¤ºé”®å€¼å¯¹æ•°é‡
                    return f"{{{len(value)}ä¸ªå‚æ•°}}"
                elif value is None:
                    return "None"
                else:
                    # å…¶ä»–ç±»å‹ï¼šè½¬å­—ç¬¦ä¸²å¹¶æˆªæ–­
                    value_str = str(value)
                    return value_str[:max_len] if len(value_str) > max_len else value_str

            def extract_observation_summary(observation: str) -> str:
                """ä»observationä¸­æå–å…³é”®ä¿¡æ¯æ‘˜è¦ï¼ˆé€šç”¨æ–¹å¼ï¼‰"""
                if not observation:
                    return ""

                obs_str = str(observation)

                # æå–å…³é”®æ•°å­—ï¼ˆç« èŠ‚æ•°ã€ç»“æœæ•°ç­‰ï¼‰
                import re

                # æ£€æŸ¥æ˜¯å¦æœªæ‰¾åˆ°å†…å®¹
                if "æœªæ‰¾åˆ°" in obs_str or "æ— ç›¸å…³" in obs_str or "æ²¡æœ‰" in obs_str or "0ä¸ª" in obs_str:
                    return " â†’ æœªæ‰¾åˆ°å†…å®¹"

                # æ£€æŸ¥æ˜¯å¦é‡å¤æ£€ç´¢ï¼ˆè¿™ä¸ªä¿¡æ¯å¯èƒ½åœ¨observationä¸­ï¼‰
                if "å·²å­˜åœ¨" in obs_str or "é‡å¤" in obs_str:
                    return " â†’ é‡å¤æ£€ç´¢"

                # æå–å…³é”®ä¿¡æ¯ï¼ˆé€šç”¨æ–¹å¼ï¼Œæ— éœ€hardcodeå·¥å…·åï¼‰
                # è§‚å¯Ÿå­—ç¬¦ä¸²ç°åœ¨æ˜¯æ ‡å‡†åŒ–çš„ï¼Œå¦‚ï¼š"æ–°å¢ 3 ä¸ªç»“æœ"ã€"è·å– 5 é¡¹æ•°æ®"ã€"è¿”å› 2 ä¸ªç»“æœï¼Œä½†å‡ä¸ºé‡å¤å†…å®¹"

                # æå–æ•°å­—ä¿¡æ¯
                numbers = re.findall(r'(\d+)\s*(?:ä¸ª|æ¡|é¡¹)', obs_str)
                if numbers:
                    count = numbers[0]
                    # æ ¹æ®è§‚å¯Ÿå­—ç¬¦ä¸²çš„å†…å®¹åˆ¤æ–­ç±»å‹
                    if "æ–°å¢" in obs_str:
                        return f" â†’ æ–°å¢{count}é¡¹"
                    elif "è·å–" in obs_str:
                        return f" â†’ è·å–{count}é¡¹"
                    elif "é‡å¤" in obs_str:
                        return f" â†’ {count}é¡¹é‡å¤"
                    else:
                        return f" â†’ {count}é¡¹"

                # é»˜è®¤ï¼šç›´æ¥ä½¿ç”¨observationçš„ç®€åŒ–ç‰ˆæœ¬
                if len(obs_str) <= 20:
                    return f" â†’ {obs_str}"
                else:
                    return f" â†’ {obs_str[:17]}..."

            retrieval_trace = []
            for i, (action, observation) in enumerate(zip(actions, observations), 1):
                tool = action.get("tool", "unknown")
                params = action.get("params", {})

                # é€šç”¨å‚æ•°æ ¼å¼åŒ–
                if params:
                    params_str = ", ".join([
                        f"{key}={format_param_value(value)}"
                        for key, value in params.items()
                    ])
                    action_str = f"{tool}({params_str})"
                else:
                    action_str = f"{tool}()"

                # æ·»åŠ observationæ‘˜è¦
                obs_summary = extract_observation_summary(observation)
                trace_item = f"{i}. {action_str}{obs_summary}"

                retrieval_trace.append(trace_item)

            history_summary = "\n".join(retrieval_trace) if retrieval_trace else "æ— æ£€ç´¢å†å²"

            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}] æ„å»ºæ£€ç´¢å†…å®¹æ‘˜è¦:")
            logger.info(f"{content_summary}")
            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}] æ„å»ºæ£€ç´¢å†å²æ‘˜è¦:")
            logger.info(f"{history_summary}")

            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}] è°ƒç”¨ LLM è¯„ä¼°æ£€ç´¢å®Œæ•´æ€§...")

            # è®¡ç®—å½“å‰è¿­ä»£ä¿¡æ¯
            current_iter = len(actions)
            is_last_iteration = current_iteration >= max_iterations - 1

            # ========== åˆ†ææ£€ç´¢ç­–ç•¥æ•ˆæœ ==========
            attempted_strategies = []
            # ========== ç®€åŒ–ï¼šç›´æ¥æ„å»ºæ£€ç´¢å†å² JSON ==========
            observations = state.get("observations", [])
            
            history_data = []
            for idx, (action, observation) in enumerate(zip(actions, observations), 1):
                history_data.append({
                    "round": idx,
                    "tool": action.get("tool", "unknown"),
                    "params": action.get("params", {}),
                    "observation": observation
                })
            
            import json
            history_json = json.dumps(history_data, ensure_ascii=False, indent=2)
            
            prompt = f"""# ç”¨æˆ·æŸ¥è¯¢
{original_query}

# æ£€ç´¢å†å²ï¼ˆJSON æ ¼å¼ï¼‰
```json
{history_json}
```

# æ£€ç´¢åˆ°çš„å†…å®¹æ‘˜è¦
{content_summary}

# å½“å‰çŠ¶æ€
- å·²æ‰§è¡Œæ£€ç´¢æ¬¡æ•°: {current_iter}
- æœ€å¤§å…è®¸æ¬¡æ•°: {max_iterations}
- æ˜¯å¦æœ€åä¸€æ¬¡æœºä¼š: {"æ˜¯" if is_last_iteration else "å¦"}

# ä»»åŠ¡
æ ¹æ®ç³»ç»Ÿæç¤ºä¸­çš„è¯„ä¼°æ ‡å‡†ï¼Œåˆ¤æ–­å½“å‰æ£€ç´¢å†…å®¹æ˜¯å¦è¶³ä»¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
**é‡è¦**ï¼š
1. ä»”ç»†åˆ†ææ£€ç´¢å†å² JSONï¼Œè¯†åˆ«æ˜¯å¦æœ‰é‡å¤çš„æ£€ç´¢ï¼ˆç›¸åŒå·¥å…·+ç›¸åŒå‚æ•°ï¼‰
2. è§‚å¯Ÿæ¯æ¬¡æ£€ç´¢çš„ observationï¼Œåˆ¤æ–­æ£€ç´¢æ•ˆæœ
3. å¦‚æœå•æ¬¡æ£€ç´¢å¤±è´¥ï¼Œreason ä¸­å¿…é¡»ç»™å‡ºå…·ä½“çš„æ›¿ä»£æ–¹æ¡ˆå»ºè®®


è¿”å›ä¸¥æ ¼çš„ JSON æ ¼å¼ï¼š
{{"is_complete": true/false, "reason": "..."}}

**reason å­—æ®µè¦æ±‚**ï¼š
- å¦‚æœ is_complete=trueï¼šè¯´æ˜ä¸ºä»€ä¹ˆåœæ­¢
- å¦‚æœ is_complete=falseï¼šå¿…é¡»åŒ…å«å…·ä½“çš„ä¸‹ä¸€æ­¥å»ºè®®
"""

            session_id = f"evaluate_{state.get('doc_name', 'default')}"
            response = await self.agent.llm.async_call_llm_chain(
                role=RetrievalRole.RETRIEVAL_EVALUATOR,
                input_prompt=prompt,
                session_id=session_id
            )

            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}] LLM å“åº”: {response[:200]}...")

            evaluation = json.loads(response.strip()) if response.strip().startswith('{') else {}
            is_complete = evaluation.get("is_complete", False)
            reason = evaluation.get("reason", "")

            state["is_complete"] = is_complete
            state["reason"] = reason

            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}] è¯„ä¼°ç»“æœ:")
            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}]   - æ˜¯å¦å®Œæ•´: {is_complete}")
            logger.info(f"âš–ï¸ [Evaluate|{self._doc_tag()}]   - åˆ¤æ–­ç†ç”±: {reason}")

            if is_complete:
                logger.info(f"âœ… [Evaluate|{self._doc_tag()}] æ£€ç´¢å®Œæˆï¼Œå‡†å¤‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
            else:
                logger.info(f"ğŸ”„ [Evaluate|{self._doc_tag()}] æ£€ç´¢æœªå®Œæˆï¼Œå°†ç»§ç»­ä¸‹ä¸€è½®")

            return state

        except Exception as e:
            logger.error(f"âŒ [Evaluate|{self._doc_tag()}] å¤±è´¥: {e}", exc_info=True)
            is_complete_fallback = current_iteration >= state.get("max_iterations", ProcessingLimits.MAX_RETRIEVAL_ITERATIONS)
            state["is_complete"] = is_complete_fallback
            state["reason"] = f"è¯„ä¼°å¤±è´¥ï¼ŒåŸºäºè¿­ä»£æ¬¡æ•°åˆ¤æ–­: {is_complete_fallback}"
            logger.info(f"âš ï¸  [Evaluate|{self._doc_tag()}] é”™è¯¯å›é€€: is_complete={is_complete_fallback}")
            return state

    async def format(self, state: RetrievalState) -> Dict:
        """ç”Ÿæˆæœ€ç»ˆç²¾å‡†æ€»ç»“"""

        logger.info(f"ğŸ¯ [Format|{self._doc_tag()}] ========== æ­¥éª¤5: ç”Ÿæˆæœ€ç»ˆæ€»ç»“ ==========")

        try:
            formatted_data = state.get("formatted_data", [])
            intermediate_summary = state.get("intermediate_summary", "")
            original_query = state["query"]

            logger.info(f"ğŸ¯ [Format|{self._doc_tag()}] è¾“å…¥:")
            logger.info(f"ğŸ¯ [Format|{self._doc_tag()}]   - ç”¨æˆ·æŸ¥è¯¢: {original_query}")
            logger.info(f"ğŸ¯ [Format|{self._doc_tag()}]   - æ ¼å¼åŒ–æ•°æ®æ•°: {len(formatted_data)}")
            #logger.info(f"ğŸ¯ [Format|{self._doc_tag()}]   - ä¸­é—´æ€»ç»“é•¿åº¦: {len(intermediate_summary)} å­—ç¬¦")

            if not formatted_data:
                logger.warning(f"âš ï¸  [Format|{self._doc_tag()}] æ— æ ¼å¼åŒ–æ•°æ®ï¼Œä½¿ç”¨ä¸­é—´æ€»ç»“ä½œä¸ºæœ€ç»ˆç­”æ¡ˆ")
                #state["final_summary"] = intermediate_summary
                #logger.info(f"ğŸ¯ [Format|{self._doc_tag()}] è¾“å‡º: ä½¿ç”¨ä¸­é—´æ€»ç»“ (é•¿åº¦: {len(intermediate_summary)})")

                # ============ çŠ¶æ€æŒä¹…åŒ–ï¼šä¿å­˜å½“å‰çŠ¶æ€ä¾›ä¸‹ä¸€è½®ä½¿ç”¨ ============
                self._save_persistent_state(state)

                return state

            # æ„å»ºæœ€ç»ˆæ€»ç»“
            logger.info(f"ğŸ¯ [Format|{self._doc_tag()}] è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆç²¾å‡†ç­”æ¡ˆ...")

            # ========== æ­¥éª¤1: å»é‡å’Œåˆå¹¶ raw_data ==========
            # ä½¿ç”¨ raw_data è€Œä¸æ˜¯ contentï¼ˆrefactor_dataï¼‰
            # æŒ‰é¡µç å»é‡ï¼šåŒä¸€é¡µåªä¿ç•™ä¸€æ¬¡
            all_raw_pages = {}  # {page_num: {"title": str, "content": str}}

            for item in formatted_data:
                # è·³è¿‡ç»“æ„åŒ–ä¿¡æ¯ï¼ˆå®ƒä»¬ä¸æ˜¯å®é™…å†…å®¹ï¼‰
                if item.get("type") == "structured_info":
                    continue

                title = item.get("title", "æœªçŸ¥ç« èŠ‚")
                raw_data = item.get("raw_data", {})
                pages = item.get("pages", [])
                content = item.get("content", "")

                # ä¼˜å…ˆä½¿ç”¨ raw_dataï¼Œå¦‚æœæ²¡æœ‰åˆ™ fallback åˆ° content
                if isinstance(raw_data, dict) and raw_data:
                    # éå†æ¯ä¸€é¡µçš„åŸå§‹æ•°æ®
                    for page_num, page_content in raw_data.items():
                        # å»é‡ï¼šåŒä¸€é¡µåªä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„å†…å®¹
                        if page_num not in all_raw_pages:
                            all_raw_pages[page_num] = {
                                "title": title,
                                "content": page_content
                            }
                elif content:
                    # Fallback: å¦‚æœæ²¡æœ‰ raw_dataï¼Œä½¿ç”¨ contentï¼ˆrefactor_dataï¼‰
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªé¡µç ä½œä¸º keyï¼ˆæˆ–ä½¿ç”¨ "unknown" å¦‚æœæ²¡æœ‰é¡µç ï¼‰
                    page_key = pages[0] if pages else f"unknown_{title}"
                    if page_key not in all_raw_pages:
                        all_raw_pages[page_key] = {
                            "title": title,
                            "content": content
                        }

            logger.info(f"ğŸ¯ [Format|{self._doc_tag()}] å»é‡åå…± {len(all_raw_pages)} é¡µåŸå§‹å†…å®¹")

            # ========== æ­¥éª¤2: æ„å»ºæ£€ç´¢å†…å®¹è¯¦æƒ… ==========
            content_parts = []

            # æŒ‰é¡µç æ’åº
            sorted_pages = sorted(all_raw_pages.keys(), key=lambda x: int(x) if str(x).isdigit() else 0)

            for idx, page_num in enumerate(sorted_pages, 1):
                page_data = all_raw_pages[page_num]
                title = page_data["title"]
                content = page_data["content"]

                content_block = f"""
## å†…å®¹ {idx}: {title} (é¡µç : {page_num})

{content}
"""
                content_parts.append(content_block.strip())

            # æ„å»ºå®Œæ•´çš„ prompt
            all_content = "\n\n".join(content_parts)

            prompt = f"""# ç”¨æˆ·æŸ¥è¯¢

{original_query}

# æ£€ç´¢åˆ°çš„å†…å®¹

{all_content}

---

# ä»»åŠ¡

åŸºäºä»¥ä¸Šæ£€ç´¢å†…å®¹ï¼Œç”Ÿæˆç²¾å‡†ã€å®Œæ•´çš„ç­”æ¡ˆæ¥å›ç­”ç”¨æˆ·æŸ¥è¯¢ã€‚

è¦æ±‚ï¼š
1. ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œèšç„¦äºæŸ¥è¯¢çš„æ ¸å¿ƒ
2. åŸºäºæ£€ç´¢å†…å®¹çš„äº‹å®å’Œæ•°æ®ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
3. ä¿ç•™é‡è¦çš„ç»†èŠ‚ã€æ•°æ®ã€å…¬å¼ç­‰å…³é”®ä¿¡æ¯
4. ä½¿ç”¨æ¸…æ™°çš„ Markdown æ ¼å¼ç»„ç»‡ç­”æ¡ˆ
5. **é¡µç æ ‡æ³¨**: åœ¨ç­”æ¡ˆæ­£æ–‡ä¸­ä¸è¦é¢‘ç¹æ ‡æ³¨é¡µç ï¼Œåªåœ¨ç­”æ¡ˆæœ«å°¾ç®€è¦æåŠä¸»è¦æ¥æºé¡µç å³å¯
6. å¦‚æœæ£€ç´¢å†…å®¹ä¸è¶³ä»¥å®Œå…¨å›ç­”é—®é¢˜ï¼Œæ˜ç¡®è¯´æ˜
"""

            logger.info(f"ğŸ¯ [Format|{self._doc_tag()}] å‡†å¤‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼Œå†…å®¹æ•°: {len(content_parts)}ï¼Œæ€»é•¿åº¦: {len(all_content)} å­—ç¬¦")

            session_id = f"format_{state.get('doc_name', 'default')}"
            final_summary = await self.agent.llm.async_call_llm_chain(
                role=RetrievalRole.CONTEXT_SUMMARIZER,
                input_prompt=prompt,
                session_id=session_id
            )

            state["final_summary"] = final_summary
            logger.info(f"âœ… [Format|{self._doc_tag()}] æœ€ç»ˆç­”æ¡ˆç”Ÿæˆå®Œæˆ")
            logger.info(f"ğŸ¯ [Format|{self._doc_tag()}]   - ç­”æ¡ˆé•¿åº¦: {len(final_summary)} å­—ç¬¦")
            logger.info(f"ğŸ¯ [Format|{self._doc_tag()}]   - ç­”æ¡ˆé¢„è§ˆ: {final_summary[:200]}...")

            # ============ çŠ¶æ€æŒä¹…åŒ–ï¼šä¿å­˜å½“å‰çŠ¶æ€ä¾›ä¸‹ä¸€è½®ä½¿ç”¨ ============
            self._save_persistent_state(state)

            return state

        except Exception as e:
            logger.error(f"âŒ [Format|{self._doc_tag()}] å¤±è´¥: {e}", exc_info=True)
            #intermediate_summary = state.get("intermediate_summary", "")
            #state["final_summary"] = intermediate_summary
            #logger.info(f"âš ï¸  [Format|{self._doc_tag()}] é”™è¯¯å›é€€: ä½¿ç”¨ä¸­é—´æ€»ç»“ (é•¿åº¦: {len(intermediate_summary)})")

            # ============ çŠ¶æ€æŒä¹…åŒ–ï¼šå³ä½¿å¤±è´¥ä¹Ÿä¿å­˜çŠ¶æ€ ============
            self._save_persistent_state(state)

            return state

    def should_continue(self, state: RetrievalState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­æ£€ç´¢"""
        current_iter = state.get("current_iteration", 0)
        max_iter = state.get("max_iterations", ProcessingLimits.MAX_RETRIEVAL_ITERATIONS)

        # æ·»åŠ è¯¦ç»†æ—¥å¿—ä»¥ä¾¿è°ƒè¯•
        logger.info(f"ğŸ” [ShouldContinue] æ£€æŸ¥è¿­ä»£çŠ¶æ€: current={current_iter}, max={max_iter}, is_complete={state.get('is_complete', False)}")

        if state.get("is_complete", False):
            logger.info(f"âœ… [ShouldContinue] æ£€ç´¢å®Œæˆï¼Œç»“æŸå¾ªç¯")
            return "finish"

        if current_iter >= max_iter:
            logger.warning(f"âš ï¸  [ShouldContinue] è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({max_iter})ï¼Œç»“æŸå¾ªç¯")
            return "finish"

        logger.info(f"ğŸ”„ [ShouldContinue] ç»§ç»­ä¸‹ä¸€è½®æ£€ç´¢ (ç¬¬ {current_iter + 1}/{max_iter} è½®)")
        return "continue"
