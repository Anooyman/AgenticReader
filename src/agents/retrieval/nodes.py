"""
RetrievalAgent WorkflowèŠ‚ç‚¹æ–¹æ³•

æ‰€æœ‰workflowèŠ‚ç‚¹çš„å®ç°
"""

from __future__ import annotations
from typing import Dict, TYPE_CHECKING
import logging
import json
import re

from .state import RetrievalState
from .prompts import RetrievalRole
from .tools_config import format_all_tools_for_llm, get_tool_by_name
from src.config.constants import ProcessingLimits

if TYPE_CHECKING:
    from .agent import RetrievalAgent

logger = logging.getLogger(__name__)


class RetrievalNodes:
    """RetrievalAgent WorkflowèŠ‚ç‚¹æ–¹æ³•é›†åˆ"""

    def __init__(self, agent: 'RetrievalAgent'):
        """
        Args:
            agent: RetrievalAgentå®ä¾‹ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
        """
        self.agent = agent

    async def initialize(self, state: RetrievalState) -> Dict:
        """åˆå§‹åŒ–èŠ‚ç‚¹ï¼šè®¾ç½®Agentçš„ä¸Šä¸‹æ–‡ç¯å¢ƒ"""
        logger.info(f"ğŸ”§ [Initialize] ========== RetrievalAgent åˆå§‹åŒ– ==========")

        try:
            # éªŒè¯state
            self.agent.utils.validate_state(state)

            # ä»stateä¸­è¯»å–å¹¶è®¾ç½®æ–‡æ¡£ä¸Šä¸‹æ–‡
            doc_name_from_state = state.get('doc_name')
            self.agent.current_doc = doc_name_from_state or self.agent.current_doc

            logger.info(f"ğŸ”§ [Initialize] é…ç½®ä¿¡æ¯:")
            logger.info(f"ğŸ”§ [Initialize]   - æ–‡æ¡£åç§°: {self.agent.current_doc or 'å¤šæ–‡æ¡£æ¨¡å¼'}")
            logger.info(f"ğŸ”§ [Initialize]   - æŸ¥è¯¢å†…å®¹: {state['query']}")
            logger.info(f"ğŸ”§ [Initialize]   - æœ€å¤§è¿­ä»£: {state['max_iterations']}")

            # åˆ›å»ºæˆ–æ›´æ–° VectorDBClient
            if self.agent.current_doc:
                if self.agent.vector_db_client is None:
                    self.agent.vector_db_client = self.agent.utils.create_vector_db_client(self.agent.current_doc)
                    logger.info(f"âœ… [Initialize] VectorDBClient å·²åˆ›å»ºå¹¶åŠ è½½")
                elif doc_name_from_state and doc_name_from_state != self.agent.current_doc:
                    logger.info(f"ğŸ”„ [Initialize] æ–‡æ¡£åç§°å˜åŒ–ï¼Œé‡æ–°åˆ›å»ºVectorDBClient")
                    self.agent.vector_db_client = self.agent.utils.create_vector_db_client(doc_name_from_state)
                    self.agent.current_doc = doc_name_from_state

            # åˆå§‹åŒ–stateå­—æ®µ
            for field in ['retrieved_content', 'formatted_data', 'thoughts', 'actions', 'observations']:
                if field not in state:
                    state[field] = []
            if 'current_iteration' not in state:
                state['current_iteration'] = 0

            logger.info(f"âœ… [Initialize] åˆå§‹åŒ–å®Œæˆ")
            return state

        except Exception as e:
            logger.error(f"âŒ [Initialize] åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            raise

    async def rewrite(self, state: RetrievalState) -> Dict:
        """æŸ¥è¯¢é‡å†™èŠ‚ç‚¹"""

        conversation_turn = state.get("conversation_turn", 0)
        intermediate_summary = state.get("intermediate_summary", "")
        original_query = state["query"]

        logger.info(f"ğŸ”„ [Rewrite] ========== æ­¥éª¤0: æŸ¥è¯¢é‡å†™ ==========")
        logger.info(f"ğŸ”„ [Rewrite] å¯¹è¯è½®æ¬¡: {conversation_turn}")
        logger.info(f"ğŸ”„ [Rewrite] åŸå§‹æŸ¥è¯¢: {original_query}")

        try:
            # ä½¿ç”¨å¯¹è¯è½®æ¬¡åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å†™ï¼ˆè€Œä¸æ˜¯æ£€ç´¢è¿­ä»£æ¬¡æ•°ï¼‰
            if conversation_turn == 0:
                logger.info(f"ğŸ”„ [Rewrite] åˆ¤æ–­: é¦–è½®å¯¹è¯æˆ–æ— ä¸­é—´æ€»ç»“ï¼Œè·³è¿‡æŸ¥è¯¢é‡å†™")
                state["rewritten_query"] = original_query
                logger.info(f"âœ… [Rewrite] è¾“å‡ºæŸ¥è¯¢: {original_query}")
                return state

            logger.info(f"ğŸ”„ [Rewrite] åˆ¤æ–­: éé¦–è½®å¯¹è¯ä¸”æœ‰ä¸­é—´æ€»ç»“ï¼Œè¿›è¡ŒæŸ¥è¯¢ä¼˜åŒ–")
            #logger.info(f"ğŸ”„ [Rewrite] ä¸­é—´æ€»ç»“é•¿åº¦: {len(intermediate_summary)} å­—ç¬¦")

            # æ„å»ºpromptï¼ˆçœç•¥å…·ä½“å®ç°ï¼‰
            #session_id = f"rewrite_{state.get('doc_name', 'default')}"
            rewritten = await self.agent.llm.async_call_llm_chain(
                role=RetrievalRole.QUERY_REWRITE,
                input_prompt=f"åŸå§‹æŸ¥è¯¢: {original_query}\nä¼˜åŒ–è¯¥æŸ¥è¯¢",
                session_id="rewrite_query"
            )

            rewritten_clean = rewritten.strip().strip('"').strip("'").strip()
            state["rewritten_query"] = rewritten_clean
            logger.info(f"âœ… [Rewrite] é‡å†™åæŸ¥è¯¢: {rewritten_clean}")
            return state

        except Exception as e:
            logger.error(f"âŒ [Rewrite] å¤±è´¥: {e}", exc_info=True)
            state["rewritten_query"] = original_query
            logger.info(f"âš ï¸  [Rewrite] å›é€€åˆ°åŸå§‹æŸ¥è¯¢: {original_query}")
            return state

    async def think(self, state: RetrievalState) -> Dict:
        """æ€è€ƒèŠ‚ç‚¹ï¼šé€‰æ‹©å·¥å…·"""

        current_iteration = state.get("current_iteration", 0)
        logger.info(f"ğŸ¤” [Think] ========== æ­¥éª¤1: æ€è€ƒå·¥å…·é€‰æ‹© ==========")
        logger.info(f"ğŸ¤” [Think] è¿­ä»£è¿›åº¦: ç¬¬ {current_iteration + 1}/{state['max_iterations']} è½®")

        try:
            tools_description = format_all_tools_for_llm()
            current_query = state.get("rewritten_query", state["query"])
            original_query = state["query"]

            logger.info(f"ğŸ¤” [Think] è¾“å…¥:")
            logger.info(f"ğŸ¤” [Think]   - åŸå§‹æŸ¥è¯¢: {original_query}")
            logger.info(f"ğŸ¤” [Think]   - å½“å‰æŸ¥è¯¢: {current_query}")

            # æ„å»ºå†å²æ‰§è¡Œä¿¡æ¯
            actions_history = state.get("actions", [])
            executed_tools = [action.get("tool", "") for action in actions_history]

            # æ„å»ºå·²ç´¯ç§¯å†…å®¹ä¿¡æ¯
            retrieved_content = state.get("retrieved_content", [])
            #intermediate_summary = state.get("intermediate_summary", "")

            logger.info(f"ğŸ¤” [Think] ä¸Šä¸‹æ–‡:")
            logger.info(f"ğŸ¤” [Think]   - å·²æ‰§è¡Œå·¥å…·: {executed_tools if executed_tools else 'æ— '}")
            logger.info(f"ğŸ¤” [Think]   - å·²æ£€ç´¢å†…å®¹æ•°: {len(retrieved_content)}")
            #logger.info(f"ğŸ¤” [Think]   - ä¸­é—´æ€»ç»“é•¿åº¦: {len(intermediate_summary)} å­—ç¬¦")

            # ========== æå–ç»“æ„åŒ–ä¿¡æ¯ï¼ˆget_document_structure å’Œ extract_titles_from_structure çš„ç»“æœï¼‰ ==========
            document_structure = None
            extracted_titles = None
            extraction_reason = None

            # éå† retrieved_contentï¼ŒæŸ¥æ‰¾ç»“æ„åŒ–ä¿¡æ¯ï¼ˆæ–°æ ¼å¼ï¼šåŒ…è£…åœ¨ dict ä¸­ï¼‰
            for item in retrieved_content:
                if isinstance(item, dict):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç»“æ„åŒ–ä¿¡æ¯
                    if item.get("type") == "structured_info":
                        tool_name = item.get("tool", "")
                        data = item.get("data", [])

                        if tool_name == "get_document_structure":
                            document_structure = data
                        elif tool_name == "extract_titles_from_structure":
                            extracted_titles = data
                            extraction_reason = item.get("reason", "")

            logger.info(f"ğŸ¤” [Think]   - æ–‡æ¡£ç»“æ„: {'å·²è·å–' if document_structure else 'æœªè·å–'}")
            logger.info(f"ğŸ¤” [Think]   - æå–æ ‡é¢˜: {extracted_titles if extracted_titles else 'æœªæå–'}")
            if extraction_reason:
                logger.info(f"ğŸ¤” [Think]   - æå–åŸå› : {extraction_reason}")

            # æ„å»ºå†å²ä¿¡æ¯æ‘˜è¦
            history_info = ""
            if executed_tools:
                history_parts = [f"## å·²æ‰§è¡Œçš„å·¥å…·\n{', '.join(executed_tools)}"]

                # å¦‚æœæœ‰æ–‡æ¡£ç»“æ„ï¼Œæ˜¾ç¤ºå®ƒ
                if document_structure:
                    structure_preview = "\n".join(document_structure[:10])  # åªæ˜¾ç¤ºå‰10è¡Œ
                    if len(document_structure) > 10:
                        structure_preview += "\n... (è¿˜æœ‰æ›´å¤šç« èŠ‚)"
                    history_parts.append(f"""
## å·²è·å–çš„æ–‡æ¡£ç»“æ„
{structure_preview}
""")

                # å¦‚æœæœ‰æå–çš„æ ‡é¢˜ï¼Œæ˜¾ç¤ºå®ƒ
                if extracted_titles:
                    title_info = f"""
## å·²æå–çš„æ ‡é¢˜åˆ—è¡¨
{extracted_titles}
"""
                    if extraction_reason:
                        title_info += f"""
**æå–åŸå› **: {extraction_reason}
"""
                    history_parts.append(title_info)

                # æ˜¾ç¤ºç´¯ç§¯å†…å®¹ï¼ˆç« èŠ‚æ ‡é¢˜å’Œé¡µç ï¼‰
                if retrieved_content:
                    content_items = []
                    for idx, item in enumerate(retrieved_content, 1):
                        if isinstance(item, dict):
                            if item.get("type") == "structured_info":
                                # ç»“æ„åŒ–ä¿¡æ¯å·²ç»åœ¨ä¸Šé¢æ˜¾ç¤ºè¿‡äº†ï¼Œè·³è¿‡
                                continue
                            else:
                                # å®é™…æ£€ç´¢å†…å®¹
                                title = item.get("title", "æœªçŸ¥ç« èŠ‚")
                                pages = item.get("pages", [])
                                content_len = len(item.get("content", ""))
                                page_info = f"é¡µç : {pages}" if pages else "æ— é¡µç "
                                content_items.append(f"{idx}. {title} ({page_info}, {content_len} å­—ç¬¦)")

                    if content_items:
                        content_summary = "å·²æ£€ç´¢çš„ç« èŠ‚:\n" + "\n".join(content_items)
                        history_parts.append(f"""
## å½“å‰ç´¯ç§¯å†…å®¹
{content_summary}
""")
                    else:
                        history_parts.append(f"""
## å½“å‰ç´¯ç§¯å†…å®¹
å·²ç´¯ç§¯ {len(retrieved_content)} æ¡ä¿¡æ¯ï¼ˆä¸»è¦ä¸ºç»“æ„åŒ–ä¿¡æ¯ï¼‰
""")

                history_info = "\n".join(history_parts)
            else:
                history_info = "## é¦–æ¬¡æ£€ç´¢\nè¿™æ˜¯ç¬¬ä¸€è½®æ£€ç´¢ï¼Œæš‚æ— å†å²æ‰§è¡Œè®°å½•ã€‚"

            # æ„å»ºç®€æ´çš„ promptï¼ˆå·¥å…·é€‰æ‹©ç­–ç•¥å’Œå‚æ•°æ ¼å¼ç”±ç³»ç»Ÿæç¤ºå¼•å¯¼ï¼‰
            prompt = f"""# å½“å‰ä»»åŠ¡ä¿¡æ¯

**ç”¨æˆ·åŸå§‹æŸ¥è¯¢**: {original_query}
**å½“å‰ä¼˜åŒ–æŸ¥è¯¢**: {current_query}
**è¿­ä»£è¿›åº¦**: ç¬¬ {current_iteration + 1}/{state['max_iterations']} è½®

{history_info}

# è¯·é€‰æ‹©ä¸‹ä¸€æ­¥å·¥å…·

è¯·ä»”ç»†é˜…è¯»æ¯ä¸ªå·¥å…·çš„æè¿°ï¼ˆç‰¹åˆ«æ˜¯"ä½¿ç”¨åœºæ™¯"ã€"å‰ç½®æ¡ä»¶"ã€"åç»­æ­¥éª¤"ã€"å‚æ•°"ï¼‰ï¼ŒåŸºäºå½“å‰ä¸Šä¸‹æ–‡é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚

**é‡è¦æç¤º**:
- ä¸¥æ ¼æŒ‰ç…§å·¥å…·æè¿°ä¸­çš„"å‚æ•°"è¦æ±‚å¡«å†™ action_input
- ç‰¹åˆ«æ³¨æ„ search_by_title å·¥å…·éœ€è¦ JSON æ•°ç»„æ ¼å¼çš„å‚æ•°ï¼Œä¸æ˜¯å­—ç¬¦ä¸²

è¿”å›ä¸¥æ ¼çš„ JSON æ ¼å¼ï¼š
{{
  "thought": "ä½ çš„æ€è€ƒè¿‡ç¨‹",
  "action": "å·¥å…·åç§°",
  "action_input": "å·¥å…·å‚æ•°ï¼ˆä¸¥æ ¼éµå¾ªå·¥å…·çš„å‚æ•°æ ¼å¼è¦æ±‚ï¼‰"
}}
"""

            logger.info(f"ğŸ¤” [Think] è°ƒç”¨ LLM è¿›è¡Œå·¥å…·é€‰æ‹©...")
            session_id = f"think_{state.get('doc_name', 'default')}"
            response = await self.agent.llm.async_call_llm_chain(
                role=RetrievalRole.RETRIEVAL,
                input_prompt=prompt,
                session_id=session_id,
                system_format_dict={"tool_info_dict": tools_description}
            )

            # è§£æJSON
            logger.info(f"ğŸ¤” [Think] LLM å“åº”: {response[:200]}...")
            decision = json.loads(response.strip()) if response.strip().startswith('{') else None

            if decision:
                thought = decision.get("thought", "")
                action = decision.get("action", "search_by_context")
                action_input = decision.get("action_input", current_query)

                logger.info(f"ğŸ¤” [Think] å†³ç­–ç»“æœ:")
                logger.info(f"ğŸ¤” [Think]   - æ€è€ƒ: {thought}")
                logger.info(f"ğŸ¤” [Think]   - é€‰æ‹©å·¥å…·: {action}")
                logger.info(f"ğŸ¤” [Think]   - å·¥å…·å‚æ•°: {action_input}")
            else:
                logger.warning(f"âš ï¸  [Think] JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·")
                action = "search_by_context"
                action_input = current_query
                logger.info(f"ğŸ¤” [Think]   - é»˜è®¤å·¥å…·: {action}")
                logger.info(f"ğŸ¤” [Think]   - é»˜è®¤å‚æ•°: {action_input}")

            state["current_tool"] = action
            state["action_input"] = action_input
            state["current_iteration"] = current_iteration + 1

            # å®‰å…¨åœ°æ˜¾ç¤ºå‚æ•°ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            if isinstance(action_input, str):
                param_preview = action_input[:50] + "..." if len(action_input) > 50 else action_input
            elif isinstance(action_input, list):
                param_preview = str(action_input)[:100] + "..." if len(str(action_input)) > 100 else str(action_input)
            else:
                param_preview = str(action_input)

            logger.info(f"âœ… [Think] è¾“å‡º: å·¥å…·={action}, å‚æ•°ç±»å‹={type(action_input).__name__}, å‚æ•°={param_preview}")
            return state

        except Exception as e:
            logger.error(f"âŒ [Think] å¤±è´¥: {e}", exc_info=True)
            state["current_tool"] = "search_by_context"
            state["action_input"] = state.get("rewritten_query", state["query"])
            state["current_iteration"] = current_iteration + 1
            logger.info(f"âš ï¸  [Think] é”™è¯¯å›é€€: ä½¿ç”¨ search_by_context")
            return state

    async def act(self, state: RetrievalState) -> Dict:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""

        tool_name = state["current_tool"]
        action_input = state.get("action_input", state.get("rewritten_query", state["query"]))

        logger.info(f"ğŸ”§ [Act] ========== æ­¥éª¤2: æ‰§è¡Œå·¥å…· ==========")
        logger.info(f"ğŸ”§ [Act] å·¥å…·åç§°: {tool_name}")
        logger.info(f"ğŸ”§ [Act] å·¥å…·å‚æ•°: {action_input}")

        try:
            # æ„å»ºå¯ç”¨å·¥å…·
            available_tools = self.agent.utils.build_retrieval_tools()
            logger.info(f"ğŸ”§ [Act] å¯ç”¨å·¥å…·åˆ—è¡¨: {list(available_tools.keys())}")

            if tool_name in available_tools:
                logger.info(f"ğŸ”§ [Act] è°ƒç”¨å·¥å…·: {tool_name}")
                tool_func = available_tools[tool_name]["function"]

                # è°ƒç”¨å·¥å…·ï¼ˆä¼ å…¥action_inputï¼‰
                result = await tool_func(action_input)
            else:
                logger.warning(f"âš ï¸  [Act] å·¥å…· '{tool_name}' ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·")
                result = await self.agent.tools.search_by_context(action_input)

            # ç»Ÿè®¡ç»“æœ
            if isinstance(result, dict):
                # extract_titles_from_structure çš„æ–°æ ¼å¼
                result_count = len(result.get("titles", []))
                logger.info(f"ğŸ”§ [Act] å·¥å…·æ‰§è¡Œå®Œæˆï¼Œæå–åˆ° {result_count} ä¸ªæ ‡é¢˜")
                if result.get("titles"):
                    logger.info(f"ğŸ”§ [Act]   æ ‡é¢˜åˆ—è¡¨: {result.get('titles')}")
                if result.get("reason"):
                    logger.info(f"ğŸ”§ [Act]   é€‰æ‹©åŸå› : {result.get('reason')}")
            elif isinstance(result, list):
                result_count = len(result)
                logger.info(f"ğŸ”§ [Act] å·¥å…·æ‰§è¡Œå®Œæˆï¼Œè¿”å› {result_count} æ¡ç»“æœ")

                if result_count > 0:
                    # åŒºåˆ†ç»“æ„åŒ–å·¥å…·å’Œå†…å®¹æ£€ç´¢å·¥å…·
                    if tool_name == "get_document_structure":
                        # get_document_structureï¼šæ˜¾ç¤ºç»“æœé¢„è§ˆ
                        preview_items = result[:5] if len(result) > 5 else result
                        logger.info(f"ğŸ”§ [Act]   ç»“æœé¢„è§ˆï¼ˆå‰{len(preview_items)}é¡¹ï¼‰:")
                        for idx, item in enumerate(preview_items, 1):
                            logger.info(f"ğŸ”§ [Act]     {idx}. {item}")
                        if len(result) > 5:
                            logger.info(f"ğŸ”§ [Act]     ... (è¿˜æœ‰ {len(result) - 5} é¡¹)")
                    else:
                        # å†…å®¹æ£€ç´¢å·¥å…·ï¼šæ˜¾ç¤ºç« èŠ‚ä¿¡æ¯ï¼ˆæ³¨æ„ï¼štitle æ˜¯æ£€ç´¢çš„ç›®æ ‡ï¼Œä¸æ˜¯æ£€ç´¢ç»“æœçš„æ ‡é¢˜ï¼‰
                        logger.info(f"ğŸ”§ [Act]   æ£€ç´¢åˆ°çš„å†…å®¹:")
                        for idx, item in enumerate(result[:3], 1):
                            if isinstance(item, dict):
                                title = item.get("title", "æ— æ ‡é¢˜")
                                pages = item.get("pages", [])
                                content_preview = item.get("content", "")[:50] + "..." if item.get("content", "") else ""
                                logger.info(f"ğŸ”§ [Act]     {idx}. ç« èŠ‚: {title} (é¡µç : {pages})")
                                logger.info(f"ğŸ”§ [Act]        å†…å®¹é¢„è§ˆ: {content_preview}")
                        if len(result) > 3:
                            logger.info(f"ğŸ”§ [Act]     ... (è¿˜æœ‰ {len(result) - 3} æ¡)")
            else:
                result_count = 0
                logger.info(f"ğŸ”§ [Act] å·¥å…·æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç»“æœç±»å‹: {type(result)}")

            # è·å–å·¥å…·é…ç½®
            tool_config = get_tool_by_name(tool_name)
            requires_summary = tool_config.get("requires_summary", True) if tool_config else True
            logger.info(f"ğŸ”§ [Act] æ˜¯å¦éœ€è¦æ€»ç»“: {requires_summary}")

            state["last_result"] = result
            state["requires_summary"] = requires_summary
            state["actions"] = state.get("actions", []) + [{"tool": tool_name}]

            logger.info(f"âœ… [Act] è¾“å‡º: {result_count} æ¡ç»“æœï¼Œrequires_summary={requires_summary}")
            return state

        except Exception as e:
            logger.error(f"âŒ [Act] å¤±è´¥: {e}", exc_info=True)
            state["last_result"] = []
            state["requires_summary"] = True
            logger.info(f"âš ï¸  [Act] é”™è¯¯å›é€€: è¿”å›ç©ºç»“æœ")
            return state

    async def summary(self, state: RetrievalState) -> Dict:
        """ç´¯ç§¯å¹¶æ€»ç»“æ•°æ®ï¼ˆå§‹ç»ˆç´¯ç§¯ï¼ŒæŒ‰éœ€æ€»ç»“ï¼‰"""

        logger.info(f"ğŸ“ [Summary] ========== æ­¥éª¤3: ç´¯ç§¯å¹¶æ€»ç»“æ•°æ® ==========")

        try:
            last_result = state.get("last_result", [])
            retrieved_content = state.get("retrieved_content", [])
            requires_summary = state.get("requires_summary", True)

            logger.info(f"ğŸ“ [Summary] è¾“å…¥:")
            logger.info(f"ğŸ“ [Summary]   - æœ¬è½®ç»“æœæ•°: {len(last_result) if isinstance(last_result, list) else 0}")
            logger.info(f"ğŸ“ [Summary]   - ç´¯ç§¯ç»“æœæ•°: {len(retrieved_content)}")
            logger.info(f"ğŸ“ [Summary]   - éœ€è¦ç”Ÿæˆæ€»ç»“: {requires_summary}")

            # ========== ç¬¬ä¸€æ­¥ï¼šå§‹ç»ˆç´¯ç§¯æ•°æ® ==========
            new_items = 0
            current_tool = state.get("current_tool", "unknown")

            if isinstance(last_result, dict):
                # æ£€æŸ¥æ˜¯å¦æ˜¯ extract_titles_from_structure çš„æ–°æ ¼å¼
                if current_tool == "extract_titles_from_structure" and "titles" in last_result:
                    # æ–°æ ¼å¼ï¼š{"titles": [...], "reason": "..."}
                    special_data = {
                        "type": "structured_info",
                        "tool": current_tool,
                        "data": last_result.get("titles", []),
                        "reason": last_result.get("reason", "")
                    }
                    retrieved_content.append(special_data)
                    new_items = 1
                    logger.info(f"ğŸ“ [Summary] ç´¯ç§¯ç»“æ„åŒ–ä¿¡æ¯: {current_tool}")
                    logger.info(f"ğŸ“ [Summary]   - æ ‡é¢˜æ•°: {len(last_result.get('titles', []))}")
                    logger.info(f"ğŸ“ [Summary]   - åŸå› : {last_result.get('reason', '')}")
                else:
                    # å¸¸è§„å†…å®¹æ£€ç´¢å·¥å…·è¿”å›çš„ dict
                    retrieved_content.append(last_result)
                    new_items = 1
            elif isinstance(last_result, list):
                # æ£€æŸ¥æ˜¯å¦æ˜¯ get_document_structure çš„ç»“æœï¼ˆè¿”å› List[str]ï¼‰
                if current_tool == "get_document_structure":
                    # è¿™ä¸ªå·¥å…·è¿”å›çš„æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œéœ€è¦åŒ…è£…æˆç‰¹æ®Šæ ¼å¼
                    if all(isinstance(x, str) for x in last_result) and len(last_result) > 0:
                        # åŒ…è£…æˆç‰¹æ®Šæ ‡è®°çš„ dict
                        special_data = {
                            "type": "structured_info",
                            "tool": current_tool,
                            "data": last_result
                        }
                        retrieved_content.append(special_data)
                        new_items = 1
                        logger.info(f"ğŸ“ [Summary] ç´¯ç§¯ç»“æ„åŒ–ä¿¡æ¯: {current_tool}, {len(last_result)} é¡¹")
                else:
                    # å¸¸è§„å·¥å…·è¿”å›çš„æ˜¯ List[dict]
                    for item in last_result:
                        if isinstance(item, dict):
                            retrieved_content.append(item)
                            new_items += 1

            state["retrieved_content"] = retrieved_content
            logger.info(f"ğŸ“ [Summary] æ–°å¢ {new_items} æ¡å†…å®¹ï¼Œæ€»è®¡ {len(retrieved_content)} æ¡")

            if not retrieved_content:
                logger.warning(f"âš ï¸  [Summary] æ— æ£€ç´¢å†…å®¹ï¼Œè·³è¿‡æ€»ç»“")
                state["intermediate_summary"] = "æœªæ£€ç´¢åˆ°ç›¸å…³å†…å®¹"
                return state

            # æ„å»ºæ ¼å¼åŒ–æ•°æ®
            formatted_data = []
            for idx, item in enumerate(retrieved_content, 1):
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç»“æ„åŒ–ä¿¡æ¯
                if isinstance(item, dict) and item.get("type") == "structured_info":
                    # ç»“æ„åŒ–ä¿¡æ¯ï¼ˆæ–‡æ¡£ç»“æ„æˆ–æ ‡é¢˜åˆ—è¡¨ï¼‰
                    tool_name = item.get("tool", "unknown")
                    data = item.get("data", [])
                    reason = item.get("reason", "")

                    formatted_item = {
                        "index": idx,
                        "type": "structured_info",
                        "tool": tool_name,
                        "data": data,
                        "title": f"[{tool_name}]",
                        "pages": [],
                        "content": "\n".join(data) if isinstance(data, list) else str(data)
                    }

                    # å¦‚æœæœ‰åŸå› è¯´æ˜ï¼Œä¹ŸåŠ å…¥
                    if reason:
                        formatted_item["reason"] = reason

                    formatted_data.append(formatted_item)
                else:
                    # å¸¸è§„å†…å®¹
                    formatted_data.append({
                        "index": idx,
                        "type": "content",
                        "title": item.get("title", ""),
                        "pages": item.get("pages", []),
                        "content": item.get("content", ""),
                        "raw_data": item.get("raw_data", {})  # ä¼ é€’åŸå§‹æ•°æ®
                    })

            state["formatted_data"] = formatted_data
            logger.info(f"ğŸ“ [Summary] æ ¼å¼åŒ– {len(formatted_data)} æ¡æ•°æ®")

            return state

            # ========== ä»¥ä¸‹ä»£ç å·²æ³¨é‡Šæ‰ ==========
#            if not requires_summary:
#                # ä¸éœ€è¦æ€»ç»“ï¼šä¿ç•™ä¹‹å‰çš„æ€»ç»“ï¼Œæˆ–ç”Ÿæˆç®€å•æè¿°
#                previous_summary = state.get("intermediate_summary", "")
#                if previous_summary:
#                    logger.info(f"ğŸ“ [Summary] ä¸éœ€è¦æ€»ç»“ï¼Œä¿ç•™ä¹‹å‰çš„æ€»ç»“ï¼ˆé•¿åº¦: {len(previous_summary)}ï¼‰")
#                else:
#                    # ç”Ÿæˆç®€å•æè¿°
#                    simple_summary = f"å·²ç´¯ç§¯ {len(retrieved_content)} æ¡æ£€ç´¢ç»“æœ"
#                    state["intermediate_summary"] = simple_summary
#                    logger.info(f"ğŸ“ [Summary] ä¸éœ€è¦æ€»ç»“ï¼Œç”Ÿæˆç®€å•æè¿°: {simple_summary}")
#
#                logger.info(f"âœ… [Summary] æ•°æ®ç´¯ç§¯å®Œæˆï¼ˆè·³è¿‡LLMæ€»ç»“ï¼‰")
#                return state
#
#            # éœ€è¦æ€»ç»“ï¼šè°ƒç”¨ LLM ç”Ÿæˆæ€»ç»“
#            logger.info(f"ğŸ“ [Summary] è°ƒç”¨ LLM ç”Ÿæˆæ€»ç»“...")
#
#            # æ„å»ºè¯¦ç»†çš„æ£€ç´¢å†…å®¹
#            content_parts = []
#            for idx, item in enumerate(formatted_data, 1):
#                # è·³è¿‡ç»“æ„åŒ–ä¿¡æ¯ï¼ˆå®ƒä»¬ä¸éœ€è¦æ€»ç»“ï¼‰
#                if item.get("type") == "structured_info":
#                    continue
#
#                # æ„å»ºå†…å®¹å—
#                title = item.get("title", "æœªçŸ¥ç« èŠ‚")
#                pages = item.get("pages", [])
#                content = item.get("content", "")
#
#                if pages:
#                    sorted_pages = sorted(pages, key=lambda x: int(x) if str(x).isdigit() else 0)
#                    page_info = f"é¡µç : {', '.join(map(str, sorted_pages))}"
#                else:
#                    page_info = "é¡µç : æœªçŸ¥"
#
#                content_block = f"""
### å†…å®¹ {idx}: {title} ({page_info})
#
#{content}
#"""
#                content_parts.append(content_block.strip())
#
#            # å¦‚æœæ²¡æœ‰å®é™…å†…å®¹ï¼ˆå…¨æ˜¯ç»“æ„åŒ–ä¿¡æ¯ï¼‰ï¼Œä½¿ç”¨ç®€å•æè¿°
#            if not content_parts:
#                state["intermediate_summary"] = f"å·²ç´¯ç§¯ {len(retrieved_content)} æ¡æ£€ç´¢ç»“æœ"
#                logger.info(f"ğŸ“ [Summary] æ— å®é™…å†…å®¹éœ€è¦æ€»ç»“ï¼Œä½¿ç”¨ç®€å•æè¿°")
#                return state
#
#            # æ„å»ºå®Œæ•´çš„ prompt
#            all_content = "\n\n".join(content_parts)
#            prompt = f"""è¯·å¯¹ä»¥ä¸‹ {len(content_parts)} æ¡æ£€ç´¢å†…å®¹è¿›è¡Œæ€»ç»“ï¼š
#
#{all_content}
#
#---
#
#è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚æ€»ç»“ï¼š
#1. ä¿ç•™å…³é”®ä¿¡æ¯ã€é‡è¦æ•°æ®ã€æ ¸å¿ƒæ¦‚å¿µ
#2. æŒ‰ç« èŠ‚ç»„ç»‡ï¼Œæ ‡æ³¨é¡µç æ¥æº
#3. ä½¿ç”¨ Markdown æ ¼å¼ï¼Œå±‚æ¬¡æ¸…æ™°
#"""
#
#            logger.info(f"ğŸ“ [Summary] å‡†å¤‡æ€»ç»“ {len(content_parts)} æ¡å†…å®¹ï¼Œæ€»é•¿åº¦: {len(all_content)} å­—ç¬¦")
#
#            session_id = f"summary_{state.get('doc_name', 'default')}"
#            summary = await self.agent.llm.async_call_llm_chain(
#                role=RetrievalRole.CONTEXT_SUMMARIZER,
#                input_prompt=prompt,
#                session_id=session_id
#            )
#
#            state["intermediate_summary"] = summary
#
#            logger.info(f"âœ… [Summary] æ€»ç»“å®Œæˆï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")
#            logger.info(f"ğŸ“ [Summary] æ€»ç»“é¢„è§ˆ: {summary[:200]}...")
#            return state
#
        except Exception as e:
            logger.error(f"âŒ [Summary] å¤±è´¥: {e}", exc_info=True)
            state["intermediate_summary"] = "æ€»ç»“å¤±è´¥"
            return state

    async def evaluate(self, state: RetrievalState) -> Dict:
        """è¯„ä¼°æ£€ç´¢ç»“æœ"""

        logger.info(f"âš–ï¸ [Evaluate] ========== æ­¥éª¤4: è¯„ä¼°æ£€ç´¢ç»“æœ ==========")

        try:
            formatted_data = state.get("formatted_data", [])
            current_iteration = state.get("current_iteration", 0)
            max_iterations = state.get("max_iterations", ProcessingLimits.MAX_RETRIEVAL_ITERATIONS)
            original_query = state["query"]

            logger.info(f"âš–ï¸ [Evaluate] è¾“å…¥:")
            logger.info(f"âš–ï¸ [Evaluate]   - ç”¨æˆ·æŸ¥è¯¢: {original_query}")
            logger.info(f"âš–ï¸ [Evaluate]   - æ ¼å¼åŒ–æ•°æ®æ•°: {len(formatted_data)}")
            logger.info(f"âš–ï¸ [Evaluate]   - å½“å‰è¿­ä»£: {current_iteration}/{max_iterations}")

            if not formatted_data:
                logger.warning(f"âš ï¸  [Evaluate] æ— æ£€ç´¢å†…å®¹ï¼Œåˆ¤æ–­ä¸ºä¸å®Œæ•´")
                state["is_complete"] = False
                state["reason"] = "æ— æ£€ç´¢å†…å®¹ï¼Œç»§ç»­æ£€ç´¢"
                logger.info(f"âš–ï¸ [Evaluate] è¾“å‡º: is_complete=False, reason='{state['reason']}'")
                return state

            # æ„å»ºæ£€ç´¢å†…å®¹æ‘˜è¦ï¼ˆç« èŠ‚æ ‡é¢˜ + é¡µç ï¼Œä¸åŒ…å«å®Œæ•´å†…å®¹ï¼‰
            content_summary_parts = []
            for idx, item in enumerate(formatted_data, 1):
                if item.get("type") == "structured_info":
                    # ç»“æ„åŒ–ä¿¡æ¯
                    tool_name = item.get("tool", "unknown")
                    data = item.get("data", [])
                    if tool_name == "extract_titles_from_structure":
                        reason = item.get("reason", "")
                        content_summary_parts.append(f"{idx}. å·²æå–æ ‡é¢˜: {data} ({reason})")
                    else:
                        content_summary_parts.append(f"{idx}. {tool_name}: {len(data)} é¡¹")
                else:
                    # å®é™…å†…å®¹
                    title = item.get("title", "æœªçŸ¥ç« èŠ‚")
                    pages = item.get("pages", [])
                    content_length = len(item.get("content", ""))
                    page_info = f"é¡µç : {pages}" if pages else "æ— é¡µç "
                    content_summary_parts.append(f"{idx}. {title} ({page_info}, {content_length} å­—ç¬¦)")

            content_summary = "\n".join(content_summary_parts)

            logger.info(f"âš–ï¸ [Evaluate] æ„å»ºæ£€ç´¢å†…å®¹æ‘˜è¦:")
            logger.info(f"{content_summary}")

            logger.info(f"âš–ï¸ [Evaluate] è°ƒç”¨ LLM è¯„ä¼°æ£€ç´¢å®Œæ•´æ€§...")
            prompt = f"""ç”¨æˆ·æŸ¥è¯¢: {original_query}

å·²æ£€ç´¢çš„å†…å®¹æ‘˜è¦:
{content_summary}

è¯„ä¼°è¿™äº›æ£€ç´¢å†…å®¹æ˜¯å¦è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚è¿”å›JSONï¼š
{{"is_complete": true/false, "reason": "..."}}

åˆ¤æ–­æ ‡å‡†ï¼š
- å¦‚æœæ£€ç´¢åˆ°çš„ç« èŠ‚/å†…å®¹èƒ½å¤Ÿå›ç­”é—®é¢˜çš„æ ¸å¿ƒï¼Œè¿”å› true
- å¦‚æœè¿˜ç¼ºå°‘å…³é”®ä¿¡æ¯ï¼Œè¿”å› false å¹¶è¯´æ˜ç¼ºå°‘ä»€ä¹ˆ
"""

            session_id = f"evaluate_{state.get('doc_name', 'default')}"
            response = await self.agent.llm.async_call_llm_chain(
                role=RetrievalRole.RETRIEVAL_EVALUATOR,
                input_prompt=prompt,
                session_id=session_id
            )

            logger.info(f"âš–ï¸ [Evaluate] LLM å“åº”: {response[:200]}...")

            evaluation = json.loads(response.strip()) if response.strip().startswith('{') else {}
            is_complete = evaluation.get("is_complete", False)
            reason = evaluation.get("reason", "")

            state["is_complete"] = is_complete
            state["reason"] = reason

            logger.info(f"âš–ï¸ [Evaluate] è¯„ä¼°ç»“æœ:")
            logger.info(f"âš–ï¸ [Evaluate]   - æ˜¯å¦å®Œæ•´: {is_complete}")
            logger.info(f"âš–ï¸ [Evaluate]   - åˆ¤æ–­ç†ç”±: {reason}")

            if is_complete:
                logger.info(f"âœ… [Evaluate] æ£€ç´¢å®Œæˆï¼Œå‡†å¤‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
            else:
                logger.info(f"ğŸ”„ [Evaluate] æ£€ç´¢æœªå®Œæˆï¼Œå°†ç»§ç»­ä¸‹ä¸€è½®")

            return state

        except Exception as e:
            logger.error(f"âŒ [Evaluate] å¤±è´¥: {e}", exc_info=True)
            is_complete_fallback = current_iteration >= state.get("max_iterations", ProcessingLimits.MAX_RETRIEVAL_ITERATIONS)
            state["is_complete"] = is_complete_fallback
            state["reason"] = f"è¯„ä¼°å¤±è´¥ï¼ŒåŸºäºè¿­ä»£æ¬¡æ•°åˆ¤æ–­: {is_complete_fallback}"
            logger.info(f"âš ï¸  [Evaluate] é”™è¯¯å›é€€: is_complete={is_complete_fallback}")
            return state

    async def format(self, state: RetrievalState) -> Dict:
        """ç”Ÿæˆæœ€ç»ˆç²¾å‡†æ€»ç»“"""

        logger.info(f"ğŸ¯ [Format] ========== æ­¥éª¤5: ç”Ÿæˆæœ€ç»ˆæ€»ç»“ ==========")

        try:
            formatted_data = state.get("formatted_data", [])
            intermediate_summary = state.get("intermediate_summary", "")
            original_query = state["query"]

            logger.info(f"ğŸ¯ [Format] è¾“å…¥:")
            logger.info(f"ğŸ¯ [Format]   - ç”¨æˆ·æŸ¥è¯¢: {original_query}")
            logger.info(f"ğŸ¯ [Format]   - æ ¼å¼åŒ–æ•°æ®æ•°: {len(formatted_data)}")
            #logger.info(f"ğŸ¯ [Format]   - ä¸­é—´æ€»ç»“é•¿åº¦: {len(intermediate_summary)} å­—ç¬¦")

            if not formatted_data:
                logger.warning(f"âš ï¸  [Format] æ— æ ¼å¼åŒ–æ•°æ®ï¼Œä½¿ç”¨ä¸­é—´æ€»ç»“ä½œä¸ºæœ€ç»ˆç­”æ¡ˆ")
                #state["final_summary"] = intermediate_summary
                #logger.info(f"ğŸ¯ [Format] è¾“å‡º: ä½¿ç”¨ä¸­é—´æ€»ç»“ (é•¿åº¦: {len(intermediate_summary)})")
                return state

            # æ„å»ºæœ€ç»ˆæ€»ç»“
            logger.info(f"ğŸ¯ [Format] è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆç²¾å‡†ç­”æ¡ˆ...")

            # ========== æ­¥éª¤1: å»é‡å’Œåˆå¹¶ raw_data ==========
            # ä½¿ç”¨ raw_data è€Œä¸æ˜¯ contentï¼ˆrefactor_dataï¼‰
            # æŒ‰é¡µç å»é‡ï¼šåŒä¸€é¡µåªä¿ç•™ä¸€æ¬¡
            all_raw_pages = {}  # {page_num: {"title": str, "content": str}}

            for item in formatted_data:
                # è·³è¿‡ç»“æ„åŒ–ä¿¡æ¯ï¼ˆå®ƒä»¬ä¸æ˜¯å®é™…å†…å®¹ï¼‰
                if item.get("type") == "structured_info":
                    continue

                title = item.get("title", "æœªçŸ¥ç« èŠ‚")
                raw_data = item.get("raw_data", {})
                pages = item.get("pages", [])
                content = item.get("content", "")

                # ä¼˜å…ˆä½¿ç”¨ raw_dataï¼Œå¦‚æœæ²¡æœ‰åˆ™ fallback åˆ° content
                if isinstance(raw_data, dict) and raw_data:
                    # éå†æ¯ä¸€é¡µçš„åŸå§‹æ•°æ®
                    for page_num, page_content in raw_data.items():
                        # å»é‡ï¼šåŒä¸€é¡µåªä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„å†…å®¹
                        if page_num not in all_raw_pages:
                            all_raw_pages[page_num] = {
                                "title": title,
                                "content": page_content
                            }
                elif content:
                    # Fallback: å¦‚æœæ²¡æœ‰ raw_dataï¼Œä½¿ç”¨ contentï¼ˆrefactor_dataï¼‰
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªé¡µç ä½œä¸º keyï¼ˆæˆ–ä½¿ç”¨ "unknown" å¦‚æœæ²¡æœ‰é¡µç ï¼‰
                    page_key = pages[0] if pages else f"unknown_{title}"
                    if page_key not in all_raw_pages:
                        all_raw_pages[page_key] = {
                            "title": title,
                            "content": content
                        }

            logger.info(f"ğŸ¯ [Format] å»é‡åå…± {len(all_raw_pages)} é¡µåŸå§‹å†…å®¹")

            # ========== æ­¥éª¤2: æ„å»ºæ£€ç´¢å†…å®¹è¯¦æƒ… ==========
            content_parts = []

            # æŒ‰é¡µç æ’åº
            sorted_pages = sorted(all_raw_pages.keys(), key=lambda x: int(x) if str(x).isdigit() else 0)

            for idx, page_num in enumerate(sorted_pages, 1):
                page_data = all_raw_pages[page_num]
                title = page_data["title"]
                content = page_data["content"]

                content_block = f"""
## å†…å®¹ {idx}: {title} (é¡µç : {page_num})

{content}
"""
                content_parts.append(content_block.strip())

            # å¦‚æœæ²¡æœ‰å®é™…å†…å®¹ï¼Œä½¿ç”¨ä¸­é—´æ€»ç»“
            if not content_parts:
                logger.warning(f"âš ï¸  [Format] æ— å®é™…å†…å®¹ï¼Œä½¿ç”¨ä¸­é—´æ€»ç»“ä½œä¸ºæœ€ç»ˆç­”æ¡ˆ")
                #state["final_summary"] = intermediate_summary
                #logger.info(f"ğŸ¯ [Format] è¾“å‡º: ä½¿ç”¨ä¸­é—´æ€»ç»“ (é•¿åº¦: {len(intermediate_summary)})")
                return state

            # æ„å»ºå®Œæ•´çš„ prompt
            all_content = "\n\n".join(content_parts)

            prompt = f"""# ç”¨æˆ·æŸ¥è¯¢

{original_query}

# æ£€ç´¢åˆ°çš„å†…å®¹

{all_content}

---

# ä»»åŠ¡

åŸºäºä»¥ä¸Šæ£€ç´¢å†…å®¹ï¼Œç”Ÿæˆç²¾å‡†ã€å®Œæ•´çš„ç­”æ¡ˆæ¥å›ç­”ç”¨æˆ·æŸ¥è¯¢ã€‚

è¦æ±‚ï¼š
1. ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œèšç„¦äºæŸ¥è¯¢çš„æ ¸å¿ƒ
2. åŸºäºæ£€ç´¢å†…å®¹çš„äº‹å®å’Œæ•°æ®ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
3. ä¿ç•™é‡è¦çš„ç»†èŠ‚ã€æ•°æ®ã€å…¬å¼ç­‰å…³é”®ä¿¡æ¯
4. æ ‡æ³¨ä¿¡æ¯æ¥æºï¼ˆç« èŠ‚å’Œé¡µç ï¼‰
5. ä½¿ç”¨æ¸…æ™°çš„ Markdown æ ¼å¼ç»„ç»‡ç­”æ¡ˆ
6. å¦‚æœæ£€ç´¢å†…å®¹ä¸è¶³ä»¥å®Œå…¨å›ç­”é—®é¢˜ï¼Œæ˜ç¡®è¯´æ˜
"""

            logger.info(f"ğŸ¯ [Format] å‡†å¤‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼Œå†…å®¹æ•°: {len(content_parts)}ï¼Œæ€»é•¿åº¦: {len(all_content)} å­—ç¬¦")

            session_id = f"format_{state.get('doc_name', 'default')}"
            final_summary = await self.agent.llm.async_call_llm_chain(
                role=RetrievalRole.CONTEXT_SUMMARIZER,
                input_prompt=prompt,
                session_id=session_id
            )

            state["final_summary"] = final_summary
            logger.info(f"âœ… [Format] æœ€ç»ˆç­”æ¡ˆç”Ÿæˆå®Œæˆ")
            logger.info(f"ğŸ¯ [Format]   - ç­”æ¡ˆé•¿åº¦: {len(final_summary)} å­—ç¬¦")
            logger.info(f"ğŸ¯ [Format]   - ç­”æ¡ˆé¢„è§ˆ: {final_summary[:200]}...")
            return state

        except Exception as e:
            logger.error(f"âŒ [Format] å¤±è´¥: {e}", exc_info=True)
            #intermediate_summary = state.get("intermediate_summary", "")
            #state["final_summary"] = intermediate_summary
            #logger.info(f"âš ï¸  [Format] é”™è¯¯å›é€€: ä½¿ç”¨ä¸­é—´æ€»ç»“ (é•¿åº¦: {len(intermediate_summary)})")
            return state

    def should_continue(self, state: RetrievalState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­æ£€ç´¢"""
        current_iter = state.get("current_iteration", 0)
        max_iter = state.get("max_iterations", ProcessingLimits.MAX_RETRIEVAL_ITERATIONS)

        # æ·»åŠ è¯¦ç»†æ—¥å¿—ä»¥ä¾¿è°ƒè¯•
        logger.info(f"ğŸ” [ShouldContinue] æ£€æŸ¥è¿­ä»£çŠ¶æ€: current={current_iter}, max={max_iter}, is_complete={state.get('is_complete', False)}")

        if state.get("is_complete", False):
            logger.info(f"âœ… [ShouldContinue] æ£€ç´¢å®Œæˆï¼Œç»“æŸå¾ªç¯")
            return "finish"

        if current_iter >= max_iter:
            logger.warning(f"âš ï¸  [ShouldContinue] è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({max_iter})ï¼Œç»“æŸå¾ªç¯")
            return "finish"

        logger.info(f"ğŸ”„ [ShouldContinue] ç»§ç»­ä¸‹ä¸€è½®æ£€ç´¢ (ç¬¬ {current_iter + 1}/{max_iter} è½®)")
        return "continue"
