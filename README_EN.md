# AgenticReader

[ä¸­æ–‡](README.md) | English

AgenticReader is an advanced document analysis and intelligent Q&A tool powered by large language models (LLM) and Multi-Agent architecture. Built on Agent orchestration patterns, focused on **deep PDF document parsing**, integrates multiple LLM providers (Azure OpenAI, OpenAI, Ollama, Gemini), and automatically extracts content, generates summaries, builds vector databases, and supports multi-turn intelligent conversations. Offers both **CLI command-line** and **Web interface** modes.

---

## Key Features | Core Capabilities

### ğŸ¤– Multi-Agent Architecture | Multi-Agent System
- **IndexingAgent**: Document indexing agent for PDF parsing, structure extraction, chunking, vectorization
- **AnswerAgent**: Q&A agent for intent analysis, answer generation, dialogue management
- **RetrievalAgent**: Retrieval agent for semantic search and context assembly
- **LangGraph Orchestration**: State machine workflow based on LangGraph, supports complex task orchestration

### ğŸ“„ Document Processing | Document Processing
- **Smart Indexing**: PDF to image + OCR content extraction
- **Structure Analysis**: Auto-detect document structure and chapter organization
- **Chunking**: Intelligent text splitting with chapter-level organization
- **Vector Database**: Efficient semantic search based on FAISS
- **Parallel Processing**: Async parallel chapter processing, significantly improved speed
- **Incremental Caching**: Stage-wise caching to avoid reprocessing

### ğŸ’¬ Intelligent Q&A | Intelligent Q&A
- **Four Dialogue Modes**:
  - Single Document Mode - Deep Q&A for specific documents
  - Cross-Document Intelligent Mode - Auto-select relevant documents for retrieval
  - Cross-Document Manual Mode - Manually specify multiple documents as background knowledge
  - General Mode - Free conversation without binding to specific documents
- **Intent Recognition**: Auto-determine if document retrieval is needed
- **Context Management**: Smart caching of retrieval results for multi-turn dialogue
- **History Compression**: LLM auto-summarizes conversation history, saves context space (90%+ compression rate)
- **Document Summary**: Auto-generate brief summaries (brief_summary.md)

### ğŸŒ Dual Operation Modes | Dual Operation Modes
- **CLI Command-line Mode**:
  - Interactive menu system supporting document indexing, management, and dialogue
  - Free switching between four dialogue modes
  - Real-time view of document selection and retrieval process
  - Suitable for technical users and automation scenarios
- **Web Interface Mode**:
  - **Dashboard**: Document overview, quick indexing, mode selection
  - **Smart Chat**: WebSocket real-time communication, supports Markdown/LaTeX rendering
  - **Session Management**: Three modes with independent session storage, support import/export
  - **Data Management**: Granular data control with partial deletion, batch operations, smart cleanup
  - **Configuration Center**: LLM provider switching, parameter adjustment
  - **Responsive Design**: Mobile-friendly adaptive interface

---

## Quick Start | Quick Start

### Requirements | Requirements
- Python 3.12+
- Virtual environment (recommended)

<details>
<summary><b>ğŸ“¦ Installation & Configuration (Click to expand)</b></summary>

### Installation Steps

```bash
# 1. Clone repository
git clone <repository-url>
cd AgenticReader

# 2. Install Python dependencies
pip install -r requirements.txt

# 3. Create data directories
mkdir -p data/pdf data/pdf_image data/json_data data/vector_db data/output data/sessions data/sessions/backups data/sessions/exports

# 4. Configure environment variables (create .env file)
# See "Configuration" section below
```

### Configuration

Create a `.env` file in the project root:

```bash
# === LLM Service Configuration ===
# Azure OpenAI
CHAT_API_KEY=your_azure_api_key
CHAT_AZURE_ENDPOINT=https://your-endpoint.openai.azure.com/
CHAT_DEPLOYMENT_NAME=your_deployment_name
CHAT_API_VERSION=2024-02-15-preview
CHAT_MODEL_NAME=gpt-4

# Embedding Configuration
EMBEDDING_API_KEY=your_embedding_api_key
EMBEDDING_MODEL=text-embedding-ada-002

# === Or use OpenAI ===
# CHAT_API_KEY=your_openai_api_key
# CHAT_MODEL_NAME=gpt-4
# OPENAI_BASE_URL=https://api.openai.com/v1/

# === Or use Ollama (Local) ===
# OLLAMA_BASE_URL=http://localhost:11434
# CHAT_MODEL_NAME=llama3

# === Or use Gemini (Google) ===
# GEMINI_API_KEY=your_gemini_api_key
# GEMINI_MODEL_NAME=gemini-1.5-pro
# GEMINI_EMBEDDING_MODEL=text-embedding-004
# GEMINI_BASE_URL=your_gemini_api_endpoint

# === Optional Configuration ===
LOGGING_LEVEL=INFO
```

</details>

### Running the Application | Running the Application

#### Method 1: Web Interface (Recommended)

```bash
# Start FastAPI server
python src/ui/run_server.py

# Or use uvicorn (supports auto-reload)
uvicorn src.ui.backend.app:app --reload --host 0.0.0.0 --port 8000

# Access: http://localhost:8000
```

**ğŸ“Š Dashboard (/) - Main Menu**
- Document list and overview
- Quick indexing (batch/single)
- Mode selection (Single/Cross/Manual)
- Quick access to chat page

**ğŸ’¬ Chat Page (/chat) - Intelligent Dialogue**

Three chat modes:
- **Single Mode**: Select specific document for deep Q&A
- **Cross Mode**: Auto-select relevant documents (intelligent decision)
- **Manual Mode**: Manually specify multiple documents as background

Features:
- WebSocket real-time communication
- Markdown and LaTeX formula rendering
- Timestamp display (year/month/day hour:minute:second)
- Session persistence (three modes independently managed)
- Clear history (clears both file and memory)
- Display selected documents and similarity scores

**ğŸ“ Data Management (/data) - Documents & Sessions**

Document Management:
- View all indexed documents and storage usage
- **Granular partial deletion**: Delete specific data types for individual documents
  - JSON data, Vector DB, Images, Summary
- Batch operations: Select multiple documents for deletion
- Smart cleanup: Auto-clean data older than N days (default 30)

Session Management:
- View all mode sessions (Single/Cross/Manual)
- Session detail view (Markdown/LaTeX rendering support)
- Delete specific sessions
- Import/export session data

**âš™ï¸ Configuration Center (/config) - LLM Settings**
- Switch LLM providers (Azure OpenAI, OpenAI, Ollama, Gemini)
- Adjust model parameters
- API Key management

**ğŸ”§ Structure Editor (/structure) - Document Structure**
- View and edit document chapter structure
- PDF online preview
- Rebuild vector database

---

#### Method 2: CLI Command-line Mode

```bash
# Start interactive CLI
python main.py
```

**Four Dialogue Modes:**

1. **Single Mode** - Select specific document
   ```
   [Single (doc.pdf)] ğŸ‘¤ Query: What is this document about?
   ğŸ¤– Assistant: This document discusses...
   ```

2. **Cross Mode** - Auto-select relevant documents
   ```
   [Cross Mode] ğŸ‘¤ Query: Compare the viewpoints
   ğŸ“š Selected Documents (2):
      - doc1.pdf (similarity: 0.856)
      - doc2.pdf (similarity: 0.742)
   ğŸ¤– Assistant: Based on retrieval...
   ```

3. **Manual Mode** - Manually select multiple documents
   ```
   Select documents: 1,2 (or 'all')
   [Manual (2 docs)] ğŸ‘¤ Query: Summarize both
   ğŸ¤– Assistant: Comprehensive summary...
   ```

4. **General Mode** - Free conversation
   ```
   [General Mode] ğŸ‘¤ Query: What is machine learning?
   ğŸ¤– Assistant: Machine learning is...
   ```

**Commands:**
- `i` - Index new document
- `m` - Manage documents (view/delete)
- `clear` - Clear conversation history
- `switch` - Switch mode
- `main` - Return to main menu
- `quit`/`exit` - Exit program

---

<details>
<summary><b>ğŸ“ Project Structure (Click to expand)</b></summary>

```
AgenticReader/
â”œâ”€â”€ main.py                        # CLI entry (uses AnswerAgent)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                    # ğŸ¤– Multi-Agent System
â”‚   â”‚   â”œâ”€â”€ indexing/              # IndexingAgent - Document indexing
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py           # Indexing agent implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ state.py           # Indexing state definition
â”‚   â”‚   â”‚   â””â”€â”€ doc_registry.py    # Document registry
â”‚   â”‚   â”œâ”€â”€ answer/                # AnswerAgent - Intelligent Q&A
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py           # Answer agent implementation
â”‚   â”‚   â”‚   â””â”€â”€ state.py           # Answer state definition
â”‚   â”‚   â””â”€â”€ retrieval/             # RetrievalAgent - Document retrieval
â”‚   â”‚       â”œâ”€â”€ agent.py           # Retrieval agent implementation
â”‚   â”‚       â””â”€â”€ state.py           # Retrieval state definition
â”‚   â”œâ”€â”€ core/                      # Core functionality
â”‚   â”‚   â”œâ”€â”€ llm/                   # LLM abstraction layer
â”‚   â”‚   â”‚   â”œâ”€â”€ client.py          # Unified LLM client
â”‚   â”‚   â”‚   â”œâ”€â”€ providers.py       # Multi-provider support
â”‚   â”‚   â”‚   â””â”€â”€ history.py         # Conversation history management
â”‚   â”‚   â”œâ”€â”€ vector_db/             # Vector database
â”‚   â”‚   â”‚   â””â”€â”€ vector_db_client.py
â”‚   â”‚   â””â”€â”€ processing/            # Document processing tools
â”‚   â”‚       â”œâ”€â”€ index_document.py  # Document indexing entry
â”‚   â”‚       â”œâ”€â”€ manage_documents.py # Document management tools
â”‚   â”‚       â”œâ”€â”€ parallel_processor.py # Parallel processor
â”‚   â”‚       â””â”€â”€ text_splitter.py   # Text splitter
â”‚   â”œâ”€â”€ config/                    # Configuration management
â”‚   â”‚   â”œâ”€â”€ settings.py            # Global configuration
â”‚   â”‚   â”œâ”€â”€ prompts/               # Prompt templates
â”‚   â”‚   â””â”€â”€ tools/                 # Agent tool definitions
â”‚   â”œâ”€â”€ services/                  # External services
â”‚   â”‚   â””â”€â”€ mcp_client.py          # MCP client (retained)
â”‚   â”œâ”€â”€ ui/                        # Web Interface
â”‚   â”‚   â”œâ”€â”€ run_server.py          # FastAPI startup script
â”‚   â”‚   â”œâ”€â”€ backend/               # Backend API
â”‚   â”‚   â”‚   â”œâ”€â”€ app.py             # FastAPI application
â”‚   â”‚   â”‚   â”œâ”€â”€ api/v1/            # API endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pdf.py         # PDF processing (uses IndexingAgent)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chapters.py    # Chapter viewing
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py        # WebSocket chat
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ data.py        # Data management
â”‚   â”‚   â”‚   â””â”€â”€ services/          # Service layer
â”‚   â”‚   â”‚       â”œâ”€â”€ chat_service.py # Chat service (uses AnswerAgent)
â”‚   â”‚   â”‚       â”œâ”€â”€ session_service.py # Session management
â”‚   â”‚   â”‚       â””â”€â”€ data_service.py    # Data management
â”‚   â”‚   â”œâ”€â”€ templates/             # Jinja2 templates
â”‚   â”‚   â””â”€â”€ static/                # Static resources
â”‚   â””â”€â”€ utils/                     # Utility functions
â”œâ”€â”€ data/                          # Data directory
â”‚   â”œâ”€â”€ pdf/                       # PDF source files
â”‚   â”œâ”€â”€ pdf_image/                 # PDF to images
â”‚   â”œâ”€â”€ json_data/                 # Document data (organized by doc name)
â”‚   â”‚   â””â”€â”€ {doc_name}/            # Document data folder
â”‚   â”‚       â”œâ”€â”€ data.json          # Raw extracted data
â”‚   â”‚       â”œâ”€â”€ structure.json     # Document structure
â”‚   â”‚       â””â”€â”€ chunks.json        # Chunked data
â”‚   â”œâ”€â”€ vector_db/                 # Vector database
â”‚   â”œâ”€â”€ output/                    # Generated summary files
â”‚   â”œâ”€â”€ sessions/                  # Session data
â”‚   â”‚   â”œâ”€â”€ backups/               # Session backups
â”‚   â”‚   â””â”€â”€ exports/               # Session exports
â”‚   â””â”€â”€ doc_registry.json          # Document registry
â””â”€â”€ requirements.txt               # Python dependencies
```

</details>

---

<details>
<summary><b>ğŸ—ï¸ Technical Architecture (Click to expand)</b></summary>

### Core Components

1. **Multi-Agent System** (src/agents/)
   - **IndexingAgent**: Document indexing workflow
     - Parse PDF â†’ Extract structure â†’ Chunk â†’ Parallel process â†’ Vectorize â†’ Register
   - **AnswerAgent**: Intelligent Q&A workflow
     - Analyze intent â†’ Retrieval decision â†’ Generate answer â†’ Evaluate result
   - **RetrievalAgent**: Document retrieval workflow
     - Semantic search â†’ Context assembly â†’ Result ranking

2. **LLM Abstraction** (src/core/llm/)
   - Unified interface supporting multiple providers (Azure OpenAI, OpenAI, Ollama)
   - Role-based prompt management
   - Session context auto-handling
   - Intelligent conversation history compression

3. **Vector Database** (src/core/vector_db/)
   - FAISS vector storage
   - Semantic similarity search
   - Chapter metadata management
   - Auto-load existing indexes

4. **Document Registry** (src/agents/indexing/doc_registry.py)
   - Centralized document metadata management
   - Track processing stage status
   - Record generated file paths
   - Support incremental indexing

5. **Web UI** (src/ui/)
   - FastAPI + WebSocket real-time communication
   - AnswerAgent-based chat service
   - IndexingAgent-based document processing
   - Data management system (granular control)

### Agent Workflows

#### IndexingAgent Workflow
```
PDF File
  â†’ check_cache (Check stage-wise caching)
  â†’ parse_document (Parse PDF)
  â†’ extract_structure (Extract document structure)
  â†’ chunk_text (Text chunking)
  â†’ process_chapters (Parallel process chapters)
  â†’ build_index (Build vector database)
  â†’ generate_brief_summary (Generate summary)
  â†’ register_document (Register to DocumentRegistry)
```

#### AnswerAgent Workflow
```
User Query
  â†’ analyze_intent (Intent analysis)
  â†’ retrieve_if_needed (Conditional retrieval)
  â†’ generate_answer (Generate answer)
  â†’ evaluate_result (Evaluate completeness)
  â†’ Return to user
```

### Data Storage Architecture

**JSON Data** (organized by document):
```
data/json_data/{doc_name}/
â”œâ”€â”€ data.json           # Raw extracted data
â”œâ”€â”€ structure.json      # Document structure info
â””â”€â”€ chunks.json         # Chunked data
```

**Advantages**:
- ğŸ“ All JSON files centralized in document folder
- ğŸ—‘ï¸ Direct folder deletion when removing, no file omissions
- ğŸ” Easy to find and manage specific document data

</details>

---

<details>
<summary><b>ğŸ› ï¸ Development Guide (Click to expand)</b></summary>

### Adding New LLM Providers
1. Add provider implementation in `src/core/llm/providers.py`
2. Add configuration in `LLM_CONFIG` in `src/config/settings.py`
3. Update provider switching logic

### Adding New Agents
1. Create new agent directory under `src/agents/`
2. Create `agent.py` (inherit AgentBase) and `state.py` (define TypedDict)
3. Implement `build_graph()` method to define workflow
4. Integrate calls in other Agents

### Extending IndexingAgent
1. Add new processing nodes in `agent.py`
2. Connect new nodes in `build_graph()`
3. Update `IndexingState` to add new fields
4. Implement cache checking logic

### Extending Web API
1. Create new route file in `src/ui/backend/api/v1/`
2. Use Agents instead of directly calling processing logic
3. Register route in `src/ui/backend/app.py`
4. Follow RESTful conventions and FastAPI best practices

### Extending Data Management Features
1. Add new data types in `DataService.delete_document_data()`
2. Update `data_type_paths` dictionary mapping
3. Add corresponding endpoints in API
4. Display new types in frontend `renderDataDetail()`

### Debugging Tips
```bash
# Enable DEBUG logging
export LOGGING_LEVEL=DEBUG
python main.py

# FastAPI development mode (auto-reload)
uvicorn src.ui.backend.app:app --reload --host 0.0.0.0 --port 8000

# View API documentation
# http://localhost:8000/docs

# Test Agents
python -c "from src.agents.indexing import IndexingAgent; print('OK')"
python -c "from src.agents.answer import AnswerAgent; print('OK')"
```

</details>

---

<details>
<summary><b>â“ FAQ (Click to expand)</b></summary>

### 1. PDF file not recognized?
- Ensure file is placed in `data/pdf/` directory
- Check filename spelling is correct
- Supported format: `.pdf`

### 2. Indexing failed?
- Check LLM API configuration is correct
- Confirm network connection is normal
- View log output to locate errors
- Try using `LOGGING_LEVEL=DEBUG` for detailed info

### 3. How to manage conversation history?
- Automatically managed by `LLMBase.message_histories`
- LLM auto-summarizes history to save context
- Web interface supports viewing and clearing history

### 4. How to view indexed documents?
```bash
# CLI mode
python main.py
# Select 'm' to enter document management

# Web mode
Visit http://localhost:8000/data
```

### 5. How to delete documents?
```bash
# CLI mode
python -m src.core.processing.manage_documents

# Web mode
Visit http://localhost:8000/data
# Use granular deletion features
```

### 6. Session data lost, how to recover?
- Visit `data/sessions/backups/` directory
- Use web interface import function to restore backups
- Backup files named by timestamp, keeps max 10

### 7. How to switch LLM providers?
```bash
# Modify .env file
CHAT_API_KEY=your_api_key
CHAT_MODEL_NAME=your_model

# Or switch in web interface configuration page
```

### 8. How to clean old data to free space?
- Visit `http://localhost:8000/data` to enter data management interface
- Use "Smart Cleanup" to auto-clean data older than 30 days
- Or manually select documents and delete specific data types (e.g., delete images only)

### 9. How to recover accidentally deleted data?
- Session data can be recovered from `data/sessions/backups/`
- Document data recommended to use "Data Backup" feature regularly
- Backup files saved in `data/backups/` directory

### 10. IndexingAgent vs Old Reader?
- âœ… **IndexingAgent** (New): LangGraph-based state machine workflow, supports caching, incremental processing, stage tracking
- âŒ **PDFReader/WebReader** (Removed): Old class inheritance architecture, completely removed

</details>

---

<details>
<summary><b>ğŸ“ Changelog (Click to expand)</b></summary>

### 2026-01-29 - Batch Indexing and Session Management Enhancements
- ğŸ› **Batch Indexing Fixes**
  - âœ… Fixed concurrent write race condition during batch PDF indexing
  - âœ… Enhanced DocumentRegistry concurrent safety (reload-before-save pattern)
  - âœ… Ensured all documents register correctly when indexing multiple PDFs simultaneously
  - âœ… Added `update_metadata()` method for safe metadata updates
- ğŸ’¬ **Session Management Optimization**
  - âœ… Fixed chat history clearing (clears both file and memory)
  - âœ… Re-instantiate AnswerAgent and RetrievalAgent when clearing history
  - âœ… Fixed memory-file synchronization (update `current_session` to prevent stale data)
  - âœ… Fixed single-mode session detail loading (support session_id lookup)
- ğŸ¨ **UI Enhancements**
  - âœ… Added timestamp display to all chat modes (format: year/month/day hour:minute:second)
  - âœ… Session detail modal supports Markdown and LaTeX rendering
  - âœ… Historical messages display original timestamps (not current time)
- ğŸ”§ **Code Improvements**
  - âœ… Unified AnswerAgent initialization parameters (only uses `doc_name`)
  - âœ… Enhanced data consistency guarantees in concurrent environments

### 2026-01-17 - Major Architecture Refactor: Migration to Multi-Agent System
- ğŸ—ï¸ **Architecture Refactor**
  - âœ… Completely removed old Reader architecture (PDFReader, WebReader, ReaderBase)
  - âœ… All functionality migrated to Multi-Agent architecture (IndexingAgent, AnswerAgent, RetrievalAgent)
  - âœ… LangGraph-based state machine workflow orchestration
  - âœ… UI backend migrated to use Agents (chat_service.py uses AnswerAgent, pdf.py uses IndexingAgent)
  - âœ… Deleted `src/readers/` directory, parallel_processor moved to `src/core/processing/`
  - âœ… Simplified chapters.py, temporarily removed chapter editing features
- ğŸ“ **Data Storage Optimization**
  - âœ… JSON files organized by document: `data/json_data/{doc_name}/data.json`
  - âœ… Unified management of all JSON files for documents (data.json, structure.json, chunks.json)
  - âœ… Direct folder deletion when removing documents, no file omissions
- ğŸ”„ **State Management Enhancement**
  - âœ… IndexingState added `is_complete` field to track completion status
  - âœ… DocumentRegistry auto-creates temporary records to track processing progress
  - âœ… Stage-wise cache checking to avoid reprocessing
- ğŸ—‘ï¸ **Code Cleanup**
  - âŒ Deleted Web-related API and backend code (temporarily, to be redesigned)
  - âŒ Deleted ~1500+ lines of old Reader code
  - âœ… Retained MCP client (as requested)
  - âœ… Cleaner codebase, easier to maintain

### 2025-11-26 - Parallel Processing Optimization and Chapter Management UI
- âš¡ **Parallel Processing Optimization**
  - Added `src/utils/async_utils.py` - Generic async parallel processing utilities
  - Added `src/core/processing/parallel_processor.py` - Specialized parallel processor
  - Chapter summary and content refactoring now execute in parallel, 3-5x speed improvement
  - Detail summary generation parallelized with semaphore-controlled concurrency
- ğŸ“ **Independent Chapter Management Interface**
  - New `/chapters` page - Parallel to config and data management
  - Integrated PDF preview with left chapter list + right PDF display
  - Support chapter edit, add, delete operations
  - Support batch rebuild of vector database and summaries
  - Processing progress indicators and chapter highlighting
- ğŸ› ï¸ **Code Refactoring**
  - Extracted parallel processing logic into independent modules for better reusability

### 2025-11-19 - Data Management System
- âœ¨ **New Data Management Interface**
  - Real-time storage overview dashboard (document count, storage size, session stats)
  - Document detail display (JSON, Vector DB, Images, Summary shown independently)
  - **Granular partial deletion** - Delete specific data types for individual documents
  - Batch operations support - Select multiple documents for deletion
  - Cache management - View and clear PDF images, vector DB, JSON cache
  - Smart cleanup - Auto-delete data older than N days
  - Data backup functionality - Create session, output, config backups
  - Session statistics - Total sessions, messages, last activity, backup count

### 2025-10-31 - Session System Enhancement
- ğŸ”„ **Session Persistence Optimization**
  - Dual storage architecture: Client localStorage + server file storage
  - Auto-backup rotation mechanism (keeps latest 10 backups)
  - Session import/export functionality
  - Storage location migration: `chat_sessions.json` â†’ `sessions/backups/chat_sessions_current.json`
- ğŸ› ï¸ **Backend Optimization**
  - SessionManager refactor with backup management support
  - Session format compatibility handling (supports dict and list formats)
  - Auto-migration of old session files

### 2025-09-15 - FastAPI Web Interface
- ğŸŒ **New Web Interface**
  - FastAPI + WebSocket real-time chat
  - Jinja2 templates + Vanilla JavaScript
  - Integrated online PDF preview
  - Responsive design, mobile-friendly

### 2025-08-20 - History Compression Optimization
- ğŸ§  **Intelligent History Management**
  - LLM auto-summarizes conversation history
  - 90%+ compression rate, significantly saves tokens
  - Maintains context coherence

### 2025-07-30 - Web Reader
- Added Web Reader functionality
- MCP service integration

</details>

---

## License | License

[MIT License](LICENSE)

## Contributing | Contributing

Welcome to submit Issues and Pull Requests!

## Acknowledgements | Acknowledgments

- [LangChain](https://github.com/langchain-ai/langchain) - Powerful LLM application development framework
- [LangGraph](https://github.com/langchain-ai/langgraph) - Multi-agent orchestration framework
- [FAISS](https://github.com/facebookresearch/faiss) - Efficient vector retrieval library
- [FastAPI](https://fastapi.tiangolo.com/) - Modern web framework
